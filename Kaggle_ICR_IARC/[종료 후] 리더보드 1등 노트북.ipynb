{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d8c6f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback, ProgbarLogger\n",
    "from tensorflow.keras import regularizers as R\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import optimizers as O\n",
    "from tensorflow.keras import constraints as C\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy, sparse_categorical_crossentropy, Loss\n",
    "from tensorflow.keras.metrics import AUC\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "tf.keras.utils.set_random_seed(722)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf60ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_log_loss_np(y_true, y_pred):\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1-1e-15)\n",
    "    nc = np.bincount(y_true)\n",
    "    balanced_log_loss_score = (-1/nc[0]*(np.sum(np.where(y_true==0,1,0) * np.log(1-y_pred))) - 1/nc[1]*(np.sum(np.where(y_true!=0,1,0) * np.log(y_pred)))) / 2\n",
    "    return balanced_log_loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "638eb913",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv', index_col='Id')\n",
    "\n",
    "train_df['EJ'] = train_df['EJ'].replace({'A': 0, 'B': 1})\n",
    "\n",
    "nan_fill = train_df.isna().any()\n",
    "nan_fill *= train_df.min() - train_df.max()\n",
    "nan_fill[nan_fill == 0] = train_df.median()\n",
    "train_df = train_df.fillna(nan_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9900641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.iloc[:,:-1].values\n",
    "tgt = train_df.Class.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15df3cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is the hard-coded label from baseline model, where \"1\" is difficult to predict, \"0\" - easy.\n",
    "### (y_true = 1 and y_pred < 0.2) or (y_true = 0 and y_pred > 0.8) -> label \"1\", otherwise label \"0\".\n",
    "tgt2 = np.asarray([1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
    "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
    "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
    "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
    "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
    "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
    "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
    "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    "       0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
    "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
    "       0], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5b11f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def smish(x):\n",
    "    return x * K.tanh(K.log(1 + K.sigmoid(x)))\n",
    "\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class GatedLinearUnit(L.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.linear = L.Dense(units)\n",
    "        self.sigmoid = L.Dense(units, activation=\"sigmoid\")\n",
    "        self.units = units\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['units'] = self.units\n",
    "        return config\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.linear(inputs) * self.sigmoid(inputs)\n",
    "    \n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class GatedResidualNetwork(L.Layer):\n",
    "    def __init__(self, units, dropout_rate, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.relu_dense = L.Dense(units, activation=smish)\n",
    "        self.linear_dense = L.Dense(units)\n",
    "        self.dropout = L.Dropout(dropout_rate)\n",
    "        self.gated_linear_unit = GatedLinearUnit(units)\n",
    "        self.layer_norm = L.LayerNormalization()\n",
    "        self.project = L.Dense(units)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['units'] = self.units\n",
    "        config['dropout_rate'] = self.dropout_rate\n",
    "        return config\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.relu_dense(inputs)\n",
    "        x = self.linear_dense(x)\n",
    "        x = self.dropout(x)\n",
    "        if inputs.shape[-1] != self.units:\n",
    "            inputs = self.project(inputs)\n",
    "        x = inputs + self.gated_linear_unit(x)\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class VariableSelection(L.Layer):\n",
    "    def __init__(self, num_features, units, dropout_rate, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.grns = list()\n",
    "        # Create a GRN for each feature independently\n",
    "        for idx in range(num_features):\n",
    "            grn = GatedResidualNetwork(units, dropout_rate)\n",
    "            self.grns.append(grn)\n",
    "        # Create a GRN for the concatenation of all the features\n",
    "        self.grn_concat = GatedResidualNetwork(units, dropout_rate)\n",
    "        self.softmax = L.Dense(units=num_features, activation=\"softmax\")\n",
    "        self.num_features = num_features\n",
    "        self.units = units\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['num_features'] = self.num_features\n",
    "        config['units'] = self.units\n",
    "        config['dropout_rate'] = self.dropout_rate\n",
    "        return config\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        v = L.concatenate(inputs)\n",
    "        v = self.grn_concat(v)\n",
    "        v = tf.expand_dims(self.softmax(v), axis=-1)\n",
    "\n",
    "        x = []\n",
    "        for idx, input_ in enumerate(inputs):\n",
    "            x.append(self.grns[idx](input_))\n",
    "        x = tf.stack(x, axis=1)\n",
    "\n",
    "        outputs = tf.squeeze(tf.matmul(v, x, transpose_a=True), axis=1)\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class VariableSelectionFlow(L.Layer):\n",
    "    def __init__(self, num_features, units, dropout_rate, dense_units=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.variableselection = VariableSelection(num_features, units, dropout_rate)\n",
    "        self.split = L.Lambda(lambda t: tf.split(t, num_features, axis=-1))\n",
    "        self.dense = dense_units\n",
    "        if dense_units:\n",
    "            self.dense_list = [L.Dense(dense_units, \\\n",
    "                                       activation='linear') \\\n",
    "                               for _ in tf.range(num_features)\n",
    "                              ]\n",
    "        self.num_features = num_features\n",
    "        self.units = units\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dense_units = dense_units\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['num_features'] = self.num_features\n",
    "        config['units'] = self.units\n",
    "        config['dropout_rate'] = self.dropout_rate\n",
    "        config['dense_units'] = self.dense_units\n",
    "        return config        \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        split_input = self.split(inputs)\n",
    "        if self.dense:\n",
    "            l = [self.dense_list[i](split_input[i]) for i in range(len(self.dense_list))]\n",
    "        else:\n",
    "            l = split_input\n",
    "        return self.variableselection(l)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61e3f054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______fold 1______, ________repeat 1__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 50s 769ms/step - loss: 0.4855 - val_loss: 0.4567 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4414\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.4414 - val_loss: 0.4646 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.4400 - val_loss: 0.4551 - lr: 9.5000e-04\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.4144 - val_loss: 0.4449 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.4107 - val_loss: 0.4375 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3943\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.3943 - val_loss: 0.4951 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.3643 - val_loss: 0.4041 - lr: 9.0250e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.3712 - val_loss: 0.3671 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3241\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.3241 - val_loss: 0.3930 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.3213 - val_loss: 0.3481 - lr: 8.5737e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3037\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.3037 - val_loss: 0.3536 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.3287 - val_loss: 0.3429 - lr: 8.1451e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2879 - val_loss: 0.2870 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2938\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2938 - val_loss: 0.2903 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2585 - val_loss: 0.2489 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2285 - val_loss: 0.2460 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2398\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2398 - val_loss: 0.3182 - lr: 7.7378e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.2428 - val_loss: 0.2400 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2225\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2225 - val_loss: 0.3013 - lr: 7.3509e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2453\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2453 - val_loss: 0.2969 - lr: 6.9834e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2195\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2195 - val_loss: 0.2838 - lr: 6.6342e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2251\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2251 - val_loss: 0.3067 - lr: 6.3025e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2111\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2111 - val_loss: 0.2818 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2355\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 6s 358ms/step - loss: 0.2355 - val_loss: 0.2571 - lr: 5.6880e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2171 - val_loss: 0.2316 - lr: 5.4036e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2154\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.2154 - val_loss: 0.2347 - lr: 5.4036e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.2045 - val_loss: 0.2265 - lr: 5.1334e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1889\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 6s 349ms/step - loss: 0.1889 - val_loss: 0.2491 - lr: 5.1334e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1969\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 6s 347ms/step - loss: 0.1969 - val_loss: 0.2328 - lr: 4.8767e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2083\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 6s 348ms/step - loss: 0.2083 - val_loss: 0.2758 - lr: 4.6329e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2003\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2003 - val_loss: 0.2549 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2069 - val_loss: 0.2242 - lr: 4.1812e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2009\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2009 - val_loss: 0.2585 - lr: 4.1812e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1907\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1907 - val_loss: 0.2270 - lr: 3.9721e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1914\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1914 - val_loss: 0.2962 - lr: 3.7735e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1765\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1765 - val_loss: 0.2361 - lr: 3.5849e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1857\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1857 - val_loss: 0.2783 - lr: 3.4056e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1853\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1853 - val_loss: 0.2624 - lr: 3.2353e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1730\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1730 - val_loss: 0.2720 - lr: 3.0736e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1710\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1710 - val_loss: 0.2766 - lr: 2.9199e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1868\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1868 - val_loss: 0.2645 - lr: 2.7739e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1754\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.1754 - val_loss: 0.2740 - lr: 2.6352e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1767\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1767 - val_loss: 0.2786 - lr: 2.5034e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1784\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1784 - val_loss: 0.2650 - lr: 2.3783e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1733\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1733 - val_loss: 0.2804 - lr: 2.2594e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1695\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1695 - val_loss: 0.2820 - lr: 2.1464e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1644\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1644 - val_loss: 0.2797 - lr: 2.0391e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1598\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1598 - val_loss: 0.3056 - lr: 1.9371e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1667\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1667 - val_loss: 0.2876 - lr: 1.8403e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1563\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1563 - val_loss: 0.2759 - lr: 1.7482e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1701\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1701 - val_loss: 0.2756 - lr: 1.6608e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1587\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1587 - val_loss: 0.2966 - lr: 1.5778e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1573\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1573 - val_loss: 0.2679 - lr: 1.4989e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1531\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1531 - val_loss: 0.2960 - lr: 1.4240e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1582\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1582 - val_loss: 0.2924 - lr: 1.3528e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1651\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1651 - val_loss: 0.3101 - lr: 1.2851e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1540\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.1540 - val_loss: 0.2744 - lr: 1.2209e-04\n",
      "Epoch 57: early stopping\n",
      "2/2 [==============================] - 8s 121ms/step\n",
      "0.2069, 0.2242, 0.3633\n",
      "______fold 1______, ________repeat 2__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 52s 811ms/step - loss: 0.4961 - val_loss: 0.4624 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.4519 - val_loss: 0.4550 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4382\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 8s 424ms/step - loss: 0.4382 - val_loss: 0.4576 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.4291 - val_loss: 0.4479 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 8s 429ms/step - loss: 0.4127 - val_loss: 0.4265 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.3710 - val_loss: 0.3660 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3535 - val_loss: 0.3121 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.3196 - val_loss: 0.2735 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 8s 434ms/step - loss: 0.2811 - val_loss: 0.2306 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2647\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 415ms/step - loss: 0.2647 - val_loss: 0.2544 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2642\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2642 - val_loss: 0.3115 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.2639 - val_loss: 0.2270 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2394\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2394 - val_loss: 0.2806 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2449\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2449 - val_loss: 0.2404 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2317\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2317 - val_loss: 0.2467 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1978\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1978 - val_loss: 0.2301 - lr: 7.3509e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2065\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2065 - val_loss: 0.2332 - lr: 6.9834e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.2052 - val_loss: 0.2193 - lr: 6.6342e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1861\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1861 - val_loss: 0.2686 - lr: 6.6342e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1994 - val_loss: 0.2175 - lr: 6.3025e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1981\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1981 - val_loss: 0.2235 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1843\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1843 - val_loss: 0.2442 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1934\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1934 - val_loss: 0.2479 - lr: 5.6880e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1930\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1930 - val_loss: 0.2840 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1741\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1741 - val_loss: 0.2357 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1903\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1903 - val_loss: 0.2552 - lr: 4.8767e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1795\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1795 - val_loss: 0.2429 - lr: 4.6329e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1702\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1702 - val_loss: 0.2293 - lr: 4.4013e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1845\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1845 - val_loss: 0.2227 - lr: 4.1812e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1673\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1673 - val_loss: 0.2400 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1657 - val_loss: 0.2150 - lr: 3.7735e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1696\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.1696 - val_loss: 0.2204 - lr: 3.7735e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1644\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1644 - val_loss: 0.2453 - lr: 3.5849e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1627\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1627 - val_loss: 0.2256 - lr: 3.4056e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1560\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1560 - val_loss: 0.2531 - lr: 3.2353e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1681\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.1681 - val_loss: 0.2495 - lr: 3.0736e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1486\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1486 - val_loss: 0.2420 - lr: 2.9199e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1468\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1468 - val_loss: 0.2576 - lr: 2.7739e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1527\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1527 - val_loss: 0.2271 - lr: 2.6352e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1394\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1394 - val_loss: 0.2527 - lr: 2.5034e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1553\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1553 - val_loss: 0.2552 - lr: 2.3783e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1312\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.1312 - val_loss: 0.2486 - lr: 2.2594e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1235\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.1235 - val_loss: 0.2518 - lr: 2.1464e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1382\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1382 - val_loss: 0.2419 - lr: 2.0391e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1399\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1399 - val_loss: 0.2489 - lr: 1.9371e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1300\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1300 - val_loss: 0.2350 - lr: 1.8403e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1347\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.1347 - val_loss: 0.2476 - lr: 1.7482e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1614\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1614 - val_loss: 0.2377 - lr: 1.6608e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1338\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1338 - val_loss: 0.2437 - lr: 1.5778e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1416\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1416 - val_loss: 0.2473 - lr: 1.4989e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1480\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1480 - val_loss: 0.2325 - lr: 1.4240e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1350\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1350 - val_loss: 0.2415 - lr: 1.3528e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1383\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1383 - val_loss: 0.2334 - lr: 1.2851e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1358\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1358 - val_loss: 0.2391 - lr: 1.2209e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1172\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1172 - val_loss: 0.2367 - lr: 1.1598e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1290\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1290 - val_loss: 0.2363 - lr: 1.1018e-04\n",
      "Epoch 56: early stopping\n",
      "2/2 [==============================] - 6s 121ms/step\n",
      "0.1657, 0.2150, 0.3581\n",
      "______fold 1______, ________repeat 3__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 51s 801ms/step - loss: 0.4869 - val_loss: 0.4617 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 430ms/step - loss: 0.4577 - val_loss: 0.4519 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.4465 - val_loss: 0.4402 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.4380 - val_loss: 0.4213 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.4065 - val_loss: 0.3722 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.3714 - val_loss: 0.3532 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.3615 - val_loss: 0.3258 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.3210 - val_loss: 0.2566 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2941\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2941 - val_loss: 0.2926 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2702\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2702 - val_loss: 0.2674 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2703 - val_loss: 0.2559 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2592 - val_loss: 0.2260 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2645\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2645 - val_loss: 0.2433 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2427 - val_loss: 0.2183 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2293 - val_loss: 0.2145 - lr: 8.5737e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2244\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2244 - val_loss: 0.2628 - lr: 8.5737e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2277\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2277 - val_loss: 0.2697 - lr: 8.1451e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2191 - val_loss: 0.2056 - lr: 7.7378e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2064\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2064 - val_loss: 0.2613 - lr: 7.7378e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1969\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1969 - val_loss: 0.2360 - lr: 7.3509e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2101\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2101 - val_loss: 0.3039 - lr: 6.9834e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1996\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1996 - val_loss: 0.2485 - lr: 6.6342e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2019\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.2019 - val_loss: 0.2465 - lr: 6.3025e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1942\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1942 - val_loss: 0.2588 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1945\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1945 - val_loss: 0.2357 - lr: 5.6880e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1939\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1939 - val_loss: 0.2613 - lr: 5.4036e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1956 - val_loss: 0.1962 - lr: 5.1334e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1709\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1709 - val_loss: 0.2418 - lr: 5.1334e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1898\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1898 - val_loss: 0.2025 - lr: 4.8767e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1829\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1829 - val_loss: 0.2290 - lr: 4.6329e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1719\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1719 - val_loss: 0.2053 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1624\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1624 - val_loss: 0.2023 - lr: 4.1812e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1666\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1666 - val_loss: 0.2169 - lr: 3.9721e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1729\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1729 - val_loss: 0.2280 - lr: 3.7735e-04\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.1660\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1660 - val_loss: 0.2452 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1505\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1505 - val_loss: 0.2313 - lr: 3.4056e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1637\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1637 - val_loss: 0.2044 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1591\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1591 - val_loss: 0.2174 - lr: 3.0736e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1511\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1511 - val_loss: 0.2043 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1581 - val_loss: 0.1897 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1632\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1632 - val_loss: 0.2026 - lr: 2.7739e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1525\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.1525 - val_loss: 0.2139 - lr: 2.6352e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1664\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1664 - val_loss: 0.2147 - lr: 2.5034e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1544\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1544 - val_loss: 0.1957 - lr: 2.3783e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1567\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.1567 - val_loss: 0.2341 - lr: 2.2594e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1355\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.1355 - val_loss: 0.2522 - lr: 2.1464e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1505\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1505 - val_loss: 0.2304 - lr: 2.0391e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1606\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1606 - val_loss: 0.2205 - lr: 1.9371e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1385\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1385 - val_loss: 0.1927 - lr: 1.8403e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1446\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1446 - val_loss: 0.2174 - lr: 1.7482e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1467\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1467 - val_loss: 0.1956 - lr: 1.6608e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1464\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1464 - val_loss: 0.2112 - lr: 1.5778e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1395\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1395 - val_loss: 0.2118 - lr: 1.4989e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1316\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1316 - val_loss: 0.2029 - lr: 1.4240e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1371\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1371 - val_loss: 0.2154 - lr: 1.3528e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1409\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1409 - val_loss: 0.2074 - lr: 1.2851e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1296\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1296 - val_loss: 0.1969 - lr: 1.2209e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1336\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1336 - val_loss: 0.2070 - lr: 1.1598e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1330\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1330 - val_loss: 0.2222 - lr: 1.1018e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1356\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1356 - val_loss: 0.2062 - lr: 1.0467e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1417\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1417 - val_loss: 0.2017 - lr: 9.9440e-05\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1343\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1343 - val_loss: 0.2108 - lr: 9.4468e-05\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1218\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1218 - val_loss: 0.2021 - lr: 8.9745e-05\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1258\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1258 - val_loss: 0.2071 - lr: 8.5258e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1507\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1507 - val_loss: 0.2029 - lr: 8.0995e-05\n",
      "Epoch 65: early stopping\n",
      "2/2 [==============================] - 6s 127ms/step\n",
      "0.1581, 0.1897, 0.3369\n",
      "______fold 1______, ________repeat 4__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 781ms/step - loss: 0.5278 - val_loss: 0.4638 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 431ms/step - loss: 0.4540 - val_loss: 0.4496 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 8s 435ms/step - loss: 0.4391 - val_loss: 0.4331 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.4251 - val_loss: 0.4193 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4071\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.4071 - val_loss: 0.4357 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3984 - val_loss: 0.3497 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.3876 - val_loss: 0.3189 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.3551 - val_loss: 0.3000 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.3361 - val_loss: 0.2902 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.3205 - val_loss: 0.2632 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2928\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2928 - val_loss: 0.2658 - lr: 9.5000e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.3014 - val_loss: 0.2532 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2934 - val_loss: 0.2293 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2568 - val_loss: 0.2264 - lr: 9.0250e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2623 - val_loss: 0.2165 - lr: 9.0250e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2395\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2395 - val_loss: 0.2405 - lr: 9.0250e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2471 - val_loss: 0.2164 - lr: 8.5737e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2290 - val_loss: 0.1952 - lr: 8.5737e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1983\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1983 - val_loss: 0.2514 - lr: 8.5737e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2234\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2234 - val_loss: 0.2818 - lr: 8.1451e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2318\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.2318 - val_loss: 0.2378 - lr: 7.7378e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2192\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2192 - val_loss: 0.2770 - lr: 7.3509e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2057\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2057 - val_loss: 0.2100 - lr: 6.9834e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2417\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2417 - val_loss: 0.2267 - lr: 6.6342e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2666\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2666 - val_loss: 0.2356 - lr: 6.3025e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2291\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2291 - val_loss: 0.2461 - lr: 5.9874e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2066\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.2066 - val_loss: 0.2478 - lr: 5.6880e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1955\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1955 - val_loss: 0.2573 - lr: 5.4036e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2104\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2104 - val_loss: 0.2147 - lr: 5.1334e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1917\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1917 - val_loss: 0.2419 - lr: 4.8767e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1822\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1822 - val_loss: 0.1994 - lr: 4.6329e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1897\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1897 - val_loss: 0.2100 - lr: 4.4013e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1670\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1670 - val_loss: 0.2218 - lr: 4.1812e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1781\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1781 - val_loss: 0.2189 - lr: 3.9721e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1755\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1755 - val_loss: 0.2621 - lr: 3.7735e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1865\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1865 - val_loss: 0.2271 - lr: 3.5849e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1883\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1883 - val_loss: 0.2279 - lr: 3.4056e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1623\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1623 - val_loss: 0.2228 - lr: 3.2353e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1573\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1573 - val_loss: 0.2160 - lr: 3.0736e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1621\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1621 - val_loss: 0.2516 - lr: 2.9199e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1784\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1784 - val_loss: 0.2196 - lr: 2.7739e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1576\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1576 - val_loss: 0.2404 - lr: 2.6352e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1609\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1609 - val_loss: 0.2182 - lr: 2.5034e-04\n",
      "Epoch 43: early stopping\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002231E124670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 8s 127ms/step\n",
      "0.2290, 0.1952, 0.3293\n",
      "______fold 1______, ________repeat 5__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 52s 813ms/step - loss: 0.5251 - val_loss: 0.4683 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.4619 - val_loss: 0.4622 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 8s 433ms/step - loss: 0.4546 - val_loss: 0.4604 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.4481 - val_loss: 0.4577 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.4260 - val_loss: 0.4548 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 431ms/step - loss: 0.3977 - val_loss: 0.4397 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.3745 - val_loss: 0.3683 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.3545 - val_loss: 0.3048 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.3435 - val_loss: 0.2853 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3165 - val_loss: 0.2739 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2849\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2849 - val_loss: 0.3030 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2817 - val_loss: 0.2736 - lr: 9.5000e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2875 - val_loss: 0.2487 - lr: 9.5000e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2777\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2777 - val_loss: 0.2526 - lr: 9.5000e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2761\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2761 - val_loss: 0.3144 - lr: 9.0250e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2481\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2481 - val_loss: 0.2744 - lr: 8.5737e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2442\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2442 - val_loss: 0.2562 - lr: 8.1451e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2370\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2370 - val_loss: 0.2595 - lr: 7.7378e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2213\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2213 - val_loss: 0.2558 - lr: 7.3509e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2212 - val_loss: 0.2437 - lr: 6.9834e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2523\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2523 - val_loss: 0.2567 - lr: 6.9834e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2048\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2048 - val_loss: 0.2494 - lr: 6.6342e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.1997 - val_loss: 0.2374 - lr: 6.3025e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2087\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2087 - val_loss: 0.2833 - lr: 6.3025e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2279\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2279 - val_loss: 0.2790 - lr: 5.9874e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2138\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2138 - val_loss: 0.2655 - lr: 5.6880e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.2079 - val_loss: 0.2283 - lr: 5.4036e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2024\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2024 - val_loss: 0.2393 - lr: 5.4036e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2037\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2037 - val_loss: 0.2465 - lr: 5.1334e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1862\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 6s 358ms/step - loss: 0.1862 - val_loss: 0.2458 - lr: 4.8767e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1877\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1877 - val_loss: 0.2333 - lr: 4.6329e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1759\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.1759 - val_loss: 0.2312 - lr: 4.4013e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1857\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1857 - val_loss: 0.2708 - lr: 4.1812e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1833\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1833 - val_loss: 0.2491 - lr: 3.9721e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1785\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1785 - val_loss: 0.2386 - lr: 3.7735e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1923\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 6s 356ms/step - loss: 0.1923 - val_loss: 0.2438 - lr: 3.5849e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1767 - val_loss: 0.2208 - lr: 3.4056e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1755\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 6s 358ms/step - loss: 0.1755 - val_loss: 0.2255 - lr: 3.4056e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1787\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1787 - val_loss: 0.2373 - lr: 3.2353e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1663\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 6s 355ms/step - loss: 0.1663 - val_loss: 0.2397 - lr: 3.0736e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1669\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1669 - val_loss: 0.2450 - lr: 2.9199e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1640\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.1640 - val_loss: 0.2549 - lr: 2.7739e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1636\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1636 - val_loss: 0.2253 - lr: 2.6352e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1720\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 6s 356ms/step - loss: 0.1720 - val_loss: 0.2293 - lr: 2.5034e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1651\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 6s 356ms/step - loss: 0.1651 - val_loss: 0.2344 - lr: 2.3783e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1621\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 6s 355ms/step - loss: 0.1621 - val_loss: 0.2424 - lr: 2.2594e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1580\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1580 - val_loss: 0.2346 - lr: 2.1464e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1606\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 6s 356ms/step - loss: 0.1606 - val_loss: 0.2296 - lr: 2.0391e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1592\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 6s 358ms/step - loss: 0.1592 - val_loss: 0.2320 - lr: 1.9371e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1590\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 6s 358ms/step - loss: 0.1590 - val_loss: 0.2405 - lr: 1.8403e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1494\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1494 - val_loss: 0.2403 - lr: 1.7482e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1649\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1649 - val_loss: 0.2536 - lr: 1.6608e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1502\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1502 - val_loss: 0.2492 - lr: 1.5778e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1550\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 6s 356ms/step - loss: 0.1550 - val_loss: 0.2382 - lr: 1.4989e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1508\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 6s 356ms/step - loss: 0.1508 - val_loss: 0.2397 - lr: 1.4240e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1407\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 6s 356ms/step - loss: 0.1407 - val_loss: 0.2481 - lr: 1.3528e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1434\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1434 - val_loss: 0.2473 - lr: 1.2851e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1452\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1452 - val_loss: 0.2666 - lr: 1.2209e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1543\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1543 - val_loss: 0.2515 - lr: 1.1598e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1595\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1595 - val_loss: 0.2677 - lr: 1.1018e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1525\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1525 - val_loss: 0.2587 - lr: 1.0467e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1471\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "18/18 [==============================] - 7s 413ms/step - loss: 0.1471 - val_loss: 0.2517 - lr: 9.9440e-05\n",
      "Epoch 62: early stopping\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002231D8360E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 6s 123ms/step\n",
      "0.1767, 0.2208, 0.4003\n",
      "______fold 1______, ________repeat 6__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 52s 803ms/step - loss: 0.4847 - val_loss: 0.4602 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.4589 - val_loss: 0.4529 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.4467 - val_loss: 0.4165 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.4230 - val_loss: 0.3832 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.3784 - val_loss: 0.3456 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3847\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.3847 - val_loss: 0.3718 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.3514 - val_loss: 0.3335 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.3423 - val_loss: 0.3141 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3129 - val_loss: 0.2482 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.3011 - val_loss: 0.2383 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2803\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2803 - val_loss: 0.2561 - lr: 9.5000e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2939\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2939 - val_loss: 0.2627 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2551\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2551 - val_loss: 0.2910 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.2509 - val_loss: 0.2300 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2482\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2482 - val_loss: 0.2564 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.2399 - val_loss: 0.1954 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2405\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2405 - val_loss: 0.2116 - lr: 7.7378e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2294 - val_loss: 0.1912 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2256\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.2256 - val_loss: 0.2793 - lr: 7.3509e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1985\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1985 - val_loss: 0.2454 - lr: 6.9834e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2086\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2086 - val_loss: 0.2041 - lr: 6.6342e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2018\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2018 - val_loss: 0.2774 - lr: 6.3025e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2052\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2052 - val_loss: 0.2283 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2005\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 415ms/step - loss: 0.2005 - val_loss: 0.2358 - lr: 5.6880e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1945\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1945 - val_loss: 0.2156 - lr: 5.4036e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1871\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1871 - val_loss: 0.2376 - lr: 5.1334e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1945\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1945 - val_loss: 0.2071 - lr: 4.8767e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1700\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1700 - val_loss: 0.2351 - lr: 4.6329e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1743\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1743 - val_loss: 0.2078 - lr: 4.4013e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1707\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1707 - val_loss: 0.2373 - lr: 4.1812e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1536\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 6s 359ms/step - loss: 0.1536 - val_loss: 0.2218 - lr: 3.9721e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1526\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 6s 358ms/step - loss: 0.1526 - val_loss: 0.2415 - lr: 3.7735e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1548\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1548 - val_loss: 0.2318 - lr: 3.5849e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1506\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1506 - val_loss: 0.2432 - lr: 3.4056e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1445\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1445 - val_loss: 0.2535 - lr: 3.2353e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1431\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1431 - val_loss: 0.2489 - lr: 3.0736e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1451\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1451 - val_loss: 0.2338 - lr: 2.9199e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1429\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1429 - val_loss: 0.2273 - lr: 2.7739e-04\n",
      "Epoch 39/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.1275\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1275 - val_loss: 0.2328 - lr: 2.6352e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1277\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1277 - val_loss: 0.2394 - lr: 2.5034e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1302\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1302 - val_loss: 0.2465 - lr: 2.3783e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1289\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1289 - val_loss: 0.2448 - lr: 2.2594e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1359\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1359 - val_loss: 0.2498 - lr: 2.1464e-04\n",
      "Epoch 43: early stopping\n",
      "2/2 [==============================] - 6s 128ms/step\n",
      "0.2294, 0.1912, 0.3603\n",
      "______fold 1______, ________repeat 7__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 793ms/step - loss: 0.4818 - val_loss: 0.4512 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.4420 - val_loss: 0.4374 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4315\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 8s 423ms/step - loss: 0.4315 - val_loss: 0.4563 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.4242 - val_loss: 0.4294 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.3901 - val_loss: 0.4092 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3917\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.3917 - val_loss: 0.4147 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.3796 - val_loss: 0.3840 - lr: 9.0250e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3765\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.3765 - val_loss: 0.4045 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3716\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.3716 - val_loss: 0.3887 - lr: 8.5737e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.3505 - val_loss: 0.3581 - lr: 8.1451e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.3238 - val_loss: 0.2965 - lr: 8.1451e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2988 - val_loss: 0.2327 - lr: 8.1451e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2780 - val_loss: 0.2145 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2636 - val_loss: 0.2093 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2443\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 8s 423ms/step - loss: 0.2443 - val_loss: 0.2598 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.2153 - val_loss: 0.1891 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2272\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2272 - val_loss: 0.2224 - lr: 7.7378e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1998\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1998 - val_loss: 0.2263 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2193\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2193 - val_loss: 0.2077 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2160\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2160 - val_loss: 0.2541 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2051\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2051 - val_loss: 0.2091 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2115\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2115 - val_loss: 0.2148 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2073\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2073 - val_loss: 0.2033 - lr: 5.6880e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2065\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.2065 - val_loss: 0.2862 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2147 - val_loss: 0.1887 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1998\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.1998 - val_loss: 0.2451 - lr: 5.1334e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1877 - val_loss: 0.1842 - lr: 4.8767e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1778\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1778 - val_loss: 0.2006 - lr: 4.8767e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.1817 - val_loss: 0.1815 - lr: 4.6329e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1737\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.1737 - val_loss: 0.1819 - lr: 4.6329e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1787\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1787 - val_loss: 0.2023 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.1647 - val_loss: 0.1810 - lr: 4.1812e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1726\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1726 - val_loss: 0.2144 - lr: 4.1812e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1514\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.1514 - val_loss: 0.1816 - lr: 3.9721e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1636\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1636 - val_loss: 0.2076 - lr: 3.7735e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1547\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 8s 472ms/step - loss: 0.1547 - val_loss: 0.2199 - lr: 3.5849e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1517\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1517 - val_loss: 0.1907 - lr: 3.4056e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1446\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1446 - val_loss: 0.1946 - lr: 3.2353e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1365 - val_loss: 0.1712 - lr: 3.0736e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1350\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1350 - val_loss: 0.2079 - lr: 3.0736e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1325\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1325 - val_loss: 0.1739 - lr: 2.9199e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1463\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1463 - val_loss: 0.1843 - lr: 2.7739e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1352\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1352 - val_loss: 0.1881 - lr: 2.6352e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1205\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 6s 358ms/step - loss: 0.1205 - val_loss: 0.1953 - lr: 2.5034e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1346\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1346 - val_loss: 0.2422 - lr: 2.3783e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1498\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1498 - val_loss: 0.1928 - lr: 2.2594e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1340\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1340 - val_loss: 0.2094 - lr: 2.1464e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1408\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1408 - val_loss: 0.1752 - lr: 2.0391e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1231\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1231 - val_loss: 0.2196 - lr: 1.9371e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1197\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1197 - val_loss: 0.2096 - lr: 1.8403e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1262\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.1262 - val_loss: 0.2279 - lr: 1.7482e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1307\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1307 - val_loss: 0.2011 - lr: 1.6608e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1148\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1148 - val_loss: 0.2346 - lr: 1.5778e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1139\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1139 - val_loss: 0.2369 - lr: 1.4989e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1108\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1108 - val_loss: 0.2106 - lr: 1.4240e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1151\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1151 - val_loss: 0.2206 - lr: 1.3528e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1158\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1158 - val_loss: 0.1816 - lr: 1.2851e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1126\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1126 - val_loss: 0.2225 - lr: 1.2209e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1110\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1110 - val_loss: 0.2180 - lr: 1.1598e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0930\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.0930 - val_loss: 0.2233 - lr: 1.1018e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1107\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1107 - val_loss: 0.2444 - lr: 1.0467e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1014\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1014 - val_loss: 0.2350 - lr: 9.9440e-05\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1168\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1168 - val_loss: 0.2131 - lr: 9.4468e-05\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1135\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.1135 - val_loss: 0.2098 - lr: 8.9745e-05\n",
      "Epoch 64: early stopping\n",
      "2/2 [==============================] - 6s 129ms/step\n",
      "0.1365, 0.1712, 0.3470\n",
      "______fold 1______, ________repeat 8__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 815ms/step - loss: 0.5079 - val_loss: 0.4671 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 431ms/step - loss: 0.4649 - val_loss: 0.4629 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.4558 - val_loss: 0.4623 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4352\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 8s 417ms/step - loss: 0.4352 - val_loss: 0.4641 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4210\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.4210 - val_loss: 0.4660 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.4188 - val_loss: 0.4475 - lr: 9.0250e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 430ms/step - loss: 0.4011 - val_loss: 0.4337 - lr: 9.0250e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.3942 - val_loss: 0.4286 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.3846 - val_loss: 0.4137 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.3703 - val_loss: 0.3718 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.3540 - val_loss: 0.3547 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 8s 435ms/step - loss: 0.3488 - val_loss: 0.3521 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 412ms/step - loss: 0.3566 - val_loss: 0.2929 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3325\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.3325 - val_loss: 0.3044 - lr: 9.0250e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.3139 - val_loss: 0.2729 - lr: 8.5737e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.3086 - val_loss: 0.2577 - lr: 8.5737e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2841\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2841 - val_loss: 0.2820 - lr: 8.5737e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2698 - val_loss: 0.2566 - lr: 8.1451e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2552\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2552 - val_loss: 0.2993 - lr: 8.1451e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2350\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2350 - val_loss: 0.3055 - lr: 7.7378e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2739\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2739 - val_loss: 0.3079 - lr: 7.3509e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2324 - val_loss: 0.2562 - lr: 6.9834e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2389 - val_loss: 0.2520 - lr: 6.9834e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2181\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.2181 - val_loss: 0.2952 - lr: 6.9834e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2490 - val_loss: 0.2412 - lr: 6.6342e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2107\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2107 - val_loss: 0.2477 - lr: 6.6342e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2079 - val_loss: 0.2334 - lr: 6.3025e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2045\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2045 - val_loss: 0.2618 - lr: 6.3025e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1867\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1867 - val_loss: 0.2548 - lr: 5.9874e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1881\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1881 - val_loss: 0.2503 - lr: 5.6880e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1804\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1804 - val_loss: 0.2411 - lr: 5.4036e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2013\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2013 - val_loss: 0.2475 - lr: 5.1334e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1995\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1995 - val_loss: 0.2469 - lr: 4.8767e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1834\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1834 - val_loss: 0.2453 - lr: 4.6329e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1969\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1969 - val_loss: 0.2565 - lr: 4.4013e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1780\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1780 - val_loss: 0.2536 - lr: 4.1812e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1761\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1761 - val_loss: 0.2464 - lr: 3.9721e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1763\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1763 - val_loss: 0.2474 - lr: 3.7735e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1872\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1872 - val_loss: 0.2546 - lr: 3.5849e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1762\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 6s 358ms/step - loss: 0.1762 - val_loss: 0.2399 - lr: 3.4056e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1662\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 6s 358ms/step - loss: 0.1662 - val_loss: 0.2626 - lr: 3.2353e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1763\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 6s 358ms/step - loss: 0.1763 - val_loss: 0.2572 - lr: 3.0736e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1564\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 6s 358ms/step - loss: 0.1564 - val_loss: 0.2506 - lr: 2.9199e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1777\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 6s 358ms/step - loss: 0.1777 - val_loss: 0.2562 - lr: 2.7739e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1638\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 6s 358ms/step - loss: 0.1638 - val_loss: 0.2512 - lr: 2.6352e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1668\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 6s 358ms/step - loss: 0.1668 - val_loss: 0.2604 - lr: 2.5034e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1612\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1612 - val_loss: 0.2609 - lr: 2.3783e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1443\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 8s 473ms/step - loss: 0.1443 - val_loss: 0.2619 - lr: 2.2594e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1420\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.1420 - val_loss: 0.2684 - lr: 2.1464e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1606\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1606 - val_loss: 0.2661 - lr: 2.0391e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1512\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1512 - val_loss: 0.2589 - lr: 1.9371e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1535\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1535 - val_loss: 0.2582 - lr: 1.8403e-04\n",
      "Epoch 52: early stopping\n",
      "2/2 [==============================] - 8s 128ms/step\n",
      "0.2079, 0.2334, 0.4171\n",
      "______fold 1______, ________repeat 9__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 762ms/step - loss: 0.5424 - val_loss: 0.4734 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.4650 - val_loss: 0.4495 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.4478 - val_loss: 0.4427 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.4377 - val_loss: 0.4271 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4156\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.4156 - val_loss: 0.4297 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4007\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4007 - val_loss: 0.4280 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 9s 491ms/step - loss: 0.3794 - val_loss: 0.4037 - lr: 9.0250e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.3550 - val_loss: 0.3426 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.3223 - val_loss: 0.3253 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.3221 - val_loss: 0.2819 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2988\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.2988 - val_loss: 0.3201 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.2781 - val_loss: 0.2572 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2638\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.2638 - val_loss: 0.2605 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.2750 - val_loss: 0.2390 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.2478 - val_loss: 0.2222 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2295\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2295 - val_loss: 0.2261 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2264\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 8s 472ms/step - loss: 0.2264 - val_loss: 0.2610 - lr: 7.7378e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2306\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 8s 473ms/step - loss: 0.2306 - val_loss: 0.2289 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2272\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 8s 417ms/step - loss: 0.2272 - val_loss: 0.2755 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2283\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 6s 356ms/step - loss: 0.2283 - val_loss: 0.2903 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2366\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 6s 357ms/step - loss: 0.2366 - val_loss: 0.3545 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2178\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 6s 358ms/step - loss: 0.2178 - val_loss: 0.2943 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2164\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 6s 359ms/step - loss: 0.2164 - val_loss: 0.2574 - lr: 5.6880e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1884\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1884 - val_loss: 0.2629 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2379\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2379 - val_loss: 0.2720 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2259\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2259 - val_loss: 0.2408 - lr: 4.8767e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1956\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1956 - val_loss: 0.2567 - lr: 4.6329e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1890\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1890 - val_loss: 0.2355 - lr: 4.4013e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1919\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1919 - val_loss: 0.2457 - lr: 4.1812e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1789\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1789 - val_loss: 0.2490 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1913\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1913 - val_loss: 0.2354 - lr: 3.7735e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1874\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.1874 - val_loss: 0.2325 - lr: 3.5849e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1806\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1806 - val_loss: 0.2925 - lr: 3.4056e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1835\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 414ms/step - loss: 0.1835 - val_loss: 0.2508 - lr: 3.2353e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1742\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1742 - val_loss: 0.2572 - lr: 3.0736e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1728\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1728 - val_loss: 0.2637 - lr: 2.9199e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1762\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1762 - val_loss: 0.2477 - lr: 2.7739e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1665\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1665 - val_loss: 0.2631 - lr: 2.6352e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1754\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1754 - val_loss: 0.2544 - lr: 2.5034e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1629\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1629 - val_loss: 0.2553 - lr: 2.3783e-04\n",
      "Epoch 40: early stopping\n",
      "2/2 [==============================] - 6s 116ms/step\n",
      "0.2478, 0.2222, 0.3765\n",
      "______fold 1______, ________repeat 10__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 817ms/step - loss: 0.4972 - val_loss: 0.4607 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 434ms/step - loss: 0.4547 - val_loss: 0.4552 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.4547 - val_loss: 0.4452 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4386\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.4386 - val_loss: 0.4541 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.4221 - val_loss: 0.4378 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 434ms/step - loss: 0.4136 - val_loss: 0.4165 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 434ms/step - loss: 0.3986 - val_loss: 0.3817 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 8s 425ms/step - loss: 0.3552 - val_loss: 0.3302 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.3247 - val_loss: 0.2845 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2968\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2968 - val_loss: 0.3298 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2802 - val_loss: 0.2194 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2593\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.2593 - val_loss: 0.2345 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.2383 - val_loss: 0.1841 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2409\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2409 - val_loss: 0.2109 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2306\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2306 - val_loss: 0.2068 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2123\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2123 - val_loss: 0.2167 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2050\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2050 - val_loss: 0.2026 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2076\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2076 - val_loss: 0.1949 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1982\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1982 - val_loss: 0.3148 - lr: 6.6342e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1913\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1913 - val_loss: 0.1993 - lr: 6.3025e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1926\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1926 - val_loss: 0.2285 - lr: 5.9874e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1982\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1982 - val_loss: 0.2116 - lr: 5.6880e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1915\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1915 - val_loss: 0.1965 - lr: 5.4036e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2094\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2094 - val_loss: 0.2602 - lr: 5.1334e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1927\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1927 - val_loss: 0.2246 - lr: 4.8767e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1826\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1826 - val_loss: 0.2755 - lr: 4.6329e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1904\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 414ms/step - loss: 0.1904 - val_loss: 0.2013 - lr: 4.4013e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1696\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1696 - val_loss: 0.2539 - lr: 4.1812e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1764\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1764 - val_loss: 0.2312 - lr: 3.9721e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1695\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.1695 - val_loss: 0.2229 - lr: 3.7735e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1768\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1768 - val_loss: 0.2252 - lr: 3.5849e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1734\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1734 - val_loss: 0.2211 - lr: 3.4056e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1696\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1696 - val_loss: 0.2279 - lr: 3.2353e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1675\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1675 - val_loss: 0.2133 - lr: 3.0736e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1572\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1572 - val_loss: 0.2073 - lr: 2.9199e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1599\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1599 - val_loss: 0.2181 - lr: 2.7739e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1563\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1563 - val_loss: 0.2236 - lr: 2.6352e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1618\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.1618 - val_loss: 0.2258 - lr: 2.5034e-04\n",
      "Epoch 38: early stopping\n",
      "2/2 [==============================] - 6s 129ms/step\n",
      "0.2383, 0.1841, 0.2894\n",
      "______fold 2______, ________repeat 1__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 767ms/step - loss: 0.5122 - val_loss: 0.4585 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.4605 - val_loss: 0.4492 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 412ms/step - loss: 0.4539 - val_loss: 0.4424 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.4385 - val_loss: 0.4277 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.4251 - val_loss: 0.4213 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.3817 - val_loss: 0.4006 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.3465 - val_loss: 0.3768 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.3148 - val_loss: 0.3229 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2918\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 6s 359ms/step - loss: 0.2918 - val_loss: 0.3818 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2965\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2965 - val_loss: 0.4291 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2623\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.2623 - val_loss: 0.3720 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2712\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2712 - val_loss: 0.4103 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2572\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2572 - val_loss: 0.3662 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2483\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.2483 - val_loss: 0.3934 - lr: 7.7378e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2518\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 6s 357ms/step - loss: 0.2518 - val_loss: 0.3587 - lr: 7.3509e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2543 - val_loss: 0.3074 - lr: 6.9834e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2444\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2444 - val_loss: 0.3244 - lr: 6.9834e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2274\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 8s 471ms/step - loss: 0.2274 - val_loss: 0.3131 - lr: 6.6342e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2164\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.2164 - val_loss: 0.3533 - lr: 6.3025e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2101 - val_loss: 0.2658 - lr: 5.9874e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2155\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2155 - val_loss: 0.3346 - lr: 5.9874e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1989\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1989 - val_loss: 0.3277 - lr: 5.6880e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1950\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1950 - val_loss: 0.2871 - lr: 5.4036e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2067\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2067 - val_loss: 0.3421 - lr: 5.1334e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2202\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2202 - val_loss: 0.2867 - lr: 4.8767e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1981\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1981 - val_loss: 0.3249 - lr: 4.6329e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2024\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.2024 - val_loss: 0.3056 - lr: 4.4013e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1907\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1907 - val_loss: 0.2926 - lr: 4.1812e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1958\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1958 - val_loss: 0.3033 - lr: 3.9721e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1963 - val_loss: 0.2334 - lr: 3.7735e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1913\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 6s 358ms/step - loss: 0.1913 - val_loss: 0.2690 - lr: 3.7735e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1820\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 6s 358ms/step - loss: 0.1820 - val_loss: 0.2572 - lr: 3.5849e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1784\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1784 - val_loss: 0.3003 - lr: 3.4056e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1783\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1783 - val_loss: 0.2706 - lr: 3.2353e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1795\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1795 - val_loss: 0.2953 - lr: 3.0736e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1849\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1849 - val_loss: 0.2738 - lr: 2.9199e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1704\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.1704 - val_loss: 0.3192 - lr: 2.7739e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1830\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 6s 357ms/step - loss: 0.1830 - val_loss: 0.2891 - lr: 2.6352e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1844\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 6s 359ms/step - loss: 0.1844 - val_loss: 0.2600 - lr: 2.5034e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1944\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.1944 - val_loss: 0.2745 - lr: 2.3783e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1679\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1679 - val_loss: 0.2514 - lr: 2.2594e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1653\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1653 - val_loss: 0.2676 - lr: 2.1464e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1863\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1863 - val_loss: 0.2685 - lr: 2.0391e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1603\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1603 - val_loss: 0.2805 - lr: 1.9371e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1591\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1591 - val_loss: 0.2664 - lr: 1.8403e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1677\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1677 - val_loss: 0.2678 - lr: 1.7482e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1586\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1586 - val_loss: 0.2763 - lr: 1.6608e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1651\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1651 - val_loss: 0.2652 - lr: 1.5778e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1566\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1566 - val_loss: 0.2703 - lr: 1.4989e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1507\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1507 - val_loss: 0.2798 - lr: 1.4240e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1545\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1545 - val_loss: 0.2542 - lr: 1.3528e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1665\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1665 - val_loss: 0.2645 - lr: 1.2851e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1508\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1508 - val_loss: 0.2698 - lr: 1.2209e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1654\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1654 - val_loss: 0.2582 - lr: 1.1598e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1678\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 30.\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.1678 - val_loss: 0.2561 - lr: 1.1018e-04\n",
      "Epoch 55: early stopping\n",
      "2/2 [==============================] - 7s 129ms/step\n",
      "0.1963, 0.2334, 0.4139\n",
      "______fold 2______, ________repeat 2__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 834ms/step - loss: 0.4883 - val_loss: 0.4665 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 442ms/step - loss: 0.4590 - val_loss: 0.4571 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.4573 - val_loss: 0.4412 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.4441 - val_loss: 0.4236 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4167\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.4167 - val_loss: 0.4260 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.3882 - val_loss: 0.4210 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.3650 - val_loss: 0.4004 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.3515 - val_loss: 0.3666 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3288\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.3288 - val_loss: 0.4484 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3439\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.3439 - val_loss: 0.4363 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2724 - val_loss: 0.3401 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2697\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2697 - val_loss: 0.3919 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2691\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 6s 358ms/step - loss: 0.2691 - val_loss: 0.3554 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2700 - val_loss: 0.3376 - lr: 7.7378e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2378 - val_loss: 0.3211 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2294 - val_loss: 0.3124 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.2483 - val_loss: 0.2822 - lr: 7.7378e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2292\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2292 - val_loss: 0.2967 - lr: 7.7378e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2047 - val_loss: 0.2781 - lr: 7.3509e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2084\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2084 - val_loss: 0.2933 - lr: 7.3509e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2218\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2218 - val_loss: 0.3068 - lr: 6.9834e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2033\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 8s 430ms/step - loss: 0.2033 - val_loss: 0.2953 - lr: 6.6342e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1958 - val_loss: 0.2657 - lr: 6.3025e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2211\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2211 - val_loss: 0.3100 - lr: 6.3025e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1885\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1885 - val_loss: 0.2942 - lr: 5.9874e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1883\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1883 - val_loss: 0.2728 - lr: 5.6880e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1928\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1928 - val_loss: 0.3166 - lr: 5.4036e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1783\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1783 - val_loss: 0.3052 - lr: 5.1334e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1719\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1719 - val_loss: 0.2871 - lr: 4.8767e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1696\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1696 - val_loss: 0.2830 - lr: 4.6329e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1800\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1800 - val_loss: 0.2990 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1704\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1704 - val_loss: 0.2790 - lr: 4.1812e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1762\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1762 - val_loss: 0.3127 - lr: 3.9721e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1476\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1476 - val_loss: 0.2940 - lr: 3.7735e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1634\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1634 - val_loss: 0.2987 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1601\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1601 - val_loss: 0.3206 - lr: 3.4056e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1808\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1808 - val_loss: 0.2725 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1557\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1557 - val_loss: 0.2822 - lr: 3.0736e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1664\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1664 - val_loss: 0.3003 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1534\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1534 - val_loss: 0.2908 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1656\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1656 - val_loss: 0.2796 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1808\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1808 - val_loss: 0.2869 - lr: 2.5034e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1630\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1630 - val_loss: 0.2821 - lr: 2.3783e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1490\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1490 - val_loss: 0.2708 - lr: 2.2594e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1493\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1493 - val_loss: 0.2838 - lr: 2.1464e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1319\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.1319 - val_loss: 0.2940 - lr: 2.0391e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1405\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 6s 359ms/step - loss: 0.1405 - val_loss: 0.2824 - lr: 1.9371e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1520\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1520 - val_loss: 0.2780 - lr: 1.8403e-04\n",
      "Epoch 48: early stopping\n",
      "2/2 [==============================] - 6s 116ms/step\n",
      "0.1958, 0.2657, 0.4936\n",
      "______fold 2______, ________repeat 3__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 766ms/step - loss: 0.4722 - val_loss: 0.4403 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.4445 - val_loss: 0.4243 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 8s 434ms/step - loss: 0.4200 - val_loss: 0.4117 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.3903 - val_loss: 0.3881 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3557\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3557 - val_loss: 0.4142 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.3307 - val_loss: 0.3547 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.3150 - val_loss: 0.3394 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.3180 - val_loss: 0.3336 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2935\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2935 - val_loss: 0.4033 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2984\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2984 - val_loss: 0.3573 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2606 - val_loss: 0.2942 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 8s 453ms/step - loss: 0.2617 - val_loss: 0.2831 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2484\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2484 - val_loss: 0.2973 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2434\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.2434 - val_loss: 0.2863 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2086 - val_loss: 0.2730 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2320 - val_loss: 0.2565 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2058\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2058 - val_loss: 0.2676 - lr: 7.7378e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2257\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2257 - val_loss: 0.2739 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2134\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2134 - val_loss: 0.2762 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2102\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2102 - val_loss: 0.2582 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2055\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2055 - val_loss: 0.2715 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1937\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1937 - val_loss: 0.3141 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1847\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1847 - val_loss: 0.2707 - lr: 5.6880e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1993\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1993 - val_loss: 0.2581 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1923\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1923 - val_loss: 0.2687 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1832\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1832 - val_loss: 0.2648 - lr: 4.8767e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.1741 - val_loss: 0.2548 - lr: 4.6329e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1830\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 417ms/step - loss: 0.1830 - val_loss: 0.2678 - lr: 4.6329e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1711\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.1711 - val_loss: 0.2751 - lr: 4.4013e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1785\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 8s 472ms/step - loss: 0.1785 - val_loss: 0.2666 - lr: 4.1812e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1747\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 413ms/step - loss: 0.1747 - val_loss: 0.2742 - lr: 3.9721e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1822\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1822 - val_loss: 0.2712 - lr: 3.7735e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1725\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1725 - val_loss: 0.2757 - lr: 3.5849e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1591\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1591 - val_loss: 0.2711 - lr: 3.4056e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1642\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1642 - val_loss: 0.2717 - lr: 3.2353e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1543\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.1543 - val_loss: 0.2735 - lr: 3.0736e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1540\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1540 - val_loss: 0.2757 - lr: 2.9199e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1741\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1741 - val_loss: 0.2814 - lr: 2.7739e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1618\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1618 - val_loss: 0.2723 - lr: 2.6352e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1736\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1736 - val_loss: 0.2742 - lr: 2.5034e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1609\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1609 - val_loss: 0.2783 - lr: 2.3783e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1516\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1516 - val_loss: 0.2718 - lr: 2.2594e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1511\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1511 - val_loss: 0.2635 - lr: 2.1464e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1636\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.1636 - val_loss: 0.2564 - lr: 2.0391e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1520\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1520 - val_loss: 0.2621 - lr: 1.9371e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1545\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1545 - val_loss: 0.2634 - lr: 1.8403e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1528\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1528 - val_loss: 0.2631 - lr: 1.7482e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1417\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1417 - val_loss: 0.2661 - lr: 1.6608e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1568\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1568 - val_loss: 0.2677 - lr: 1.5778e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1477\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1477 - val_loss: 0.2701 - lr: 1.4989e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1704\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1704 - val_loss: 0.2681 - lr: 1.4240e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1576\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1576 - val_loss: 0.2728 - lr: 1.3528e-04\n",
      "Epoch 52: early stopping\n",
      "2/2 [==============================] - 6s 135ms/step\n",
      "0.1741, 0.2548, 0.4638\n",
      "______fold 2______, ________repeat 4__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 818ms/step - loss: 0.4796 - val_loss: 0.4415 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.4449 - val_loss: 0.4207 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.4441 - val_loss: 0.4118 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.4090 - val_loss: 0.3901 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3865\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.3865 - val_loss: 0.3999 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3507\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.3507 - val_loss: 0.4307 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3249\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.3249 - val_loss: 0.4161 - lr: 9.0250e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3174 - val_loss: 0.3556 - lr: 8.5737e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.2910 - val_loss: 0.3405 - lr: 8.5737e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2983\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 415ms/step - loss: 0.2983 - val_loss: 0.3676 - lr: 8.5737e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2769\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2769 - val_loss: 0.3479 - lr: 8.1451e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2558 - val_loss: 0.3276 - lr: 7.7378e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2705\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2705 - val_loss: 0.3559 - lr: 7.7378e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2668\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2668 - val_loss: 0.3732 - lr: 7.3509e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2640\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2640 - val_loss: 0.3510 - lr: 6.9834e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2570 - val_loss: 0.2551 - lr: 6.6342e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2444\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2444 - val_loss: 0.2703 - lr: 6.6342e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2335\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2335 - val_loss: 0.3122 - lr: 6.3025e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2170\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2170 - val_loss: 0.2668 - lr: 5.9874e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2001\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2001 - val_loss: 0.2656 - lr: 5.6880e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2190\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2190 - val_loss: 0.2877 - lr: 5.4036e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2070\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2070 - val_loss: 0.2767 - lr: 5.1334e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1978\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1978 - val_loss: 0.2770 - lr: 4.8767e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2017\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2017 - val_loss: 0.2715 - lr: 4.6329e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1864\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1864 - val_loss: 0.2681 - lr: 4.4013e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1922\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1922 - val_loss: 0.2793 - lr: 4.1812e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1954\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1954 - val_loss: 0.2674 - lr: 3.9721e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1878\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1878 - val_loss: 0.2939 - lr: 3.7735e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1978\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1978 - val_loss: 0.2879 - lr: 3.5849e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.1787 - val_loss: 0.2549 - lr: 3.4056e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.1886 - val_loss: 0.2539 - lr: 3.4056e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.1816 - val_loss: 0.2369 - lr: 3.4056e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1890\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1890 - val_loss: 0.2742 - lr: 3.4056e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1762\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1762 - val_loss: 0.2551 - lr: 3.2353e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.1804 - val_loss: 0.2318 - lr: 3.0736e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1690 - val_loss: 0.2280 - lr: 3.0736e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1797 - val_loss: 0.2194 - lr: 3.0736e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1627\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1627 - val_loss: 0.2323 - lr: 3.0736e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1724\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1724 - val_loss: 0.2233 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1679\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1679 - val_loss: 0.2375 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1604\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1604 - val_loss: 0.2313 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1638\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1638 - val_loss: 0.2296 - lr: 2.5034e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1553 - val_loss: 0.2140 - lr: 2.3783e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1601\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1601 - val_loss: 0.2288 - lr: 2.3783e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1753\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1753 - val_loss: 0.2385 - lr: 2.2594e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1695\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1695 - val_loss: 0.2351 - lr: 2.1464e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1593\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1593 - val_loss: 0.2227 - lr: 2.0391e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1522 - val_loss: 0.2122 - lr: 1.9371e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1677 - val_loss: 0.2085 - lr: 1.9371e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1636\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1636 - val_loss: 0.2100 - lr: 1.9371e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1615 - val_loss: 0.1985 - lr: 1.8403e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1682\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1682 - val_loss: 0.2077 - lr: 1.8403e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1575 - val_loss: 0.1860 - lr: 1.7482e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1493\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1493 - val_loss: 0.1908 - lr: 1.7482e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1465\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1465 - val_loss: 0.1915 - lr: 1.6608e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1566\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1566 - val_loss: 0.1988 - lr: 1.5778e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1638\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1638 - val_loss: 0.1891 - lr: 1.4989e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1579 - val_loss: 0.1826 - lr: 1.4240e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1543\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1543 - val_loss: 0.1911 - lr: 1.4240e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1550\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1550 - val_loss: 0.1925 - lr: 1.3528e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1483\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1483 - val_loss: 0.1901 - lr: 1.2851e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1439\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1439 - val_loss: 0.1982 - lr: 1.2209e-04\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1531\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1531 - val_loss: 0.1853 - lr: 1.1598e-04\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1607\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1607 - val_loss: 0.1858 - lr: 1.1018e-04\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1430\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1430 - val_loss: 0.1923 - lr: 1.0467e-04\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1568\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1568 - val_loss: 0.1886 - lr: 9.9440e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1433\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1433 - val_loss: 0.1906 - lr: 9.4468e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1438\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1438 - val_loss: 0.1862 - lr: 8.9745e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.1388 - val_loss: 0.1810 - lr: 8.5258e-05\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1496 - val_loss: 0.1776 - lr: 8.5258e-05\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1487\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1487 - val_loss: 0.1820 - lr: 8.5258e-05\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1425\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1425 - val_loss: 0.1870 - lr: 8.0995e-05\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1380\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1380 - val_loss: 0.1872 - lr: 7.6945e-05\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1450\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1450 - val_loss: 0.1844 - lr: 7.3098e-05\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1423\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1423 - val_loss: 0.1808 - lr: 6.9443e-05\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1463\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1463 - val_loss: 0.1789 - lr: 6.5971e-05\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1420\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1420 - val_loss: 0.1804 - lr: 6.2672e-05\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1376\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 5.656161210936261e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1376 - val_loss: 0.1864 - lr: 5.9539e-05\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1404\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 5.373353305913042e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1404 - val_loss: 0.1878 - lr: 5.6562e-05\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1380\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 5.104685606056591e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1380 - val_loss: 0.1858 - lr: 5.3734e-05\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1355\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 4.849451343034161e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1355 - val_loss: 0.1862 - lr: 5.1047e-05\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1480\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 4.606978654919658e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1480 - val_loss: 0.1814 - lr: 4.8495e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1425\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 4.3766295493696814e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1425 - val_loss: 0.1836 - lr: 4.6070e-05\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1402\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 4.1577981755835934e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1402 - val_loss: 0.1861 - lr: 4.3766e-05\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1386\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 3.949908405047608e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1386 - val_loss: 0.1890 - lr: 4.1578e-05\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1414\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 3.752413140318822e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1414 - val_loss: 0.1896 - lr: 3.9499e-05\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1429\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 3.564792586985277e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1429 - val_loss: 0.1815 - lr: 3.7524e-05\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1397\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 3.3865528712340166e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1397 - val_loss: 0.1796 - lr: 3.5648e-05\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1394\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 3.217225348635111e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1394 - val_loss: 0.1788 - lr: 3.3866e-05\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1320\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 3.0563641848857516e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1320 - val_loss: 0.1795 - lr: 3.2172e-05\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1270\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 2.9035460102022626e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1270 - val_loss: 0.1791 - lr: 3.0564e-05\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1428 - val_loss: 0.1767 - lr: 2.9035e-05\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1409 - val_loss: 0.1752 - lr: 2.9035e-05\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1359\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 2.7583687096921494e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1359 - val_loss: 0.1769 - lr: 2.9035e-05\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1316\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 2.620450213726144e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1316 - val_loss: 0.1774 - lr: 2.7584e-05\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1451\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 2.4894276339182395e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1451 - val_loss: 0.1754 - lr: 2.6205e-05\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1293 - val_loss: 0.1735 - lr: 2.4894e-05\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1408\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 2.3649562263017287e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1408 - val_loss: 0.1752 - lr: 2.4894e-05\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1327\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 2.2467083545052444e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1327 - val_loss: 0.1768 - lr: 2.3650e-05\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1304\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 2.134372971340781e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1304 - val_loss: 0.1781 - lr: 2.2467e-05\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1302\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 2.0276544091757387e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1302 - val_loss: 0.1760 - lr: 2.1344e-05\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1289\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 1.9262716887169517e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1289 - val_loss: 0.1753 - lr: 2.0277e-05\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1222 - val_loss: 0.1722 - lr: 1.9263e-05\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1359\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 1.8299581734027014e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1359 - val_loss: 0.1741 - lr: 1.9263e-05\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1405\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 1.7384601869707693e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1405 - val_loss: 0.1755 - lr: 1.8300e-05\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1396\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 1.6515371862624305e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1396 - val_loss: 0.1755 - lr: 1.7385e-05\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1367\n",
      "Epoch 107: ReduceLROnPlateau reducing learning rate to 1.568960378790507e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1367 - val_loss: 0.1753 - lr: 1.6515e-05\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1374\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 1.490512377131381e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1374 - val_loss: 0.1744 - lr: 1.5690e-05\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1403\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 1.4159867669150115e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1403 - val_loss: 0.1731 - lr: 1.4905e-05\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1364\n",
      "Epoch 110: ReduceLROnPlateau reducing learning rate to 1.3451874156089615e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1364 - val_loss: 0.1744 - lr: 1.4160e-05\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1427\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 1.2779280405084136e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1427 - val_loss: 0.1752 - lr: 1.3452e-05\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1440\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 1.2140316039221942e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1440 - val_loss: 0.1741 - lr: 1.2779e-05\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1337\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 1.1533300539667834e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1337 - val_loss: 0.1729 - lr: 1.2140e-05\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1288\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 1.0956635469483444e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1288 - val_loss: 0.1727 - lr: 1.1533e-05\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1412\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 1.0408803609607275e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1412 - val_loss: 0.1728 - lr: 1.0957e-05\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1431\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 9.888363774734898e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1431 - val_loss: 0.1737 - lr: 1.0409e-05\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1348\n",
      "Epoch 117: ReduceLROnPlateau reducing learning rate to 9.393945629199151e-06.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1348 - val_loss: 0.1734 - lr: 9.8884e-06\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1403\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 8.92424795893021e-06.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1403 - val_loss: 0.1729 - lr: 9.3939e-06\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1340\n",
      "Epoch 119: ReduceLROnPlateau reducing learning rate to 8.478035215375711e-06.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1340 - val_loss: 0.1729 - lr: 8.9242e-06\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1199\n",
      "Epoch 120: ReduceLROnPlateau reducing learning rate to 8.054133195400936e-06.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1199 - val_loss: 0.1732 - lr: 8.4780e-06\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1303\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 7.651426449228893e-06.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1303 - val_loss: 0.1729 - lr: 8.0541e-06\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1312\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 7.2688548243604595e-06.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1312 - val_loss: 0.1724 - lr: 7.6514e-06\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1353 - val_loss: 0.1718 - lr: 7.2689e-06\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1402\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 6.905412169544433e-06.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1402 - val_loss: 0.1719 - lr: 7.2689e-06\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1316\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 6.5601415826677105e-06.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1316 - val_loss: 0.1724 - lr: 6.9054e-06\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1372\n",
      "Epoch 126: ReduceLROnPlateau reducing learning rate to 6.2321345467353235e-06.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1372 - val_loss: 0.1720 - lr: 6.5601e-06\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1476\n",
      "Epoch 127: ReduceLROnPlateau reducing learning rate to 5.920527905800554e-06.\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1476 - val_loss: 0.1718 - lr: 6.2321e-06\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 8s 435ms/step - loss: 0.1303 - val_loss: 0.1712 - lr: 5.9205e-06\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 8s 435ms/step - loss: 0.1439 - val_loss: 0.1707 - lr: 5.9205e-06\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1380\n",
      "Epoch 130: ReduceLROnPlateau reducing learning rate to 5.624501704915019e-06.\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.1380 - val_loss: 0.1707 - lr: 5.9205e-06\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.1290 - val_loss: 0.1705 - lr: 5.6245e-06\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1300\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 5.343276598068769e-06.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.1300 - val_loss: 0.1708 - lr: 5.6245e-06\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1349\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 5.076112984170322e-06.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1349 - val_loss: 0.1705 - lr: 5.3433e-06\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1390\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 4.8223071189568145e-06.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1390 - val_loss: 0.1705 - lr: 5.0761e-06\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1297 - val_loss: 0.1704 - lr: 4.8223e-06\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.1448 - val_loss: 0.1703 - lr: 4.8223e-06\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1368\n",
      "Epoch 137: ReduceLROnPlateau reducing learning rate to 4.581191979013965e-06.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1368 - val_loss: 0.1706 - lr: 4.8223e-06\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1239\n",
      "Epoch 138: ReduceLROnPlateau reducing learning rate to 4.352132509666262e-06.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1239 - val_loss: 0.1708 - lr: 4.5812e-06\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1336\n",
      "Epoch 139: ReduceLROnPlateau reducing learning rate to 4.134526056986942e-06.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1336 - val_loss: 0.1712 - lr: 4.3521e-06\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1409\n",
      "Epoch 140: ReduceLROnPlateau reducing learning rate to 3.927799775738094e-06.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1409 - val_loss: 0.1714 - lr: 4.1345e-06\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1372\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 3.7314097653506904e-06.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1372 - val_loss: 0.1715 - lr: 3.9278e-06\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1529\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 3.5448393418846533e-06.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1529 - val_loss: 0.1711 - lr: 3.7314e-06\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1289\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 3.3675973099889233e-06.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1289 - val_loss: 0.1713 - lr: 3.5448e-06\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1526\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 3.199217530891474e-06.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1526 - val_loss: 0.1711 - lr: 3.3676e-06\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1289\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 3.039256762349396e-06.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1289 - val_loss: 0.1713 - lr: 3.1992e-06\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1254\n",
      "Epoch 146: ReduceLROnPlateau reducing learning rate to 2.887294010633923e-06.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1254 - val_loss: 0.1711 - lr: 3.0393e-06\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1349\n",
      "Epoch 147: ReduceLROnPlateau reducing learning rate to 2.7429292345004796e-06.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1349 - val_loss: 0.1711 - lr: 2.8873e-06\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1390\n",
      "Epoch 148: ReduceLROnPlateau reducing learning rate to 2.6057826971737086e-06.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1390 - val_loss: 0.1711 - lr: 2.7429e-06\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1389\n",
      "Epoch 149: ReduceLROnPlateau reducing learning rate to 2.4754936703175187e-06.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1389 - val_loss: 0.1710 - lr: 2.6058e-06\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1378\n",
      "Epoch 150: ReduceLROnPlateau reducing learning rate to 2.3517189220001454e-06.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1378 - val_loss: 0.1713 - lr: 2.4755e-06\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1264\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 2.2341329326991397e-06.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1264 - val_loss: 0.1714 - lr: 2.3517e-06\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1491\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 2.122426383266429e-06.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1491 - val_loss: 0.1716 - lr: 2.2341e-06\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1392\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 2.0163050749033573e-06.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1392 - val_loss: 0.1716 - lr: 2.1224e-06\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1382\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 1.915489929160685e-06.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1382 - val_loss: 0.1716 - lr: 2.0163e-06\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1338\n",
      "Epoch 155: ReduceLROnPlateau reducing learning rate to 1.8197154759036493e-06.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1338 - val_loss: 0.1717 - lr: 1.9155e-06\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1368\n",
      "Epoch 156: ReduceLROnPlateau reducing learning rate to 1.728729745309465e-06.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1368 - val_loss: 0.1719 - lr: 1.8197e-06\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1467\n",
      "Epoch 157: ReduceLROnPlateau reducing learning rate to 1.6422932958448655e-06.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1467 - val_loss: 0.1719 - lr: 1.7287e-06\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1466\n",
      "Epoch 158: ReduceLROnPlateau reducing learning rate to 1.5601786742536206e-06.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1466 - val_loss: 0.1719 - lr: 1.6423e-06\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1474\n",
      "Epoch 159: ReduceLROnPlateau reducing learning rate to 1.4821697675415633e-06.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1474 - val_loss: 0.1721 - lr: 1.5602e-06\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1427\n",
      "Epoch 160: ReduceLROnPlateau reducing learning rate to 1.408061262964111e-06.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1427 - val_loss: 0.1720 - lr: 1.4822e-06\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1299\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.3376582160162797e-06.\n",
      "Restoring model weights from the end of the best epoch: 136.\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1299 - val_loss: 0.1722 - lr: 1.4081e-06\n",
      "Epoch 161: early stopping\n",
      "2/2 [==============================] - 6s 120ms/step\n",
      "0.1448, 0.1703, 0.3375\n",
      "______fold 2______, ________repeat 5__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 863ms/step - loss: 0.4887 - val_loss: 0.4521 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 412ms/step - loss: 0.4417 - val_loss: 0.4214 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.4141 - val_loss: 0.4017 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 8s 434ms/step - loss: 0.3860 - val_loss: 0.3743 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 8s 431ms/step - loss: 0.3575 - val_loss: 0.3732 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 412ms/step - loss: 0.3357 - val_loss: 0.3574 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3267\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 8s 421ms/step - loss: 0.3267 - val_loss: 0.3770 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.3154 - val_loss: 0.3411 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.2942 - val_loss: 0.3388 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.2789 - val_loss: 0.3215 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2697\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2697 - val_loss: 0.3375 - lr: 9.5000e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2530\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2530 - val_loss: 0.3337 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2440\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2440 - val_loss: 0.3567 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2490\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2490 - val_loss: 0.3513 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2314\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2314 - val_loss: 0.3383 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2550\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2550 - val_loss: 0.3369 - lr: 7.3509e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2522 - val_loss: 0.3042 - lr: 6.9834e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2191\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2191 - val_loss: 0.3495 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2242\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2242 - val_loss: 0.3111 - lr: 6.6342e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2029\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2029 - val_loss: 0.3267 - lr: 6.3025e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2214\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2214 - val_loss: 0.3402 - lr: 5.9874e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2079 - val_loss: 0.2904 - lr: 5.6880e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2067 - val_loss: 0.2852 - lr: 5.6880e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2120\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2120 - val_loss: 0.3123 - lr: 5.6880e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1894\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1894 - val_loss: 0.2978 - lr: 5.4036e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1956 - val_loss: 0.2691 - lr: 5.1334e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1913\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1913 - val_loss: 0.2727 - lr: 5.1334e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1902\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1902 - val_loss: 0.2775 - lr: 4.8767e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1764 - val_loss: 0.2596 - lr: 4.6329e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1739\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1739 - val_loss: 0.2978 - lr: 4.6329e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1668 - val_loss: 0.2537 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1914\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1914 - val_loss: 0.2667 - lr: 4.4013e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1732\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1732 - val_loss: 0.2854 - lr: 4.1812e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1598\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1598 - val_loss: 0.2716 - lr: 3.9721e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1913\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1913 - val_loss: 0.2565 - lr: 3.7735e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1639 - val_loss: 0.2530 - lr: 3.5849e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1656\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1656 - val_loss: 0.2656 - lr: 3.5849e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1577\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1577 - val_loss: 0.2671 - lr: 3.4056e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1726\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1726 - val_loss: 0.2680 - lr: 3.2353e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1538\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1538 - val_loss: 0.2666 - lr: 3.0736e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1501\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1501 - val_loss: 0.2889 - lr: 2.9199e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1683 - val_loss: 0.2396 - lr: 2.7739e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1667\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1667 - val_loss: 0.2510 - lr: 2.7739e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1516\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1516 - val_loss: 0.2508 - lr: 2.6352e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1647 - val_loss: 0.2339 - lr: 2.5034e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1520\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1520 - val_loss: 0.2525 - lr: 2.5034e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1564\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1564 - val_loss: 0.2426 - lr: 2.3783e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1676\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1676 - val_loss: 0.2474 - lr: 2.2594e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1465\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1465 - val_loss: 0.2580 - lr: 2.1464e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1461\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1461 - val_loss: 0.2504 - lr: 2.0391e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1416\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1416 - val_loss: 0.2622 - lr: 1.9371e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1510\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1510 - val_loss: 0.2690 - lr: 1.8403e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1547\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1547 - val_loss: 0.2514 - lr: 1.7482e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1361\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1361 - val_loss: 0.2567 - lr: 1.6608e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1392\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1392 - val_loss: 0.2540 - lr: 1.5778e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1383\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1383 - val_loss: 0.2583 - lr: 1.4989e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1455\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1455 - val_loss: 0.2524 - lr: 1.4240e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1379\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1379 - val_loss: 0.2546 - lr: 1.3528e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1306\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1306 - val_loss: 0.2531 - lr: 1.2851e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1440\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1440 - val_loss: 0.2481 - lr: 1.2209e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1447\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1447 - val_loss: 0.2439 - lr: 1.1598e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1310\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1310 - val_loss: 0.2560 - lr: 1.1018e-04\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1375\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1375 - val_loss: 0.2553 - lr: 1.0467e-04\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1460\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1460 - val_loss: 0.2483 - lr: 9.9440e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1393\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1393 - val_loss: 0.2512 - lr: 9.4468e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1427\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1427 - val_loss: 0.2480 - lr: 8.9745e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1186\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1186 - val_loss: 0.2518 - lr: 8.5258e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1185\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1185 - val_loss: 0.2428 - lr: 8.0995e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1254\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1254 - val_loss: 0.2445 - lr: 7.6945e-05\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1307\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "18/18 [==============================] - 7s 418ms/step - loss: 0.1307 - val_loss: 0.2407 - lr: 7.3098e-05\n",
      "Epoch 70: early stopping\n",
      "2/2 [==============================] - 6s 128ms/step\n",
      "0.1647, 0.2339, 0.4238\n",
      "______fold 2______, ________repeat 6__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 821ms/step - loss: 0.4969 - val_loss: 0.4663 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.4626 - val_loss: 0.4614 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.4576 - val_loss: 0.4517 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.4461 - val_loss: 0.4380 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.4330 - val_loss: 0.4186 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3947\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.3947 - val_loss: 0.4259 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.3628 - val_loss: 0.4002 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.3656 - val_loss: 0.3971 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3395\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.3395 - val_loss: 0.4281 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3265\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.3265 - val_loss: 0.4229 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.3037 - val_loss: 0.3909 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2897 - val_loss: 0.3197 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2936\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2936 - val_loss: 0.3580 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2781\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2781 - val_loss: 0.3968 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2790\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2790 - val_loss: 0.3746 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2651 - val_loss: 0.2640 - lr: 7.3509e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2449 - val_loss: 0.2605 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2405\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2405 - val_loss: 0.2741 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2328\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2328 - val_loss: 0.3681 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2210 - val_loss: 0.2408 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2208\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2208 - val_loss: 0.2663 - lr: 6.6342e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2114\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2114 - val_loss: 0.2411 - lr: 6.3025e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2112\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2112 - val_loss: 0.2737 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2215\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2215 - val_loss: 0.3239 - lr: 5.6880e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1871\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1871 - val_loss: 0.2434 - lr: 5.4036e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1994\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1994 - val_loss: 0.2656 - lr: 5.1334e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2060 - val_loss: 0.2283 - lr: 4.8767e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1938\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1938 - val_loss: 0.2522 - lr: 4.8767e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2061\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2061 - val_loss: 0.2556 - lr: 4.6329e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1987\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1987 - val_loss: 0.2312 - lr: 4.4013e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1929\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1929 - val_loss: 0.2551 - lr: 4.1812e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1758\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1758 - val_loss: 0.2509 - lr: 3.9721e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1802\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1802 - val_loss: 0.2710 - lr: 3.7735e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1805\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1805 - val_loss: 0.2566 - lr: 3.5849e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1748\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1748 - val_loss: 0.2626 - lr: 3.4056e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1827\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1827 - val_loss: 0.2381 - lr: 3.2353e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1858\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1858 - val_loss: 0.2333 - lr: 3.0736e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1698\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1698 - val_loss: 0.2383 - lr: 2.9199e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1655\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1655 - val_loss: 0.2472 - lr: 2.7739e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1753\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1753 - val_loss: 0.2367 - lr: 2.6352e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1585\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1585 - val_loss: 0.2398 - lr: 2.5034e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1706\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1706 - val_loss: 0.2383 - lr: 2.3783e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1622\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1622 - val_loss: 0.2342 - lr: 2.2594e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1742\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1742 - val_loss: 0.2445 - lr: 2.1464e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1665\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1665 - val_loss: 0.2422 - lr: 2.0391e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1534\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1534 - val_loss: 0.2681 - lr: 1.9371e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1716\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1716 - val_loss: 0.2373 - lr: 1.8403e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1589\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1589 - val_loss: 0.2461 - lr: 1.7482e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1609\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1609 - val_loss: 0.2418 - lr: 1.6608e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1655\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1655 - val_loss: 0.2506 - lr: 1.5778e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1642\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1642 - val_loss: 0.2440 - lr: 1.4989e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1686\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.1686 - val_loss: 0.2345 - lr: 1.4240e-04\n",
      "Epoch 52: early stopping\n",
      "2/2 [==============================] - 6s 128ms/step\n",
      "0.2060, 0.2283, 0.4254\n",
      "______fold 2______, ________repeat 7__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 817ms/step - loss: 0.5296 - val_loss: 0.4670 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 414ms/step - loss: 0.4617 - val_loss: 0.4528 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.4559 - val_loss: 0.4306 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.4468 - val_loss: 0.4087 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.4323 - val_loss: 0.3999 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.4154 - val_loss: 0.3746 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.4009 - val_loss: 0.3613 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3700\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.3700 - val_loss: 0.4296 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.3309 - val_loss: 0.3353 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2942\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 8s 422ms/step - loss: 0.2942 - val_loss: 0.3831 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3018\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 8s 422ms/step - loss: 0.3018 - val_loss: 0.3539 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2748\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 8s 422ms/step - loss: 0.2748 - val_loss: 0.3886 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2634\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.2634 - val_loss: 0.3736 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2636\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2636 - val_loss: 0.3476 - lr: 7.7378e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2397\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2397 - val_loss: 0.3604 - lr: 7.3509e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2608\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2608 - val_loss: 0.3656 - lr: 6.9834e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.2437 - val_loss: 0.3298 - lr: 6.6342e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2264\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.2264 - val_loss: 0.3706 - lr: 6.6342e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.2199 - val_loss: 0.3297 - lr: 6.3025e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2308\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2308 - val_loss: 0.3756 - lr: 6.3025e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2393 - val_loss: 0.3080 - lr: 5.9874e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2162\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2162 - val_loss: 0.3098 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2188\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2188 - val_loss: 0.3092 - lr: 5.6880e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2134\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2134 - val_loss: 0.3145 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2172\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2172 - val_loss: 0.3257 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1971\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1971 - val_loss: 0.3292 - lr: 4.8767e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1914\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1914 - val_loss: 0.3207 - lr: 4.6329e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1785\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1785 - val_loss: 0.3165 - lr: 4.4013e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1886\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1886 - val_loss: 0.3346 - lr: 4.1812e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1941 - val_loss: 0.3001 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1827\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 8s 418ms/step - loss: 0.1827 - val_loss: 0.3069 - lr: 3.9721e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1762\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1762 - val_loss: 0.3084 - lr: 3.7735e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1679\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1679 - val_loss: 0.3075 - lr: 3.5849e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1717\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1717 - val_loss: 0.3353 - lr: 3.4056e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1761\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1761 - val_loss: 0.3374 - lr: 3.2353e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1718\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1718 - val_loss: 0.3200 - lr: 3.0736e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1856 - val_loss: 0.2947 - lr: 2.9199e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1774\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1774 - val_loss: 0.3059 - lr: 2.9199e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1781\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1781 - val_loss: 0.3300 - lr: 2.7739e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1683\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1683 - val_loss: 0.3356 - lr: 2.6352e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1604\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1604 - val_loss: 0.3246 - lr: 2.5034e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1617\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1617 - val_loss: 0.3180 - lr: 2.3783e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1677\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1677 - val_loss: 0.3140 - lr: 2.2594e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1816\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1816 - val_loss: 0.3107 - lr: 2.1464e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1693\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1693 - val_loss: 0.3192 - lr: 2.0391e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1660\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1660 - val_loss: 0.3136 - lr: 1.9371e-04\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.1406\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1406 - val_loss: 0.3076 - lr: 1.8403e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1582\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1582 - val_loss: 0.3103 - lr: 1.7482e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1449\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1449 - val_loss: 0.3113 - lr: 1.6608e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1689\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1689 - val_loss: 0.2992 - lr: 1.5778e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1644\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1644 - val_loss: 0.3008 - lr: 1.4989e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1636\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1636 - val_loss: 0.3081 - lr: 1.4240e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1552\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1552 - val_loss: 0.2999 - lr: 1.3528e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1599 - val_loss: 0.2945 - lr: 1.2851e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1487 - val_loss: 0.2878 - lr: 1.2851e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1575 - val_loss: 0.2866 - lr: 1.2851e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1542\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1542 - val_loss: 0.2913 - lr: 1.2851e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1481\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1481 - val_loss: 0.2957 - lr: 1.2209e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1538\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1538 - val_loss: 0.3013 - lr: 1.1598e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1418\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1418 - val_loss: 0.3014 - lr: 1.1018e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1494\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1494 - val_loss: 0.3021 - lr: 1.0467e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1413\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1413 - val_loss: 0.3090 - lr: 9.9440e-05\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1414\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1414 - val_loss: 0.3026 - lr: 9.4468e-05\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1446\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1446 - val_loss: 0.2998 - lr: 8.9745e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1515\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1515 - val_loss: 0.3019 - lr: 8.5258e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1425\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1425 - val_loss: 0.3032 - lr: 8.0995e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1347\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1347 - val_loss: 0.2997 - lr: 7.6945e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1309\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1309 - val_loss: 0.2961 - lr: 7.3098e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1583\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1583 - val_loss: 0.2936 - lr: 6.9443e-05\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1505\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1505 - val_loss: 0.2956 - lr: 6.5971e-05\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1479\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1479 - val_loss: 0.2983 - lr: 6.2672e-05\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1515\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 5.656161210936261e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1515 - val_loss: 0.2964 - lr: 5.9539e-05\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1410\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 5.373353305913042e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1410 - val_loss: 0.2960 - lr: 5.6562e-05\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1333\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 5.104685606056591e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1333 - val_loss: 0.2953 - lr: 5.3734e-05\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1430\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 4.849451343034161e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1430 - val_loss: 0.2937 - lr: 5.1047e-05\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1354\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 4.606978654919658e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1354 - val_loss: 0.2950 - lr: 4.8495e-05\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1354\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 4.3766295493696814e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1354 - val_loss: 0.2975 - lr: 4.6070e-05\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1354\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 4.1577981755835934e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1354 - val_loss: 0.2997 - lr: 4.3766e-05\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1384\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 3.949908405047608e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1384 - val_loss: 0.2988 - lr: 4.1578e-05\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1355\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 3.752413140318822e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1355 - val_loss: 0.3000 - lr: 3.9499e-05\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1451\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.564792586985277e-05.\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1451 - val_loss: 0.2998 - lr: 3.7524e-05\n",
      "Epoch 81: early stopping\n",
      "2/2 [==============================] - 8s 134ms/step\n",
      "0.1575, 0.2866, 0.5559\n",
      "______fold 2______, ________repeat 8__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 819ms/step - loss: 0.4993 - val_loss: 0.4598 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.4537 - val_loss: 0.4300 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.4548 - val_loss: 0.4268 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.4211 - val_loss: 0.4068 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.4082 - val_loss: 0.3977 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 424ms/step - loss: 0.3766 - val_loss: 0.3659 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3547 - val_loss: 0.3192 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3422\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.3422 - val_loss: 0.4113 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3331\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.3331 - val_loss: 0.3716 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3333\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.3333 - val_loss: 0.3366 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2866 - val_loss: 0.2862 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2727\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2727 - val_loss: 0.2874 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2886\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2886 - val_loss: 0.3334 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2721\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2721 - val_loss: 0.3743 - lr: 7.7378e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2878\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2878 - val_loss: 0.3588 - lr: 7.3509e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.2859 - val_loss: 0.2835 - lr: 6.9834e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2553 - val_loss: 0.2756 - lr: 6.9834e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2470\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 418ms/step - loss: 0.2470 - val_loss: 0.2855 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2455\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2455 - val_loss: 0.3058 - lr: 6.6342e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2264 - val_loss: 0.2505 - lr: 6.3025e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2524\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2524 - val_loss: 0.2702 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2011\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2011 - val_loss: 0.2743 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2334\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2334 - val_loss: 0.2832 - lr: 5.6880e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2403\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2403 - val_loss: 0.2658 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2221\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2221 - val_loss: 0.2530 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2056\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2056 - val_loss: 0.2618 - lr: 4.8767e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2068\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2068 - val_loss: 0.2743 - lr: 4.6329e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2061\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2061 - val_loss: 0.2743 - lr: 4.4013e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2093\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2093 - val_loss: 0.2612 - lr: 4.1812e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1926\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1926 - val_loss: 0.2817 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2127 - val_loss: 0.2500 - lr: 3.7735e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1914 - val_loss: 0.2359 - lr: 3.7735e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2033\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2033 - val_loss: 0.2577 - lr: 3.7735e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1970\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1970 - val_loss: 0.2463 - lr: 3.5849e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2042 - val_loss: 0.2313 - lr: 3.4056e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1850\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1850 - val_loss: 0.2544 - lr: 3.4056e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1828\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1828 - val_loss: 0.2439 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1767\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1767 - val_loss: 0.2448 - lr: 3.0736e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1882\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1882 - val_loss: 0.2530 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1867\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1867 - val_loss: 0.2400 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1882\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1882 - val_loss: 0.2572 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1733\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1733 - val_loss: 0.2585 - lr: 2.5034e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1821\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1821 - val_loss: 0.2458 - lr: 2.3783e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1707\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1707 - val_loss: 0.2387 - lr: 2.2594e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1749\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1749 - val_loss: 0.2405 - lr: 2.1464e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1781\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1781 - val_loss: 0.2460 - lr: 2.0391e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1831\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1831 - val_loss: 0.2392 - lr: 1.9371e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1611\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1611 - val_loss: 0.2396 - lr: 1.8403e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1817\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1817 - val_loss: 0.2446 - lr: 1.7482e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1682\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1682 - val_loss: 0.2511 - lr: 1.6608e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1742\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1742 - val_loss: 0.2483 - lr: 1.5778e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1804\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1804 - val_loss: 0.2472 - lr: 1.4989e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1656\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1656 - val_loss: 0.2388 - lr: 1.4240e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1708\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1708 - val_loss: 0.2454 - lr: 1.3528e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1690\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1690 - val_loss: 0.2486 - lr: 1.2851e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1616\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1616 - val_loss: 0.2416 - lr: 1.2209e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1635\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1635 - val_loss: 0.2408 - lr: 1.1598e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1598\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1598 - val_loss: 0.2451 - lr: 1.1018e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1634\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1634 - val_loss: 0.2455 - lr: 1.0467e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1630\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1630 - val_loss: 0.2372 - lr: 9.9440e-05\n",
      "Epoch 60: early stopping\n",
      "2/2 [==============================] - 6s 139ms/step\n",
      "0.2042, 0.2313, 0.4494\n",
      "______fold 2______, ________repeat 9__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 829ms/step - loss: 0.4825 - val_loss: 0.4755 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.4546 - val_loss: 0.4463 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4085\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 8s 421ms/step - loss: 0.4085 - val_loss: 0.4481 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.3951 - val_loss: 0.4226 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.3927 - val_loss: 0.4004 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3964\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 415ms/step - loss: 0.3964 - val_loss: 0.4178 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3937\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.3937 - val_loss: 0.4220 - lr: 9.0250e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3752\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.3752 - val_loss: 0.4546 - lr: 8.5737e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3635\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.3635 - val_loss: 0.4282 - lr: 8.1451e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.3599 - val_loss: 0.3745 - lr: 7.7378e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3648\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.3648 - val_loss: 0.4201 - lr: 7.7378e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3447\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.3447 - val_loss: 0.3818 - lr: 7.3509e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.3297 - val_loss: 0.3447 - lr: 6.9834e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.3287 - val_loss: 0.3247 - lr: 6.9834e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3000\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.3000 - val_loss: 0.4061 - lr: 6.9834e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.2628 - val_loss: 0.3001 - lr: 6.6342e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2611\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 8s 421ms/step - loss: 0.2611 - val_loss: 0.3697 - lr: 6.6342e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2586\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2586 - val_loss: 0.3134 - lr: 6.3025e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2330\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2330 - val_loss: 0.3226 - lr: 5.9874e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2468\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2468 - val_loss: 0.3208 - lr: 5.6880e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2399 - val_loss: 0.2868 - lr: 5.4036e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2181\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 414ms/step - loss: 0.2181 - val_loss: 0.3103 - lr: 5.4036e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2384 - val_loss: 0.2799 - lr: 5.1334e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2598\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2598 - val_loss: 0.3201 - lr: 5.1334e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2208 - val_loss: 0.2527 - lr: 4.8767e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2060\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2060 - val_loss: 0.2803 - lr: 4.8767e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2081\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2081 - val_loss: 0.2827 - lr: 4.6329e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2020\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2020 - val_loss: 0.2815 - lr: 4.4013e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1970\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1970 - val_loss: 0.2789 - lr: 4.1812e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1922\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1922 - val_loss: 0.2997 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2051\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2051 - val_loss: 0.2694 - lr: 3.7735e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1908\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1908 - val_loss: 0.2554 - lr: 3.5849e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1835\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1835 - val_loss: 0.2650 - lr: 3.4056e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1771 - val_loss: 0.2486 - lr: 3.2353e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1799\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1799 - val_loss: 0.2511 - lr: 3.2353e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1832 - val_loss: 0.2460 - lr: 3.0736e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1578\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1578 - val_loss: 0.2541 - lr: 3.0736e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1881\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1881 - val_loss: 0.2475 - lr: 2.9199e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1864\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1864 - val_loss: 0.2615 - lr: 2.7739e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1629 - val_loss: 0.2445 - lr: 2.6352e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.1724 - val_loss: 0.2399 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1755\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1755 - val_loss: 0.2599 - lr: 2.6352e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1773 - val_loss: 0.2350 - lr: 2.5034e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1754\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1754 - val_loss: 0.2425 - lr: 2.5034e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1745\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1745 - val_loss: 0.2372 - lr: 2.3783e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1651\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1651 - val_loss: 0.2428 - lr: 2.2594e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1757 - val_loss: 0.2348 - lr: 2.1464e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1464\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.1464 - val_loss: 0.2699 - lr: 2.1464e-04\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.1619\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1619 - val_loss: 0.2387 - lr: 2.0391e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1617\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1617 - val_loss: 0.2500 - lr: 1.9371e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1798\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1798 - val_loss: 0.2516 - lr: 1.8403e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1579\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1579 - val_loss: 0.2413 - lr: 1.7482e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1557\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1557 - val_loss: 0.2561 - lr: 1.6608e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1613\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1613 - val_loss: 0.2384 - lr: 1.5778e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1493 - val_loss: 0.2313 - lr: 1.4989e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1509\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1509 - val_loss: 0.2358 - lr: 1.4989e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1667 - val_loss: 0.2279 - lr: 1.4240e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1525\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1525 - val_loss: 0.2302 - lr: 1.4240e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1490\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1490 - val_loss: 0.2338 - lr: 1.3528e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1430\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1430 - val_loss: 0.2321 - lr: 1.2851e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1529\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1529 - val_loss: 0.2347 - lr: 1.2209e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1343\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1343 - val_loss: 0.2440 - lr: 1.1598e-04\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1516\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1516 - val_loss: 0.2350 - lr: 1.1018e-04\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1477\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1477 - val_loss: 0.2405 - lr: 1.0467e-04\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1613\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1613 - val_loss: 0.2419 - lr: 9.9440e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1453\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1453 - val_loss: 0.2343 - lr: 9.4468e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1430\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1430 - val_loss: 0.2422 - lr: 8.9745e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1475\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1475 - val_loss: 0.2433 - lr: 8.5258e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1480\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1480 - val_loss: 0.2407 - lr: 8.0995e-05\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1463\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1463 - val_loss: 0.2409 - lr: 7.6945e-05\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1577\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1577 - val_loss: 0.2406 - lr: 7.3098e-05\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1543\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1543 - val_loss: 0.2410 - lr: 6.9443e-05\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1382\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1382 - val_loss: 0.2403 - lr: 6.5971e-05\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1420\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1420 - val_loss: 0.2405 - lr: 6.2672e-05\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1461\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 5.656161210936261e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1461 - val_loss: 0.2401 - lr: 5.9539e-05\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1322\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 5.373353305913042e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1322 - val_loss: 0.2392 - lr: 5.6562e-05\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1314\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 5.104685606056591e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1314 - val_loss: 0.2402 - lr: 5.3734e-05\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1368\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 4.849451343034161e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1368 - val_loss: 0.2441 - lr: 5.1047e-05\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1288\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 4.606978654919658e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1288 - val_loss: 0.2436 - lr: 4.8495e-05\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1321\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 4.3766295493696814e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1321 - val_loss: 0.2457 - lr: 4.6070e-05\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1382\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 4.1577981755835934e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1382 - val_loss: 0.2445 - lr: 4.3766e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1344\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.949908405047608e-05.\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1344 - val_loss: 0.2434 - lr: 4.1578e-05\n",
      "Epoch 82: early stopping\n",
      "2/2 [==============================] - 6s 125ms/step\n",
      "0.1667, 0.2279, 0.4718\n",
      "______fold 2______, ________repeat 10__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 789ms/step - loss: 0.5176 - val_loss: 0.4711 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 431ms/step - loss: 0.4622 - val_loss: 0.4634 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.4621 - val_loss: 0.4516 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.4516 - val_loss: 0.4219 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.4378 - val_loss: 0.4103 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.4332 - val_loss: 0.3952 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.3808 - val_loss: 0.3579 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.3499 - val_loss: 0.3479 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.3176 - val_loss: 0.3326 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2766 - val_loss: 0.3050 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.2636 - val_loss: 0.2859 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2400\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2400 - val_loss: 0.3157 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2455\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.2455 - val_loss: 0.3891 - lr: 9.5000e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2752\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2752 - val_loss: 0.3053 - lr: 9.0250e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2481\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2481 - val_loss: 0.3142 - lr: 8.5737e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2357\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.2357 - val_loss: 0.2882 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.2356 - val_loss: 0.2626 - lr: 7.7378e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2250 - val_loss: 0.2577 - lr: 7.7378e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2213\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2213 - val_loss: 0.2704 - lr: 7.7378e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2066 - val_loss: 0.2527 - lr: 7.3509e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2246\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.2246 - val_loss: 0.2934 - lr: 7.3509e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2169\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.2169 - val_loss: 0.2711 - lr: 6.9834e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2174\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2174 - val_loss: 0.2582 - lr: 6.6342e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2170\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.2170 - val_loss: 0.2653 - lr: 6.3025e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1895 - val_loss: 0.2497 - lr: 5.9874e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1946\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1946 - val_loss: 0.2575 - lr: 5.9874e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1963\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1963 - val_loss: 0.2683 - lr: 5.6880e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1884\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1884 - val_loss: 0.2633 - lr: 5.4036e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1962\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1962 - val_loss: 0.2613 - lr: 5.1334e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1908 - val_loss: 0.2447 - lr: 4.8767e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1881\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1881 - val_loss: 0.2454 - lr: 4.8767e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1816 - val_loss: 0.2422 - lr: 4.6329e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1676\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.1676 - val_loss: 0.2525 - lr: 4.6329e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1592\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1592 - val_loss: 0.2499 - lr: 4.4013e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1702\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1702 - val_loss: 0.2590 - lr: 4.1812e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1655\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1655 - val_loss: 0.2525 - lr: 3.9721e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1554\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1554 - val_loss: 0.2585 - lr: 3.7735e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1635\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1635 - val_loss: 0.2501 - lr: 3.5849e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1600 - val_loss: 0.2379 - lr: 3.4056e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1626\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1626 - val_loss: 0.2577 - lr: 3.4056e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1509\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1509 - val_loss: 0.2476 - lr: 3.2353e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1548\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1548 - val_loss: 0.2467 - lr: 3.0736e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1519\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1519 - val_loss: 0.2508 - lr: 2.9199e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1419\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1419 - val_loss: 0.2562 - lr: 2.7739e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1482\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1482 - val_loss: 0.2624 - lr: 2.6352e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1389\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1389 - val_loss: 0.2564 - lr: 2.5034e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1463\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1463 - val_loss: 0.2635 - lr: 2.3783e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1463\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1463 - val_loss: 0.2774 - lr: 2.2594e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1459\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1459 - val_loss: 0.2656 - lr: 2.1464e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1444\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1444 - val_loss: 0.2533 - lr: 2.0391e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1363\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1363 - val_loss: 0.2544 - lr: 1.9371e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1432\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1432 - val_loss: 0.2570 - lr: 1.8403e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1384\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1384 - val_loss: 0.2527 - lr: 1.7482e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1325\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1325 - val_loss: 0.2520 - lr: 1.6608e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1351\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1351 - val_loss: 0.2488 - lr: 1.5778e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1510\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1510 - val_loss: 0.2479 - lr: 1.4989e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.1188 - val_loss: 0.2346 - lr: 1.4240e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1290\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1290 - val_loss: 0.2423 - lr: 1.4240e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1364\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1364 - val_loss: 0.2484 - lr: 1.3528e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1218\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1218 - val_loss: 0.2443 - lr: 1.2851e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1316\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1316 - val_loss: 0.2412 - lr: 1.2209e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1344\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1344 - val_loss: 0.2492 - lr: 1.1598e-04\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1253\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1253 - val_loss: 0.2450 - lr: 1.1018e-04\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1332\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1332 - val_loss: 0.2373 - lr: 1.0467e-04\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1374\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1374 - val_loss: 0.2388 - lr: 9.9440e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1176\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1176 - val_loss: 0.2400 - lr: 9.4468e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1137\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1137 - val_loss: 0.2500 - lr: 8.9745e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1257\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.1257 - val_loss: 0.2513 - lr: 8.5258e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1274\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1274 - val_loss: 0.2442 - lr: 8.0995e-05\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1287\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1287 - val_loss: 0.2402 - lr: 7.6945e-05\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1220\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1220 - val_loss: 0.2439 - lr: 7.3098e-05\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1233\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1233 - val_loss: 0.2532 - lr: 6.9443e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1218\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1218 - val_loss: 0.2526 - lr: 6.5971e-05\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1097\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1097 - val_loss: 0.2506 - lr: 6.2672e-05\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1254\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 5.656161210936261e-05.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1254 - val_loss: 0.2434 - lr: 5.9539e-05\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1209\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 5.373353305913042e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1209 - val_loss: 0.2392 - lr: 5.6562e-05\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1181\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 5.104685606056591e-05.\n",
      "18/18 [==============================] - 6s 359ms/step - loss: 0.1181 - val_loss: 0.2430 - lr: 5.3734e-05\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1181\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 4.849451343034161e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1181 - val_loss: 0.2481 - lr: 5.1047e-05\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1146\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 4.606978654919658e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1146 - val_loss: 0.2499 - lr: 4.8495e-05\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1232\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 4.3766295493696814e-05.\n",
      "18/18 [==============================] - 6s 359ms/step - loss: 0.1232 - val_loss: 0.2499 - lr: 4.6070e-05\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1149\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 4.1577981755835934e-05.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1149 - val_loss: 0.2489 - lr: 4.3766e-05\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1169\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.949908405047608e-05.\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1169 - val_loss: 0.2450 - lr: 4.1578e-05\n",
      "Epoch 82: early stopping\n",
      "2/2 [==============================] - 6s 126ms/step\n",
      "0.1188, 0.2346, 0.4445\n",
      "______fold 3______, ________repeat 1__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 820ms/step - loss: 0.4924 - val_loss: 0.4699 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.4571 - val_loss: 0.4539 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4429\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.4429 - val_loss: 0.4725 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4415\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.4415 - val_loss: 0.4636 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4133 - val_loss: 0.4444 - lr: 9.0250e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.4034 - val_loss: 0.4251 - lr: 9.0250e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.3822 - val_loss: 0.4026 - lr: 9.0250e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.3634 - val_loss: 0.3589 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.3332 - val_loss: 0.3574 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 8s 423ms/step - loss: 0.3228 - val_loss: 0.3407 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3140 - val_loss: 0.2265 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.2865 - val_loss: 0.1978 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2696 - val_loss: 0.1615 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2669\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 6s 362ms/step - loss: 0.2669 - val_loss: 0.1723 - lr: 9.0250e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2514\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.2514 - val_loss: 0.2242 - lr: 8.5737e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2527\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.2527 - val_loss: 0.1704 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2226\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 6s 362ms/step - loss: 0.2226 - val_loss: 0.1937 - lr: 7.7378e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2602\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.2602 - val_loss: 0.1640 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2371\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.2371 - val_loss: 0.1779 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2100\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2100 - val_loss: 0.1811 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2087\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2087 - val_loss: 0.1685 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1990\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1990 - val_loss: 0.1799 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2246\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2246 - val_loss: 0.1766 - lr: 5.6880e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2030 - val_loss: 0.1423 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1953\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1953 - val_loss: 0.1827 - lr: 5.4036e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1875\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1875 - val_loss: 0.1865 - lr: 5.1334e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1836\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1836 - val_loss: 0.1768 - lr: 4.8767e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1790\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1790 - val_loss: 0.2065 - lr: 4.6329e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1823\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1823 - val_loss: 0.1891 - lr: 4.4013e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1918\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1918 - val_loss: 0.1778 - lr: 4.1812e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1888\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1888 - val_loss: 0.1781 - lr: 3.9721e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1825\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1825 - val_loss: 0.2045 - lr: 3.7735e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1749\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1749 - val_loss: 0.1988 - lr: 3.5849e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1785\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1785 - val_loss: 0.1866 - lr: 3.4056e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1626\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1626 - val_loss: 0.1803 - lr: 3.2353e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1632\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1632 - val_loss: 0.2015 - lr: 3.0736e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1755\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1755 - val_loss: 0.1948 - lr: 2.9199e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1739\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1739 - val_loss: 0.1903 - lr: 2.7739e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1702\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 8s 429ms/step - loss: 0.1702 - val_loss: 0.2076 - lr: 2.6352e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1677\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 9s 476ms/step - loss: 0.1677 - val_loss: 0.1781 - lr: 2.5034e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1589\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 8s 456ms/step - loss: 0.1589 - val_loss: 0.1689 - lr: 2.3783e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1705\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1705 - val_loss: 0.2156 - lr: 2.2594e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1708\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1708 - val_loss: 0.1856 - lr: 2.1464e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1472\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1472 - val_loss: 0.1796 - lr: 2.0391e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1473\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1473 - val_loss: 0.2206 - lr: 1.9371e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1559\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1559 - val_loss: 0.2195 - lr: 1.8403e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1356\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.1356 - val_loss: 0.2149 - lr: 1.7482e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1524\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1524 - val_loss: 0.2299 - lr: 1.6608e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1410\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.1410 - val_loss: 0.2189 - lr: 1.5778e-04\n",
      "Epoch 49: early stopping\n",
      "2/2 [==============================] - 6s 130ms/step\n",
      "0.2030, 0.1423, 0.2760\n",
      "______fold 3______, ________repeat 2__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 822ms/step - loss: 0.4811 - val_loss: 0.4693 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4431\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.4431 - val_loss: 0.4696 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4119 - val_loss: 0.4251 - lr: 9.5000e-04\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3873\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3873 - val_loss: 0.4646 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3935\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3935 - val_loss: 0.4462 - lr: 9.0250e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.3900 - val_loss: 0.3769 - lr: 8.5737e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.3527 - val_loss: 0.3558 - lr: 8.5737e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.3270 - val_loss: 0.3463 - lr: 8.5737e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.3213 - val_loss: 0.2429 - lr: 8.5737e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3258\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.3258 - val_loss: 0.3063 - lr: 8.5737e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.3089 - val_loss: 0.2363 - lr: 8.1451e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2797 - val_loss: 0.2025 - lr: 8.1451e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2792\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2792 - val_loss: 0.2722 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2852 - val_loss: 0.1930 - lr: 7.7378e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2351\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2351 - val_loss: 0.1997 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2663 - val_loss: 0.1896 - lr: 7.3509e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2358 - val_loss: 0.1857 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.2608 - val_loss: 0.1667 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2147 - val_loss: 0.1628 - lr: 7.3509e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2211\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2211 - val_loss: 0.1984 - lr: 7.3509e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2267\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2267 - val_loss: 0.1807 - lr: 6.9834e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2169\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2169 - val_loss: 0.1679 - lr: 6.6342e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2242\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2242 - val_loss: 0.1791 - lr: 6.3025e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2024\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2024 - val_loss: 0.1647 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1999\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1999 - val_loss: 0.1979 - lr: 5.6880e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1872\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1872 - val_loss: 0.1665 - lr: 5.4036e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1918\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1918 - val_loss: 0.1642 - lr: 5.1334e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1864\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1864 - val_loss: 0.1814 - lr: 4.8767e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.2121 - val_loss: 0.1525 - lr: 4.6329e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1845\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1845 - val_loss: 0.1820 - lr: 4.6329e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1801\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1801 - val_loss: 0.2118 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1864\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1864 - val_loss: 0.1811 - lr: 4.1812e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1816\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1816 - val_loss: 0.1700 - lr: 3.9721e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1910\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.1910 - val_loss: 0.1915 - lr: 3.7735e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1708\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1708 - val_loss: 0.1684 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1814\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1814 - val_loss: 0.1963 - lr: 3.4056e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1598\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1598 - val_loss: 0.1862 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1739\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1739 - val_loss: 0.1918 - lr: 3.0736e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1637\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1637 - val_loss: 0.1581 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1477\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1477 - val_loss: 0.1678 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1608\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1608 - val_loss: 0.1759 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1595\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1595 - val_loss: 0.1942 - lr: 2.5034e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1438\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1438 - val_loss: 0.2052 - lr: 2.3783e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1456\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1456 - val_loss: 0.1771 - lr: 2.2594e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1518\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1518 - val_loss: 0.1738 - lr: 2.1464e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1586\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1586 - val_loss: 0.1916 - lr: 2.0391e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1418\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1418 - val_loss: 0.2008 - lr: 1.9371e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1368\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1368 - val_loss: 0.1991 - lr: 1.8403e-04\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.1459\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1459 - val_loss: 0.2057 - lr: 1.7482e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1480\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 415ms/step - loss: 0.1480 - val_loss: 0.2027 - lr: 1.6608e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1533\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1533 - val_loss: 0.2052 - lr: 1.5778e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1409\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1409 - val_loss: 0.2134 - lr: 1.4989e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1402\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1402 - val_loss: 0.2090 - lr: 1.4240e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1436\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1436 - val_loss: 0.1864 - lr: 1.3528e-04\n",
      "Epoch 54: early stopping\n",
      "2/2 [==============================] - 8s 139ms/step\n",
      "0.2121, 0.1525, 0.2160\n",
      "______fold 3______, ________repeat 3__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 828ms/step - loss: 0.4965 - val_loss: 0.4668 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 425ms/step - loss: 0.4501 - val_loss: 0.4588 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4233\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.4233 - val_loss: 0.4622 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.4202 - val_loss: 0.4414 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3874\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.3874 - val_loss: 0.4605 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3758\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.3758 - val_loss: 0.4479 - lr: 9.0250e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 428ms/step - loss: 0.3608 - val_loss: 0.4301 - lr: 8.5737e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3517\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.3517 - val_loss: 0.4396 - lr: 8.5737e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.3376 - val_loss: 0.4042 - lr: 8.1451e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3332\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.3332 - val_loss: 0.4171 - lr: 8.1451e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.3400 - val_loss: 0.2789 - lr: 7.7378e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2956\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2956 - val_loss: 0.2842 - lr: 7.7378e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2783\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2783 - val_loss: 0.3021 - lr: 7.3509e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.2801 - val_loss: 0.2281 - lr: 6.9834e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.2683 - val_loss: 0.2280 - lr: 6.9834e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2527 - val_loss: 0.2011 - lr: 6.9834e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2565\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2565 - val_loss: 0.2187 - lr: 6.9834e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2605 - val_loss: 0.1694 - lr: 6.6342e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2316\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 8s 421ms/step - loss: 0.2316 - val_loss: 0.1993 - lr: 6.6342e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2133\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.2133 - val_loss: 0.2208 - lr: 6.3025e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2371\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2371 - val_loss: 0.2039 - lr: 5.9874e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2273\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2273 - val_loss: 0.2020 - lr: 5.6880e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2364\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2364 - val_loss: 0.2086 - lr: 5.4036e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2146\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2146 - val_loss: 0.2328 - lr: 5.1334e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2132\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2132 - val_loss: 0.1982 - lr: 4.8767e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2182\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2182 - val_loss: 0.1830 - lr: 4.6329e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2044\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2044 - val_loss: 0.1947 - lr: 4.4013e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1896\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1896 - val_loss: 0.2190 - lr: 4.1812e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1936\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1936 - val_loss: 0.2041 - lr: 3.9721e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1902\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1902 - val_loss: 0.2052 - lr: 3.7735e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1945\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1945 - val_loss: 0.2028 - lr: 3.5849e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1920\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1920 - val_loss: 0.2269 - lr: 3.4056e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1687\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1687 - val_loss: 0.2279 - lr: 3.2353e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1823\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1823 - val_loss: 0.2149 - lr: 3.0736e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1559\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1559 - val_loss: 0.2315 - lr: 2.9199e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1672\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1672 - val_loss: 0.2272 - lr: 2.7739e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1708 - val_loss: 0.1628 - lr: 2.6352e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1655\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1655 - val_loss: 0.2113 - lr: 2.6352e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1632\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1632 - val_loss: 0.2487 - lr: 2.5034e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1452\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1452 - val_loss: 0.2444 - lr: 2.3783e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1433\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1433 - val_loss: 0.2316 - lr: 2.2594e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1458\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1458 - val_loss: 0.2044 - lr: 2.1464e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1553\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1553 - val_loss: 0.2313 - lr: 2.0391e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1384\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1384 - val_loss: 0.2200 - lr: 1.9371e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1437\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1437 - val_loss: 0.2205 - lr: 1.8403e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1432\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1432 - val_loss: 0.2105 - lr: 1.7482e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1485\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.1485 - val_loss: 0.2403 - lr: 1.6608e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1290\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1290 - val_loss: 0.2558 - lr: 1.5778e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1287\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1287 - val_loss: 0.2626 - lr: 1.4989e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1489\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1489 - val_loss: 0.2605 - lr: 1.4240e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1464\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1464 - val_loss: 0.2442 - lr: 1.3528e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1195\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1195 - val_loss: 0.2065 - lr: 1.2851e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1351\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1351 - val_loss: 0.2416 - lr: 1.2209e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1366\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1366 - val_loss: 0.2416 - lr: 1.1598e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1316\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1316 - val_loss: 0.2403 - lr: 1.1018e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1310\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1310 - val_loss: 0.2205 - lr: 1.0467e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1385\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1385 - val_loss: 0.2199 - lr: 9.9440e-05\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1367\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.1367 - val_loss: 0.2257 - lr: 9.4468e-05\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1215\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1215 - val_loss: 0.2172 - lr: 8.9745e-05\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1280\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1280 - val_loss: 0.2208 - lr: 8.5258e-05\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1372\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1372 - val_loss: 0.2258 - lr: 8.0995e-05\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1237\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.1237 - val_loss: 0.2376 - lr: 7.6945e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: early stopping\n",
      "2/2 [==============================] - 7s 132ms/step\n",
      "0.1708, 0.1628, 0.2802\n",
      "______fold 3______, ________repeat 4__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 52s 782ms/step - loss: 0.5158 - val_loss: 0.4689 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.4625 - val_loss: 0.4645 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4501\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.4501 - val_loss: 0.4693 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.4494 - val_loss: 0.4609 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.4198 - val_loss: 0.4299 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3954\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.3954 - val_loss: 0.4486 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3821 - val_loss: 0.4280 - lr: 9.0250e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.3815 - val_loss: 0.3748 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.3666 - val_loss: 0.3378 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3337\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.3337 - val_loss: 0.3763 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.3400 - val_loss: 0.2885 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.3084 - val_loss: 0.2158 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2733 - val_loss: 0.1948 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2813 - val_loss: 0.1831 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 9s 493ms/step - loss: 0.2627 - val_loss: 0.1792 - lr: 8.5737e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2541\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 8s 417ms/step - loss: 0.2541 - val_loss: 0.2331 - lr: 8.5737e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2797 - val_loss: 0.1658 - lr: 8.1451e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2507\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2507 - val_loss: 0.2187 - lr: 8.1451e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2321\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2321 - val_loss: 0.1802 - lr: 7.7378e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2114\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2114 - val_loss: 0.1801 - lr: 7.3509e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2449\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2449 - val_loss: 0.1683 - lr: 6.9834e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2125\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2125 - val_loss: 0.1695 - lr: 6.6342e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2067\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2067 - val_loss: 0.1972 - lr: 6.3025e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1886\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1886 - val_loss: 0.1747 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1786\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1786 - val_loss: 0.1741 - lr: 5.6880e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1984\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1984 - val_loss: 0.1662 - lr: 5.4036e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1821 - val_loss: 0.1631 - lr: 5.1334e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1821 - val_loss: 0.1511 - lr: 5.1334e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1760 - val_loss: 0.1473 - lr: 5.1334e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1764\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1764 - val_loss: 0.1627 - lr: 5.1334e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1830\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 6s 362ms/step - loss: 0.1830 - val_loss: 0.1667 - lr: 4.8767e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1709\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1709 - val_loss: 0.1723 - lr: 4.6329e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1663\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.1663 - val_loss: 0.1759 - lr: 4.4013e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1679\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 8s 422ms/step - loss: 0.1679 - val_loss: 0.1761 - lr: 4.1812e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 9s 490ms/step - loss: 0.1637 - val_loss: 0.1380 - lr: 3.9721e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1493\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 413ms/step - loss: 0.1493 - val_loss: 0.1934 - lr: 3.9721e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1747 - val_loss: 0.1370 - lr: 3.7735e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1756\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1756 - val_loss: 0.1544 - lr: 3.7735e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.1556 - val_loss: 0.1342 - lr: 3.5849e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.1556 - val_loss: 0.1288 - lr: 3.5849e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1510\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1510 - val_loss: 0.1695 - lr: 3.5849e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1333\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1333 - val_loss: 0.1888 - lr: 3.4056e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1322\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1322 - val_loss: 0.1505 - lr: 3.2353e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1406\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1406 - val_loss: 0.1758 - lr: 3.0736e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1356\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1356 - val_loss: 0.1747 - lr: 2.9199e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1410\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1410 - val_loss: 0.1858 - lr: 2.7739e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1416\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1416 - val_loss: 0.1828 - lr: 2.6352e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1365\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1365 - val_loss: 0.1773 - lr: 2.5034e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1198\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.1198 - val_loss: 0.2023 - lr: 2.3783e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1383\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1383 - val_loss: 0.1879 - lr: 2.2594e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1432\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1432 - val_loss: 0.1780 - lr: 2.1464e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1277\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1277 - val_loss: 0.2234 - lr: 2.0391e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1325\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1325 - val_loss: 0.1894 - lr: 1.9371e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1357\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 8s 442ms/step - loss: 0.1357 - val_loss: 0.1664 - lr: 1.8403e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1239\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.1239 - val_loss: 0.2001 - lr: 1.7482e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1208\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1208 - val_loss: 0.1932 - lr: 1.6608e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1281\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1281 - val_loss: 0.1651 - lr: 1.5778e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1207\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1207 - val_loss: 0.1506 - lr: 1.4989e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1084\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1084 - val_loss: 0.1631 - lr: 1.4240e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1257\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1257 - val_loss: 0.1654 - lr: 1.3528e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1152\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1152 - val_loss: 0.1590 - lr: 1.2851e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1219\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1219 - val_loss: 0.1760 - lr: 1.2209e-04\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1167\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1167 - val_loss: 0.1495 - lr: 1.1598e-04\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1100\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1100 - val_loss: 0.1516 - lr: 1.1018e-04\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1150\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.1150 - val_loss: 0.1701 - lr: 1.0467e-04\n",
      "Epoch 65: early stopping\n",
      "2/2 [==============================] - 8s 121ms/step\n",
      "0.1556, 0.1288, 0.2063\n",
      "______fold 3______, ________repeat 5__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 825ms/step - loss: 0.4958 - val_loss: 0.4691 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 427ms/step - loss: 0.4633 - val_loss: 0.4676 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.4618 - val_loss: 0.4659 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4588\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 8s 417ms/step - loss: 0.4588 - val_loss: 0.4668 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.4523 - val_loss: 0.4613 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 443ms/step - loss: 0.4404 - val_loss: 0.4512 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.3934 - val_loss: 0.4166 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.3584 - val_loss: 0.3577 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 8s 433ms/step - loss: 0.3326 - val_loss: 0.2773 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2980\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2980 - val_loss: 0.3589 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.3113 - val_loss: 0.2606 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.2771 - val_loss: 0.1862 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2816\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2816 - val_loss: 0.2269 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2438\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2438 - val_loss: 0.1983 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.2522 - val_loss: 0.1395 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2602\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2602 - val_loss: 0.1945 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2347\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2347 - val_loss: 0.1940 - lr: 7.7378e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2571\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2571 - val_loss: 0.1585 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2215\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2215 - val_loss: 0.1841 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2245\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2245 - val_loss: 0.1534 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2083\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2083 - val_loss: 0.1947 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2197\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2197 - val_loss: 0.2022 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2050\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2050 - val_loss: 0.2046 - lr: 5.6880e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1933\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1933 - val_loss: 0.1898 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2010\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2010 - val_loss: 0.2270 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1955\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1955 - val_loss: 0.2038 - lr: 4.8767e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1858\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1858 - val_loss: 0.2342 - lr: 4.6329e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1743\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1743 - val_loss: 0.1881 - lr: 4.4013e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1952\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1952 - val_loss: 0.2240 - lr: 4.1812e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2019\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2019 - val_loss: 0.1941 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1712\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1712 - val_loss: 0.1929 - lr: 3.7735e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1780\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1780 - val_loss: 0.1855 - lr: 3.5849e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1636\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1636 - val_loss: 0.2313 - lr: 3.4056e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1506\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1506 - val_loss: 0.2362 - lr: 3.2353e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1601\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1601 - val_loss: 0.1826 - lr: 3.0736e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1612\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1612 - val_loss: 0.1925 - lr: 2.9199e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1643\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1643 - val_loss: 0.1953 - lr: 2.7739e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1741\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1741 - val_loss: 0.2060 - lr: 2.6352e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1632\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1632 - val_loss: 0.2231 - lr: 2.5034e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1548\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1548 - val_loss: 0.2066 - lr: 2.3783e-04\n",
      "Epoch 40: early stopping\n",
      "2/2 [==============================] - 6s 128ms/step\n",
      "0.2522, 0.1395, 0.2145\n",
      "______fold 3______, ________repeat 6__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 823ms/step - loss: 0.4795 - val_loss: 0.4635 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 415ms/step - loss: 0.4513 - val_loss: 0.4568 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4346 - val_loss: 0.4505 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4316\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.4316 - val_loss: 0.4547 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.4043 - val_loss: 0.4493 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.3877 - val_loss: 0.4448 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.3697 - val_loss: 0.4144 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.3399 - val_loss: 0.3210 - lr: 9.5000e-04\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.3145\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3145 - val_loss: 0.3369 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3104\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.3104 - val_loss: 0.3258 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2967 - val_loss: 0.2000 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2851 - val_loss: 0.1846 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2726\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2726 - val_loss: 0.2495 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2657\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2657 - val_loss: 0.2017 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2371\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.2371 - val_loss: 0.1976 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2240 - val_loss: 0.1772 - lr: 7.3509e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2279\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.2279 - val_loss: 0.1929 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.2532 - val_loss: 0.1555 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2249\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2249 - val_loss: 0.2379 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2527\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2527 - val_loss: 0.1896 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2507\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2507 - val_loss: 0.1943 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2411\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.2411 - val_loss: 0.1708 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2159\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.2159 - val_loss: 0.1867 - lr: 5.6880e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1951\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1951 - val_loss: 0.1767 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1857\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1857 - val_loss: 0.2117 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2037\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 8s 445ms/step - loss: 0.2037 - val_loss: 0.2040 - lr: 4.8767e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1942\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1942 - val_loss: 0.1944 - lr: 4.6329e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2017\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2017 - val_loss: 0.1785 - lr: 4.4013e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1746\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1746 - val_loss: 0.2166 - lr: 4.1812e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1950\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1950 - val_loss: 0.2239 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1858\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1858 - val_loss: 0.2004 - lr: 3.7735e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1829\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1829 - val_loss: 0.2299 - lr: 3.5849e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1912\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1912 - val_loss: 0.2189 - lr: 3.4056e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1970\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1970 - val_loss: 0.2092 - lr: 3.2353e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1687\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1687 - val_loss: 0.2283 - lr: 3.0736e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2167\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2167 - val_loss: 0.1898 - lr: 2.9199e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1820\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1820 - val_loss: 0.2167 - lr: 2.7739e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1934\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1934 - val_loss: 0.1856 - lr: 2.6352e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1626\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1626 - val_loss: 0.2125 - lr: 2.5034e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1700\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1700 - val_loss: 0.2059 - lr: 2.3783e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1677\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1677 - val_loss: 0.1940 - lr: 2.2594e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1719\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1719 - val_loss: 0.2185 - lr: 2.1464e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1629\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.1629 - val_loss: 0.2427 - lr: 2.0391e-04\n",
      "Epoch 43: early stopping\n",
      "2/2 [==============================] - 6s 128ms/step\n",
      "0.2532, 0.1555, 0.2386\n",
      "______fold 3______, ________repeat 7__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 805ms/step - loss: 0.4746 - val_loss: 0.4621 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.4487 - val_loss: 0.4392 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.4064 - val_loss: 0.3681 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.3947 - val_loss: 0.3352 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3711\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.3711 - val_loss: 0.3533 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.3518 - val_loss: 0.3024 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.3343 - val_loss: 0.2765 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.3272 - val_loss: 0.2649 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 8s 432ms/step - loss: 0.3238 - val_loss: 0.2585 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2816\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.2816 - val_loss: 0.2728 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2868 - val_loss: 0.2051 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2859 - val_loss: 0.1833 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2681 - val_loss: 0.1600 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2639\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2639 - val_loss: 0.1983 - lr: 9.0250e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2710\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2710 - val_loss: 0.1821 - lr: 8.5737e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2598\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2598 - val_loss: 0.2129 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2235\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2235 - val_loss: 0.1872 - lr: 7.7378e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2445\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2445 - val_loss: 0.1755 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2176\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2176 - val_loss: 0.1987 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1982\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1982 - val_loss: 0.1737 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2243 - val_loss: 0.1326 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2283\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2283 - val_loss: 0.1983 - lr: 6.3025e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2210\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 418ms/step - loss: 0.2210 - val_loss: 0.1924 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2052\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 8s 418ms/step - loss: 0.2052 - val_loss: 0.1486 - lr: 5.6880e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2137\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.2137 - val_loss: 0.2338 - lr: 5.4036e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1966\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 8s 467ms/step - loss: 0.1966 - val_loss: 0.1541 - lr: 5.1334e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1868\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 415ms/step - loss: 0.1868 - val_loss: 0.2106 - lr: 4.8767e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1802\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1802 - val_loss: 0.1890 - lr: 4.6329e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1680\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1680 - val_loss: 0.2007 - lr: 4.4013e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1769\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1769 - val_loss: 0.1878 - lr: 4.1812e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1669\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1669 - val_loss: 0.2155 - lr: 3.9721e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1841\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1841 - val_loss: 0.2316 - lr: 3.7735e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1584\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1584 - val_loss: 0.2075 - lr: 3.5849e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1686\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1686 - val_loss: 0.2236 - lr: 3.4056e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1599\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1599 - val_loss: 0.2110 - lr: 3.2353e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1532\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1532 - val_loss: 0.1921 - lr: 3.0736e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1613\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1613 - val_loss: 0.2283 - lr: 2.9199e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1609\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1609 - val_loss: 0.1958 - lr: 2.7739e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1670\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1670 - val_loss: 0.2101 - lr: 2.6352e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1413\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 6s 359ms/step - loss: 0.1413 - val_loss: 0.2256 - lr: 2.5034e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1636\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 6s 359ms/step - loss: 0.1636 - val_loss: 0.2183 - lr: 2.3783e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1595\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 6s 359ms/step - loss: 0.1595 - val_loss: 0.2381 - lr: 2.2594e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1540\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 6s 359ms/step - loss: 0.1540 - val_loss: 0.2062 - lr: 2.1464e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1506\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1506 - val_loss: 0.2029 - lr: 2.0391e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1528\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1528 - val_loss: 0.2147 - lr: 1.9371e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1302\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "18/18 [==============================] - 7s 412ms/step - loss: 0.1302 - val_loss: 0.2119 - lr: 1.8403e-04\n",
      "Epoch 46: early stopping\n",
      "2/2 [==============================] - 7s 127ms/step\n",
      "0.2243, 0.1326, 0.2475\n",
      "______fold 3______, ________repeat 8__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 824ms/step - loss: 0.4695 - val_loss: 0.4681 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.4590 - val_loss: 0.4658 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4332\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.4332 - val_loss: 0.4896 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.4216 - val_loss: 0.4557 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4174\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.4174 - val_loss: 0.5082 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.3901 - val_loss: 0.4390 - lr: 9.0250e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.3729 - val_loss: 0.3981 - lr: 9.0250e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.3694 - val_loss: 0.3655 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3494\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.3494 - val_loss: 0.3935 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3456\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.3456 - val_loss: 0.3662 - lr: 8.5737e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.3188 - val_loss: 0.3197 - lr: 8.1451e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2934 - val_loss: 0.2342 - lr: 8.1451e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2941\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2941 - val_loss: 0.2976 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.2933 - val_loss: 0.2035 - lr: 7.7378e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2865\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2865 - val_loss: 0.2384 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2548\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2548 - val_loss: 0.2539 - lr: 7.3509e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2581 - val_loss: 0.1913 - lr: 6.9834e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2585\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2585 - val_loss: 0.1945 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2375 - val_loss: 0.1761 - lr: 6.6342e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2266\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2266 - val_loss: 0.2181 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2568\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2568 - val_loss: 0.2195 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2169\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2169 - val_loss: 0.1990 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2220\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2220 - val_loss: 0.2080 - lr: 5.6880e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2113\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2113 - val_loss: 0.2065 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1880\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1880 - val_loss: 0.2098 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2233\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.2233 - val_loss: 0.1875 - lr: 4.8767e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2153\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.2153 - val_loss: 0.2287 - lr: 4.6329e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1970\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 6s 359ms/step - loss: 0.1970 - val_loss: 0.2061 - lr: 4.4013e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1843\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1843 - val_loss: 0.2268 - lr: 4.1812e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1949\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1949 - val_loss: 0.2021 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1870\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1870 - val_loss: 0.2133 - lr: 3.7735e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1946\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1946 - val_loss: 0.2216 - lr: 3.5849e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1875\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1875 - val_loss: 0.2385 - lr: 3.4056e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1885\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1885 - val_loss: 0.2274 - lr: 3.2353e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1850\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1850 - val_loss: 0.2256 - lr: 3.0736e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1702\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1702 - val_loss: 0.2276 - lr: 2.9199e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1684\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1684 - val_loss: 0.2565 - lr: 2.7739e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1777\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1777 - val_loss: 0.2396 - lr: 2.6352e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1760\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1760 - val_loss: 0.2180 - lr: 2.5034e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1803\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1803 - val_loss: 0.2201 - lr: 2.3783e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1690\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1690 - val_loss: 0.2087 - lr: 2.2594e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1807\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1807 - val_loss: 0.2379 - lr: 2.1464e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1790\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1790 - val_loss: 0.2480 - lr: 2.0391e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1559\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1559 - val_loss: 0.2470 - lr: 1.9371e-04\n",
      "Epoch 44: early stopping\n",
      "2/2 [==============================] - 6s 129ms/step\n",
      "0.2375, 0.1761, 0.3451\n",
      "______fold 3______, ________repeat 9__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 818ms/step - loss: 0.4786 - val_loss: 0.4712 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4518 - val_loss: 0.4556 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.4368 - val_loss: 0.4548 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.4141 - val_loss: 0.4523 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.3897 - val_loss: 0.4458 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.3777 - val_loss: 0.4405 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 434ms/step - loss: 0.3567 - val_loss: 0.4049 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.3565 - val_loss: 0.3437 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 8s 434ms/step - loss: 0.3384 - val_loss: 0.2266 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3207\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.3207 - val_loss: 0.3239 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2997 - val_loss: 0.1909 - lr: 9.5000e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2809 - val_loss: 0.1869 - lr: 9.5000e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.2618 - val_loss: 0.1846 - lr: 9.5000e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2434\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2434 - val_loss: 0.2443 - lr: 9.5000e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2561 - val_loss: 0.1614 - lr: 9.0250e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2390\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2390 - val_loss: 0.2203 - lr: 9.0250e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2236\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2236 - val_loss: 0.1808 - lr: 8.5737e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2236\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2236 - val_loss: 0.2047 - lr: 8.1451e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1977\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1977 - val_loss: 0.2440 - lr: 7.7378e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2104\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2104 - val_loss: 0.2016 - lr: 7.3509e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1929\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1929 - val_loss: 0.2364 - lr: 6.9834e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1820\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1820 - val_loss: 0.2162 - lr: 6.6342e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1934\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1934 - val_loss: 0.2173 - lr: 6.3025e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1780\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1780 - val_loss: 0.2263 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1725\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1725 - val_loss: 0.2328 - lr: 5.6880e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1815\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1815 - val_loss: 0.2334 - lr: 5.4036e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1784\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1784 - val_loss: 0.2504 - lr: 5.1334e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1663\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1663 - val_loss: 0.2410 - lr: 4.8767e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1653\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1653 - val_loss: 0.2104 - lr: 4.6329e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1649\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1649 - val_loss: 0.2328 - lr: 4.4013e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1531\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1531 - val_loss: 0.2350 - lr: 4.1812e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1570\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1570 - val_loss: 0.2364 - lr: 3.9721e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1415\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1415 - val_loss: 0.2682 - lr: 3.7735e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1533\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1533 - val_loss: 0.2370 - lr: 3.5849e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1514\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1514 - val_loss: 0.2111 - lr: 3.4056e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1487\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1487 - val_loss: 0.2389 - lr: 3.2353e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1637\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1637 - val_loss: 0.2468 - lr: 3.0736e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1413\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1413 - val_loss: 0.2304 - lr: 2.9199e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1528\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1528 - val_loss: 0.2211 - lr: 2.7739e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1326\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1326 - val_loss: 0.2494 - lr: 2.6352e-04\n",
      "Epoch 40: early stopping\n",
      "2/2 [==============================] - 6s 132ms/step\n",
      "0.2561, 0.1614, 0.2348\n",
      "______fold 3______, ________repeat 10__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 824ms/step - loss: 0.5015 - val_loss: 0.4675 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4599\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.4599 - val_loss: 0.4699 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.4475 - val_loss: 0.4653 - lr: 9.5000e-04\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4306\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.4306 - val_loss: 0.4660 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4206\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.4206 - val_loss: 0.4907 - lr: 9.0250e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.4049 - val_loss: 0.4554 - lr: 8.5737e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3927 - val_loss: 0.4087 - lr: 8.5737e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 8s 426ms/step - loss: 0.3887 - val_loss: 0.4026 - lr: 8.5737e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3738 - val_loss: 0.3448 - lr: 8.5737e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3516\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.3516 - val_loss: 0.3600 - lr: 8.5737e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3417 - val_loss: 0.2968 - lr: 8.1451e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.3452 - val_loss: 0.2720 - lr: 8.1451e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.3186 - val_loss: 0.2619 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.3113 - val_loss: 0.2250 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.2967 - val_loss: 0.2218 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2785 - val_loss: 0.1884 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2788\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2788 - val_loss: 0.1947 - lr: 8.1451e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2810\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2810 - val_loss: 0.1908 - lr: 7.7378e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2634\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2634 - val_loss: 0.2243 - lr: 7.3509e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2834\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2834 - val_loss: 0.2244 - lr: 6.9834e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2453\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2453 - val_loss: 0.1979 - lr: 6.6342e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2374 - val_loss: 0.1637 - lr: 6.3025e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2395\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2395 - val_loss: 0.2012 - lr: 6.3025e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2334\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2334 - val_loss: 0.1819 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2144\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2144 - val_loss: 0.2023 - lr: 5.6880e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2126\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2126 - val_loss: 0.1942 - lr: 5.4036e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1996\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1996 - val_loss: 0.1767 - lr: 5.1334e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2113\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2113 - val_loss: 0.1819 - lr: 4.8767e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1958 - val_loss: 0.1599 - lr: 4.6329e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1958\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1958 - val_loss: 0.1875 - lr: 4.6329e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1880\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1880 - val_loss: 0.1929 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1906\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1906 - val_loss: 0.1757 - lr: 4.1812e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1751\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1751 - val_loss: 0.2195 - lr: 3.9721e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2019\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2019 - val_loss: 0.2224 - lr: 3.7735e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1777\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1777 - val_loss: 0.2366 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1729\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1729 - val_loss: 0.2300 - lr: 3.4056e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1612\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1612 - val_loss: 0.2161 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1684\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1684 - val_loss: 0.1741 - lr: 3.0736e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1708\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1708 - val_loss: 0.1811 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1628\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1628 - val_loss: 0.1933 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1532\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1532 - val_loss: 0.2113 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1761\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1761 - val_loss: 0.2175 - lr: 2.5034e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1707\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1707 - val_loss: 0.1947 - lr: 2.3783e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1591\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1591 - val_loss: 0.2120 - lr: 2.2594e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1662\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1662 - val_loss: 0.2297 - lr: 2.1464e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1577\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1577 - val_loss: 0.2097 - lr: 2.0391e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1389\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1389 - val_loss: 0.2245 - lr: 1.9371e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1554\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1554 - val_loss: 0.2299 - lr: 1.8403e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1603\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1603 - val_loss: 0.2250 - lr: 1.7482e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1504\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1504 - val_loss: 0.2154 - lr: 1.6608e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1532\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1532 - val_loss: 0.2132 - lr: 1.5778e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1447\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1447 - val_loss: 0.2382 - lr: 1.4989e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1566\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1566 - val_loss: 0.2381 - lr: 1.4240e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1473\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1473 - val_loss: 0.2158 - lr: 1.3528e-04\n",
      "Epoch 54: early stopping\n",
      "2/2 [==============================] - 6s 129ms/step\n",
      "0.1958, 0.1599, 0.2292\n",
      "______fold 4______, ________repeat 1__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 791ms/step - loss: 0.4853 - val_loss: 0.4674 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.4644 - val_loss: 0.4625 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.4578 - val_loss: 0.4444 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.4415 - val_loss: 0.4097 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.4300 - val_loss: 0.3787 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.4109 - val_loss: 0.3732 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.3945 - val_loss: 0.3668 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.3805 - val_loss: 0.3377 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.3455 - val_loss: 0.2884 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.3331 - val_loss: 0.2263 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.2915 - val_loss: 0.1944 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2536 - val_loss: 0.1924 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.2773 - val_loss: 0.1553 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2376\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2376 - val_loss: 0.1797 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2507\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2507 - val_loss: 0.1737 - lr: 9.5000e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2652\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2652 - val_loss: 0.1716 - lr: 9.0250e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2150\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2150 - val_loss: 0.1567 - lr: 8.5737e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2285\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2285 - val_loss: 0.1835 - lr: 8.1451e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2077\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2077 - val_loss: 0.1775 - lr: 7.7378e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2222\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2222 - val_loss: 0.1956 - lr: 7.3509e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2305\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2305 - val_loss: 0.1614 - lr: 6.9834e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2158\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2158 - val_loss: 0.1713 - lr: 6.6342e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2241\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.2241 - val_loss: 0.1800 - lr: 6.3025e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1919\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1919 - val_loss: 0.1713 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1925\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1925 - val_loss: 0.1617 - lr: 5.6880e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2004\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2004 - val_loss: 0.1660 - lr: 5.4036e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2033\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.2033 - val_loss: 0.1633 - lr: 5.1334e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2009\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.2009 - val_loss: 0.1585 - lr: 4.8767e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2013\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2013 - val_loss: 0.1720 - lr: 4.6329e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2014\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2014 - val_loss: 0.1750 - lr: 4.4013e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1848\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1848 - val_loss: 0.1809 - lr: 4.1812e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1964\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1964 - val_loss: 0.1775 - lr: 3.9721e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1866\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1866 - val_loss: 0.1680 - lr: 3.7735e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1719\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1719 - val_loss: 0.1676 - lr: 3.5849e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1801\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1801 - val_loss: 0.1779 - lr: 3.4056e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1632\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1632 - val_loss: 0.1722 - lr: 3.2353e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1734\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1734 - val_loss: 0.1922 - lr: 3.0736e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1830\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1830 - val_loss: 0.1902 - lr: 2.9199e-04\n",
      "Epoch 38: early stopping\n",
      "2/2 [==============================] - 8s 128ms/step\n",
      "0.2773, 0.1553, 0.2580\n",
      "______fold 4______, ________repeat 2__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 820ms/step - loss: 0.5047 - val_loss: 0.4643 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.4619 - val_loss: 0.4594 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.4565 - val_loss: 0.4452 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.4474 - val_loss: 0.4270 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.4324 - val_loss: 0.4079 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.4257 - val_loss: 0.3965 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.4142 - val_loss: 0.3665 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4014\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.4014 - val_loss: 0.3697 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.4079 - val_loss: 0.3511 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.3703 - val_loss: 0.3370 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.3446 - val_loss: 0.2815 - lr: 9.5000e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 8s 435ms/step - loss: 0.3200 - val_loss: 0.1993 - lr: 9.5000e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.2802 - val_loss: 0.1634 - lr: 9.5000e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 8s 435ms/step - loss: 0.2550 - val_loss: 0.1549 - lr: 9.5000e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2655\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2655 - val_loss: 0.1974 - lr: 9.5000e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2829\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2829 - val_loss: 0.1789 - lr: 9.0250e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2551\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2551 - val_loss: 0.1571 - lr: 8.5737e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2509\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2509 - val_loss: 0.1706 - lr: 8.1451e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2340\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2340 - val_loss: 0.1609 - lr: 7.7378e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2210\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2210 - val_loss: 0.1623 - lr: 7.3509e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2538\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2538 - val_loss: 0.1617 - lr: 6.9834e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2089\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2089 - val_loss: 0.1902 - lr: 6.6342e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2175\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2175 - val_loss: 0.1831 - lr: 6.3025e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2070\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2070 - val_loss: 0.1852 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2049\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2049 - val_loss: 0.1880 - lr: 5.6880e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2091\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2091 - val_loss: 0.1719 - lr: 5.4036e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1960\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1960 - val_loss: 0.1647 - lr: 5.1334e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2028 - val_loss: 0.1520 - lr: 4.8767e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1870\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1870 - val_loss: 0.1613 - lr: 4.8767e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2003\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2003 - val_loss: 0.1866 - lr: 4.6329e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1874\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1874 - val_loss: 0.1835 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1750\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1750 - val_loss: 0.1663 - lr: 4.1812e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1617\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1617 - val_loss: 0.1746 - lr: 3.9721e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1770\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1770 - val_loss: 0.1704 - lr: 3.7735e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1471\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1471 - val_loss: 0.1768 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1698\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1698 - val_loss: 0.1861 - lr: 3.4056e-04\n",
      "Epoch 37/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.1560\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1560 - val_loss: 0.1855 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1578\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1578 - val_loss: 0.1848 - lr: 3.0736e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1768\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1768 - val_loss: 0.1870 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1651\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1651 - val_loss: 0.1874 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1744\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1744 - val_loss: 0.1873 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1547\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1547 - val_loss: 0.1860 - lr: 2.5034e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1740\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1740 - val_loss: 0.1828 - lr: 2.3783e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1612\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1612 - val_loss: 0.1988 - lr: 2.2594e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1705\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1705 - val_loss: 0.1936 - lr: 2.1464e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1565\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1565 - val_loss: 0.1829 - lr: 2.0391e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1495\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1495 - val_loss: 0.1765 - lr: 1.9371e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1559\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1559 - val_loss: 0.1658 - lr: 1.8403e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1498\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1498 - val_loss: 0.1644 - lr: 1.7482e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1345\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1345 - val_loss: 0.1651 - lr: 1.6608e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1550\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1550 - val_loss: 0.1654 - lr: 1.5778e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1388\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1388 - val_loss: 0.1683 - lr: 1.4989e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1565\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.1565 - val_loss: 0.1712 - lr: 1.4240e-04\n",
      "Epoch 53: early stopping\n",
      "2/2 [==============================] - 6s 129ms/step\n",
      "0.2028, 0.1520, 0.2186\n",
      "______fold 4______, ________repeat 3__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 865ms/step - loss: 0.5126 - val_loss: 0.4689 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.4621 - val_loss: 0.4574 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.4548 - val_loss: 0.4467 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.4517 - val_loss: 0.4328 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.4415 - val_loss: 0.4159 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4300 - val_loss: 0.4019 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.4079 - val_loss: 0.3921 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.4085 - val_loss: 0.3572 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3907 - val_loss: 0.3513 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3653\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.3653 - val_loss: 0.3537 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.3698 - val_loss: 0.3349 - lr: 9.5000e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.3363 - val_loss: 0.3045 - lr: 9.5000e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.2896 - val_loss: 0.2350 - lr: 9.5000e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 8s 422ms/step - loss: 0.2930 - val_loss: 0.2120 - lr: 9.5000e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 8s 429ms/step - loss: 0.3089 - val_loss: 0.2046 - lr: 9.5000e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2599\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2599 - val_loss: 0.2150 - lr: 9.5000e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.2518 - val_loss: 0.1983 - lr: 9.0250e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2381\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2381 - val_loss: 0.2179 - lr: 9.0250e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2283\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2283 - val_loss: 0.2035 - lr: 8.5737e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2480\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2480 - val_loss: 0.1991 - lr: 8.1451e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2497\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2497 - val_loss: 0.2010 - lr: 7.7378e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2201\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2201 - val_loss: 0.2038 - lr: 7.3509e-04\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.2147\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2147 - val_loss: 0.1987 - lr: 6.9834e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2276\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2276 - val_loss: 0.2260 - lr: 6.6342e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2096\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2096 - val_loss: 0.2289 - lr: 6.3025e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2174\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2174 - val_loss: 0.2177 - lr: 5.9874e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2106\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2106 - val_loss: 0.2115 - lr: 5.6880e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2249\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2249 - val_loss: 0.2096 - lr: 5.4036e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1849\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1849 - val_loss: 0.2216 - lr: 5.1334e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1935\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1935 - val_loss: 0.2218 - lr: 4.8767e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1848\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1848 - val_loss: 0.2122 - lr: 4.6329e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1769\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1769 - val_loss: 0.2172 - lr: 4.4013e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1813\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1813 - val_loss: 0.2268 - lr: 4.1812e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1767\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1767 - val_loss: 0.2234 - lr: 3.9721e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1750\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1750 - val_loss: 0.2258 - lr: 3.7735e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1777\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1777 - val_loss: 0.2209 - lr: 3.5849e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1724\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1724 - val_loss: 0.2164 - lr: 3.4056e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1596\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1596 - val_loss: 0.2086 - lr: 3.2353e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1610\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1610 - val_loss: 0.2037 - lr: 3.0736e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1628\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1628 - val_loss: 0.2232 - lr: 2.9199e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1698\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1698 - val_loss: 0.2123 - lr: 2.7739e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1773\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1773 - val_loss: 0.2134 - lr: 2.6352e-04\n",
      "Epoch 42: early stopping\n",
      "2/2 [==============================] - 6s 124ms/step\n",
      "0.2518, 0.1983, 0.3694\n",
      "______fold 4______, ________repeat 4__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 826ms/step - loss: 0.4861 - val_loss: 0.4632 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.4584 - val_loss: 0.4516 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.4458 - val_loss: 0.4229 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.4401 - val_loss: 0.4006 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.4253 - val_loss: 0.3820 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.4206 - val_loss: 0.3570 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.4044 - val_loss: 0.3245 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.3700 - val_loss: 0.2689 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.3235 - val_loss: 0.2132 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3190 - val_loss: 0.1956 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2744 - val_loss: 0.1924 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2834 - val_loss: 0.1898 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2608 - val_loss: 0.1729 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2624 - val_loss: 0.1448 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2654\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2654 - val_loss: 0.1491 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2222\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2222 - val_loss: 0.1524 - lr: 9.5000e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2380\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2380 - val_loss: 0.1507 - lr: 9.0250e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2094\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2094 - val_loss: 0.1633 - lr: 8.5737e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2121\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2121 - val_loss: 0.1507 - lr: 8.1451e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2288\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2288 - val_loss: 0.1600 - lr: 7.7378e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2335\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2335 - val_loss: 0.1815 - lr: 7.3509e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2075\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2075 - val_loss: 0.1538 - lr: 6.9834e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1974\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1974 - val_loss: 0.1673 - lr: 6.6342e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1984\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1984 - val_loss: 0.1478 - lr: 6.3025e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1833\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1833 - val_loss: 0.1468 - lr: 5.9874e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1871 - val_loss: 0.1439 - lr: 5.6880e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1699\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1699 - val_loss: 0.1488 - lr: 5.6880e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1789 - val_loss: 0.1399 - lr: 5.4036e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1621\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1621 - val_loss: 0.1593 - lr: 5.4036e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1808\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1808 - val_loss: 0.1837 - lr: 5.1334e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1630\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1630 - val_loss: 0.1795 - lr: 4.8767e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1693\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1693 - val_loss: 0.1778 - lr: 4.6329e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1580\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1580 - val_loss: 0.1691 - lr: 4.4013e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1567\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1567 - val_loss: 0.1679 - lr: 4.1812e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1696\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1696 - val_loss: 0.1689 - lr: 3.9721e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1575\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1575 - val_loss: 0.1567 - lr: 3.7735e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1550\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1550 - val_loss: 0.1619 - lr: 3.5849e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1543\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1543 - val_loss: 0.1662 - lr: 3.4056e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1751\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1751 - val_loss: 0.1709 - lr: 3.2353e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1507\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1507 - val_loss: 0.1686 - lr: 3.0736e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1274\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1274 - val_loss: 0.1684 - lr: 2.9199e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1490\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1490 - val_loss: 0.1618 - lr: 2.7739e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1482\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1482 - val_loss: 0.1676 - lr: 2.6352e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1238\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1238 - val_loss: 0.1756 - lr: 2.5034e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1413\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1413 - val_loss: 0.1794 - lr: 2.3783e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1415\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1415 - val_loss: 0.1815 - lr: 2.2594e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1354\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1354 - val_loss: 0.1759 - lr: 2.1464e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1203\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1203 - val_loss: 0.1732 - lr: 2.0391e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1332\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1332 - val_loss: 0.1681 - lr: 1.9371e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1177\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1177 - val_loss: 0.1745 - lr: 1.8403e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1274\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1274 - val_loss: 0.1794 - lr: 1.7482e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1219\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1219 - val_loss: 0.1807 - lr: 1.6608e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1224\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1224 - val_loss: 0.1800 - lr: 1.5778e-04\n",
      "Epoch 53: early stopping\n",
      "2/2 [==============================] - 6s 126ms/step\n",
      "0.1789, 0.1399, 0.1995\n",
      "______fold 4______, ________repeat 5__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 826ms/step - loss: 0.4877 - val_loss: 0.4649 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.4591 - val_loss: 0.4547 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.4428 - val_loss: 0.3939 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4429\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.4429 - val_loss: 0.4110 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.4062 - val_loss: 0.3805 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3884 - val_loss: 0.2828 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.3373 - val_loss: 0.2784 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.3478 - val_loss: 0.2385 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.3259 - val_loss: 0.1947 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3146\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.3146 - val_loss: 0.2154 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2827\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2827 - val_loss: 0.2252 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2709 - val_loss: 0.1486 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2673\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2673 - val_loss: 0.1504 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2608\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2608 - val_loss: 0.1856 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2486\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2486 - val_loss: 0.1767 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2531 - val_loss: 0.1470 - lr: 7.3509e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2479\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.2479 - val_loss: 0.1617 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2455\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2455 - val_loss: 0.1568 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2220\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2220 - val_loss: 0.1495 - lr: 6.6342e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2284\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2284 - val_loss: 0.1688 - lr: 6.3025e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2235\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2235 - val_loss: 0.1511 - lr: 5.9874e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2051 - val_loss: 0.1420 - lr: 5.6880e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2265\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2265 - val_loss: 0.2241 - lr: 5.6880e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2087\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2087 - val_loss: 0.1476 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2096\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2096 - val_loss: 0.1678 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2072\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2072 - val_loss: 0.1533 - lr: 4.8767e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1926\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1926 - val_loss: 0.1748 - lr: 4.6329e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1936\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1936 - val_loss: 0.1851 - lr: 4.4013e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1732\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1732 - val_loss: 0.1524 - lr: 4.1812e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1935\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1935 - val_loss: 0.1493 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1744\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1744 - val_loss: 0.1768 - lr: 3.7735e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1772\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1772 - val_loss: 0.1460 - lr: 3.5849e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1820\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1820 - val_loss: 0.1775 - lr: 3.4056e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1722\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1722 - val_loss: 0.1827 - lr: 3.2353e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1696\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1696 - val_loss: 0.1628 - lr: 3.0736e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1717\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1717 - val_loss: 0.1716 - lr: 2.9199e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1687\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1687 - val_loss: 0.1795 - lr: 2.7739e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1760\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1760 - val_loss: 0.1797 - lr: 2.6352e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1697\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1697 - val_loss: 0.1817 - lr: 2.5034e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1730\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1730 - val_loss: 0.1718 - lr: 2.3783e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1679\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1679 - val_loss: 0.1844 - lr: 2.2594e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1668\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1668 - val_loss: 0.1601 - lr: 2.1464e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1590\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1590 - val_loss: 0.1650 - lr: 2.0391e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1611\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1611 - val_loss: 0.1519 - lr: 1.9371e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1672\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1672 - val_loss: 0.1804 - lr: 1.8403e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1684\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1684 - val_loss: 0.1736 - lr: 1.7482e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1517\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.1517 - val_loss: 0.1503 - lr: 1.6608e-04\n",
      "Epoch 47: early stopping\n",
      "2/2 [==============================] - 6s 124ms/step\n",
      "0.2051, 0.1420, 0.2031\n",
      "______fold 4______, ________repeat 6__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 827ms/step - loss: 0.4916 - val_loss: 0.4639 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 418ms/step - loss: 0.4600 - val_loss: 0.4463 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 8s 443ms/step - loss: 0.4455 - val_loss: 0.4231 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.4292 - val_loss: 0.3839 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.3984 - val_loss: 0.3811 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.3937 - val_loss: 0.3534 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.3830 - val_loss: 0.3263 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 8s 417ms/step - loss: 0.3558 - val_loss: 0.2620 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.3314 - val_loss: 0.2317 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.3157 - val_loss: 0.1882 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2928\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2928 - val_loss: 0.2452 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3070\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.3070 - val_loss: 0.1927 - lr: 9.5000e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2786 - val_loss: 0.1867 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2852 - val_loss: 0.1734 - lr: 9.0250e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.2675 - val_loss: 0.1728 - lr: 9.0250e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.2512 - val_loss: 0.1606 - lr: 9.0250e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2589\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2589 - val_loss: 0.1820 - lr: 9.0250e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2401\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2401 - val_loss: 0.2047 - lr: 8.5737e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2358\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2358 - val_loss: 0.1900 - lr: 8.1451e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2455\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2455 - val_loss: 0.1694 - lr: 7.7378e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2298 - val_loss: 0.1522 - lr: 7.3509e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2206 - val_loss: 0.1434 - lr: 7.3509e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2354\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2354 - val_loss: 0.1796 - lr: 7.3509e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2199\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2199 - val_loss: 0.1811 - lr: 6.9834e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2016 - val_loss: 0.1376 - lr: 6.6342e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2243\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2243 - val_loss: 0.1449 - lr: 6.6342e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1942\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1942 - val_loss: 0.1452 - lr: 6.3025e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2078\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2078 - val_loss: 0.1468 - lr: 5.9874e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2114\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2114 - val_loss: 0.1571 - lr: 5.6880e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1866\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1866 - val_loss: 0.1533 - lr: 5.4036e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1928\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1928 - val_loss: 0.1520 - lr: 5.1334e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1943\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1943 - val_loss: 0.1513 - lr: 4.8767e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1772\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1772 - val_loss: 0.1491 - lr: 4.6329e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1871\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1871 - val_loss: 0.1445 - lr: 4.4013e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1793\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1793 - val_loss: 0.1518 - lr: 4.1812e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1744\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1744 - val_loss: 0.1465 - lr: 3.9721e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1776\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1776 - val_loss: 0.1478 - lr: 3.7735e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1774\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1774 - val_loss: 0.1445 - lr: 3.5849e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1745\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1745 - val_loss: 0.1488 - lr: 3.4056e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1784\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1784 - val_loss: 0.1523 - lr: 3.2353e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1864\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1864 - val_loss: 0.1428 - lr: 3.0736e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1580\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1580 - val_loss: 0.1449 - lr: 2.9199e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1738\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1738 - val_loss: 0.1551 - lr: 2.7739e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1683\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1683 - val_loss: 0.1565 - lr: 2.6352e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1631\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1631 - val_loss: 0.1565 - lr: 2.5034e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1744\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1744 - val_loss: 0.1541 - lr: 2.3783e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1602\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1602 - val_loss: 0.1544 - lr: 2.2594e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1621\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1621 - val_loss: 0.1534 - lr: 2.1464e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1639\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1639 - val_loss: 0.1503 - lr: 2.0391e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1596\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1596 - val_loss: 0.1444 - lr: 1.9371e-04\n",
      "Epoch 50: early stopping\n",
      "2/2 [==============================] - 6s 123ms/step\n",
      "0.2016, 0.1376, 0.1626\n",
      "______fold 4______, ________repeat 7__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 822ms/step - loss: 0.4788 - val_loss: 0.4438 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.4382 - val_loss: 0.4263 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.4349 - val_loss: 0.4157 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4165\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.4165 - val_loss: 0.4317 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.4068 - val_loss: 0.3746 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4158\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.4158 - val_loss: 0.3853 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3851\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3851 - val_loss: 0.3920 - lr: 9.0250e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3923\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.3923 - val_loss: 0.3773 - lr: 8.5737e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3992\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3992 - val_loss: 0.3962 - lr: 8.1451e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.3747 - val_loss: 0.3677 - lr: 7.7378e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.3650 - val_loss: 0.3413 - lr: 7.7378e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3552\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.3552 - val_loss: 0.3425 - lr: 7.7378e-04\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.3705\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.3705 - val_loss: 0.3663 - lr: 7.3509e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.3474 - val_loss: 0.3330 - lr: 6.9834e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3396\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.3396 - val_loss: 0.3346 - lr: 6.9834e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.3276 - val_loss: 0.3274 - lr: 6.6342e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3038\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.3038 - val_loss: 0.3805 - lr: 6.6342e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2956 - val_loss: 0.3099 - lr: 6.3025e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.3004 - val_loss: 0.2456 - lr: 6.3025e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2745\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2745 - val_loss: 0.3247 - lr: 6.3025e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2949\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2949 - val_loss: 0.2827 - lr: 5.9874e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2692\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2692 - val_loss: 0.2705 - lr: 5.6880e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2637 - val_loss: 0.2415 - lr: 5.4036e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2615 - val_loss: 0.2395 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2559\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2559 - val_loss: 0.2426 - lr: 5.4036e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2323\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2323 - val_loss: 0.2431 - lr: 5.1334e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2230\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2230 - val_loss: 0.2448 - lr: 4.8767e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2288\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2288 - val_loss: 0.2535 - lr: 4.6329e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2289 - val_loss: 0.2387 - lr: 4.4013e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2351\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 418ms/step - loss: 0.2351 - val_loss: 0.2505 - lr: 4.4013e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1995 - val_loss: 0.2351 - lr: 4.1812e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2186\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 415ms/step - loss: 0.2186 - val_loss: 0.2368 - lr: 4.1812e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2054 - val_loss: 0.2270 - lr: 3.9721e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2149 - val_loss: 0.2256 - lr: 3.9721e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1947\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1947 - val_loss: 0.2348 - lr: 3.9721e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2004\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2004 - val_loss: 0.2291 - lr: 3.7735e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1922\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1922 - val_loss: 0.2332 - lr: 3.5849e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1862 - val_loss: 0.2154 - lr: 3.4056e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2024\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2024 - val_loss: 0.2438 - lr: 3.4056e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2073\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2073 - val_loss: 0.2254 - lr: 3.2353e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1797\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1797 - val_loss: 0.2183 - lr: 3.0736e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1943\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1943 - val_loss: 0.2250 - lr: 2.9199e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1839\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1839 - val_loss: 0.2213 - lr: 2.7739e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1797 - val_loss: 0.2141 - lr: 2.6352e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1905\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1905 - val_loss: 0.2306 - lr: 2.6352e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1837\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1837 - val_loss: 0.2253 - lr: 2.5034e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1801\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1801 - val_loss: 0.2358 - lr: 2.3783e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1781\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1781 - val_loss: 0.2298 - lr: 2.2594e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1807\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1807 - val_loss: 0.2385 - lr: 2.1464e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1856\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1856 - val_loss: 0.2418 - lr: 2.0391e-04\n",
      "Epoch 51/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.1773\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1773 - val_loss: 0.2411 - lr: 1.9371e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1779\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1779 - val_loss: 0.2427 - lr: 1.8403e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1857\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1857 - val_loss: 0.2512 - lr: 1.7482e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1727\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1727 - val_loss: 0.2368 - lr: 1.6608e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1727\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1727 - val_loss: 0.2281 - lr: 1.5778e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1636\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1636 - val_loss: 0.2146 - lr: 1.4989e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1960\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1960 - val_loss: 0.2222 - lr: 1.4240e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1722\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1722 - val_loss: 0.2161 - lr: 1.3528e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1702\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1702 - val_loss: 0.2224 - lr: 1.2851e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1592\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1592 - val_loss: 0.2245 - lr: 1.2209e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1633\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1633 - val_loss: 0.2208 - lr: 1.1598e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1592\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1592 - val_loss: 0.2221 - lr: 1.1018e-04\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1635\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1635 - val_loss: 0.2219 - lr: 1.0467e-04\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1668\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1668 - val_loss: 0.2240 - lr: 9.9440e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1655\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1655 - val_loss: 0.2201 - lr: 9.4468e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1433\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1433 - val_loss: 0.2245 - lr: 8.9745e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1602\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1602 - val_loss: 0.2230 - lr: 8.5258e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1704\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1704 - val_loss: 0.2288 - lr: 8.0995e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1539\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1539 - val_loss: 0.2236 - lr: 7.6945e-05\n",
      "Epoch 69: early stopping\n",
      "2/2 [==============================] - 8s 129ms/step\n",
      "0.1797, 0.2141, 0.3066\n",
      "______fold 4______, ________repeat 8__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 796ms/step - loss: 0.4882 - val_loss: 0.4384 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 423ms/step - loss: 0.4426 - val_loss: 0.4190 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 8s 427ms/step - loss: 0.4294 - val_loss: 0.4048 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 5s 284ms/step - loss: 0.3996 - val_loss: 0.3910 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4268\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.4268 - val_loss: 0.3961 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.3691 - val_loss: 0.3699 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3602\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.3602 - val_loss: 0.3756 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 413ms/step - loss: 0.3457 - val_loss: 0.3219 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.3311 - val_loss: 0.3101 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3376\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.3376 - val_loss: 0.3516 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3224\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.3224 - val_loss: 0.3639 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.3161 - val_loss: 0.2887 - lr: 8.1451e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2935\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 414ms/step - loss: 0.2935 - val_loss: 0.3387 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2904\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2904 - val_loss: 0.3339 - lr: 7.7378e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.2754 - val_loss: 0.2816 - lr: 7.3509e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2823\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2823 - val_loss: 0.3360 - lr: 7.3509e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2684\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2684 - val_loss: 0.3399 - lr: 6.9834e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2601\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.2601 - val_loss: 0.3082 - lr: 6.6342e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 414ms/step - loss: 0.2394 - val_loss: 0.2814 - lr: 6.3025e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2309\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 8s 423ms/step - loss: 0.2309 - val_loss: 0.3442 - lr: 6.3025e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.2633 - val_loss: 0.2278 - lr: 5.9874e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.2407 - val_loss: 0.2260 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2383\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2383 - val_loss: 0.2938 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2403\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2403 - val_loss: 0.2945 - lr: 5.6880e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2229 - val_loss: 0.2060 - lr: 5.4036e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.2134 - val_loss: 0.1736 - lr: 5.4036e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1983\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 8s 424ms/step - loss: 0.1983 - val_loss: 0.2172 - lr: 5.4036e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2028\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 412ms/step - loss: 0.2028 - val_loss: 0.2322 - lr: 5.1334e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2021\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2021 - val_loss: 0.1908 - lr: 4.8767e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1882\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1882 - val_loss: 0.2045 - lr: 4.6329e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1953\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1953 - val_loss: 0.1935 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.1911 - val_loss: 0.1526 - lr: 4.1812e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1845\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1845 - val_loss: 0.1865 - lr: 4.1812e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1794\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1794 - val_loss: 0.1788 - lr: 3.9721e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1778\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.1778 - val_loss: 0.1742 - lr: 3.7735e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 8s 428ms/step - loss: 0.1785 - val_loss: 0.1383 - lr: 3.5849e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1629\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1629 - val_loss: 0.1876 - lr: 3.5849e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1769\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1769 - val_loss: 0.1517 - lr: 3.4056e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1683\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1683 - val_loss: 0.1476 - lr: 3.2353e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.1610 - val_loss: 0.1375 - lr: 3.0736e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1655\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.1655 - val_loss: 0.1718 - lr: 3.0736e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1755\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1755 - val_loss: 0.1943 - lr: 2.9199e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1707 - val_loss: 0.1283 - lr: 2.7739e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1799\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1799 - val_loss: 0.1663 - lr: 2.7739e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1745\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1745 - val_loss: 0.1741 - lr: 2.6352e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1543\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1543 - val_loss: 0.1513 - lr: 2.5034e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1628\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.1628 - val_loss: 0.1690 - lr: 2.3783e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1477\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1477 - val_loss: 0.1393 - lr: 2.2594e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1538\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1538 - val_loss: 0.1637 - lr: 2.1464e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1506\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1506 - val_loss: 0.1643 - lr: 2.0391e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1407\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1407 - val_loss: 0.1602 - lr: 1.9371e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1477\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1477 - val_loss: 0.1622 - lr: 1.8403e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1656\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1656 - val_loss: 0.1438 - lr: 1.7482e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1422\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1422 - val_loss: 0.1558 - lr: 1.6608e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1638\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1638 - val_loss: 0.1611 - lr: 1.5778e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1537\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1537 - val_loss: 0.1729 - lr: 1.4989e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1483\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1483 - val_loss: 0.1539 - lr: 1.4240e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1364\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 418ms/step - loss: 0.1364 - val_loss: 0.1552 - lr: 1.3528e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1535\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 8s 421ms/step - loss: 0.1535 - val_loss: 0.1417 - lr: 1.2851e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1263\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1263 - val_loss: 0.1548 - lr: 1.2209e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1449\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1449 - val_loss: 0.1432 - lr: 1.1598e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1453\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1453 - val_loss: 0.1436 - lr: 1.1018e-04\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1506\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1506 - val_loss: 0.1566 - lr: 1.0467e-04\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1356\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1356 - val_loss: 0.1546 - lr: 9.9440e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1251\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1251 - val_loss: 0.1548 - lr: 9.4468e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1350\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1350 - val_loss: 0.1545 - lr: 8.9745e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1407\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1407 - val_loss: 0.1348 - lr: 8.5258e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1253\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.1253 - val_loss: 0.1480 - lr: 8.0995e-05\n",
      "Epoch 68: early stopping\n",
      "2/2 [==============================] - 6s 122ms/step\n",
      "0.1707, 0.1283, 0.1757\n",
      "______fold 4______, ________repeat 9__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 865ms/step - loss: 0.4970 - val_loss: 0.4698 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 412ms/step - loss: 0.4597 - val_loss: 0.4603 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.4557 - val_loss: 0.4445 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 8s 433ms/step - loss: 0.4488 - val_loss: 0.4279 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.4385 - val_loss: 0.4051 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.4353 - val_loss: 0.3410 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.4179 - val_loss: 0.3123 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.3912 - val_loss: 0.3033 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.3683 - val_loss: 0.2946 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3855\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.3855 - val_loss: 0.3641 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3485\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.3485 - val_loss: 0.3399 - lr: 9.5000e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.3315 - val_loss: 0.2386 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2980\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2980 - val_loss: 0.3066 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.2872 - val_loss: 0.2238 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2618\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2618 - val_loss: 0.2244 - lr: 8.5737e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.2427 - val_loss: 0.1987 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2831\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2831 - val_loss: 0.2193 - lr: 8.1451e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2793\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2793 - val_loss: 0.2177 - lr: 7.7378e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2328 - val_loss: 0.1923 - lr: 7.3509e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2546\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2546 - val_loss: 0.2060 - lr: 7.3509e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2384\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2384 - val_loss: 0.2086 - lr: 6.9834e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2297\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2297 - val_loss: 0.2093 - lr: 6.6342e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2146\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2146 - val_loss: 0.1949 - lr: 6.3025e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2178\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2178 - val_loss: 0.1987 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.2083 - val_loss: 0.1895 - lr: 5.6880e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2091\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2091 - val_loss: 0.1927 - lr: 5.6880e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1833\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1833 - val_loss: 0.1949 - lr: 5.4036e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2009\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2009 - val_loss: 0.1966 - lr: 5.1334e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1887\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1887 - val_loss: 0.1925 - lr: 4.8767e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1807\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1807 - val_loss: 0.1918 - lr: 4.6329e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.1856 - val_loss: 0.1854 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.1896 - val_loss: 0.1773 - lr: 4.4013e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1834\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1834 - val_loss: 0.1783 - lr: 4.4013e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1781\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1781 - val_loss: 0.1817 - lr: 4.1812e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1676 - val_loss: 0.1763 - lr: 3.9721e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1638 - val_loss: 0.1726 - lr: 3.9721e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1631\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1631 - val_loss: 0.1797 - lr: 3.9721e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1584\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1584 - val_loss: 0.1793 - lr: 3.7735e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1689\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1689 - val_loss: 0.1822 - lr: 3.5849e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1731\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1731 - val_loss: 0.1730 - lr: 3.4056e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1738\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1738 - val_loss: 0.1838 - lr: 3.2353e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1751\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1751 - val_loss: 0.1750 - lr: 3.0736e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1647\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1647 - val_loss: 0.1816 - lr: 2.9199e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1503\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1503 - val_loss: 0.1831 - lr: 2.7739e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1446\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1446 - val_loss: 0.1930 - lr: 2.6352e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1534\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1534 - val_loss: 0.1919 - lr: 2.5034e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1578\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1578 - val_loss: 0.1839 - lr: 2.3783e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1536\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1536 - val_loss: 0.1839 - lr: 2.2594e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1403\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1403 - val_loss: 0.1879 - lr: 2.1464e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1599\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1599 - val_loss: 0.1903 - lr: 2.0391e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1501\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1501 - val_loss: 0.1875 - lr: 1.9371e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1489\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1489 - val_loss: 0.1869 - lr: 1.8403e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1715\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1715 - val_loss: 0.1881 - lr: 1.7482e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1309\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1309 - val_loss: 0.1900 - lr: 1.6608e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1553\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1553 - val_loss: 0.1864 - lr: 1.5778e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1296\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1296 - val_loss: 0.1865 - lr: 1.4989e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1349\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1349 - val_loss: 0.1906 - lr: 1.4240e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1381\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1381 - val_loss: 0.1871 - lr: 1.3528e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1568\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1568 - val_loss: 0.1842 - lr: 1.2851e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1562\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1562 - val_loss: 0.1845 - lr: 1.2209e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1425\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.1425 - val_loss: 0.1849 - lr: 1.1598e-04\n",
      "Epoch 61: early stopping\n",
      "2/2 [==============================] - 6s 139ms/step\n",
      "0.1638, 0.1726, 0.2971\n",
      "______fold 4______, ________repeat 10__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 824ms/step - loss: 0.4794 - val_loss: 0.4541 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.4397 - val_loss: 0.4099 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.4277 - val_loss: 0.3809 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4173\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 412ms/step - loss: 0.4173 - val_loss: 0.3914 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.4180 - val_loss: 0.3781 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4119\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.4119 - val_loss: 0.3846 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3935\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.3935 - val_loss: 0.3828 - lr: 9.0250e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 8s 428ms/step - loss: 0.3837 - val_loss: 0.3692 - lr: 8.5737e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3868\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.3868 - val_loss: 0.3714 - lr: 8.5737e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3641\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.3641 - val_loss: 0.3704 - lr: 8.1451e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.3629 - val_loss: 0.3411 - lr: 7.7378e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 8s 423ms/step - loss: 0.3280 - val_loss: 0.2654 - lr: 7.7378e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 8s 424ms/step - loss: 0.3012 - val_loss: 0.2568 - lr: 7.7378e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 8s 422ms/step - loss: 0.2768 - val_loss: 0.2404 - lr: 7.7378e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 8s 428ms/step - loss: 0.2702 - val_loss: 0.2384 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 413ms/step - loss: 0.2503 - val_loss: 0.2213 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 8s 423ms/step - loss: 0.2628 - val_loss: 0.2142 - lr: 7.7378e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2314\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2314 - val_loss: 0.2406 - lr: 7.7378e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2216\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2216 - val_loss: 0.2432 - lr: 7.3509e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2339\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2339 - val_loss: 0.2363 - lr: 6.9834e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2334 - val_loss: 0.1784 - lr: 6.6342e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.2026 - val_loss: 0.1738 - lr: 6.6342e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2111\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 8s 421ms/step - loss: 0.2111 - val_loss: 0.2068 - lr: 6.6342e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2182\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.2182 - val_loss: 0.2112 - lr: 6.3025e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2106\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2106 - val_loss: 0.1812 - lr: 5.9874e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2149\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2149 - val_loss: 0.2443 - lr: 5.6880e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2002\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2002 - val_loss: 0.2183 - lr: 5.4036e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2003\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2003 - val_loss: 0.2070 - lr: 5.1334e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1812\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1812 - val_loss: 0.1965 - lr: 4.8767e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1810\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1810 - val_loss: 0.1964 - lr: 4.6329e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1750\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1750 - val_loss: 0.1930 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1731\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1731 - val_loss: 0.2215 - lr: 4.1812e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1792\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1792 - val_loss: 0.2109 - lr: 3.9721e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1871\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1871 - val_loss: 0.1779 - lr: 3.7735e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1601 - val_loss: 0.1629 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.1849 - val_loss: 0.1576 - lr: 3.5849e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1764\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 8s 419ms/step - loss: 0.1764 - val_loss: 0.1654 - lr: 3.5849e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1632\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1632 - val_loss: 0.1698 - lr: 3.4056e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1729\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1729 - val_loss: 0.1813 - lr: 3.2353e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1702\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1702 - val_loss: 0.1703 - lr: 3.0736e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1763\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1763 - val_loss: 0.1661 - lr: 2.9199e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1615\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1615 - val_loss: 0.1655 - lr: 2.7739e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1639\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1639 - val_loss: 0.1717 - lr: 2.6352e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1559\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1559 - val_loss: 0.1619 - lr: 2.5034e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1472\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1472 - val_loss: 0.1585 - lr: 2.3783e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1406\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1406 - val_loss: 0.1579 - lr: 2.2594e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1663\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1663 - val_loss: 0.1777 - lr: 2.1464e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1382\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1382 - val_loss: 0.1636 - lr: 2.0391e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.1508 - val_loss: 0.1519 - lr: 1.9371e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1486\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1486 - val_loss: 0.1519 - lr: 1.9371e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1551\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1551 - val_loss: 0.1644 - lr: 1.8403e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1596\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1596 - val_loss: 0.1666 - lr: 1.7482e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1518\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1518 - val_loss: 0.1694 - lr: 1.6608e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1435\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1435 - val_loss: 0.1735 - lr: 1.5778e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1387\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1387 - val_loss: 0.1765 - lr: 1.4989e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1437\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1437 - val_loss: 0.1813 - lr: 1.4240e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1428\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1428 - val_loss: 0.1699 - lr: 1.3528e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1449\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1449 - val_loss: 0.1739 - lr: 1.2851e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1457\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1457 - val_loss: 0.1705 - lr: 1.2209e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1401\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1401 - val_loss: 0.1787 - lr: 1.1598e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1629\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1629 - val_loss: 0.1777 - lr: 1.1018e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1226\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1226 - val_loss: 0.1767 - lr: 1.0467e-04\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1380\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1380 - val_loss: 0.1798 - lr: 9.9440e-05\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1252\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1252 - val_loss: 0.1836 - lr: 9.4468e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1292\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1292 - val_loss: 0.1854 - lr: 8.9745e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1282\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1282 - val_loss: 0.1879 - lr: 8.5258e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1272\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.1272 - val_loss: 0.1884 - lr: 8.0995e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1273\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1273 - val_loss: 0.1821 - lr: 7.6945e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1350\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1350 - val_loss: 0.1808 - lr: 7.3098e-05\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1484\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1484 - val_loss: 0.1802 - lr: 6.9443e-05\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1287\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 8s 430ms/step - loss: 0.1287 - val_loss: 0.1821 - lr: 6.5971e-05\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1519\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1519 - val_loss: 0.1796 - lr: 6.2672e-05\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1179\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 5.656161210936261e-05.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1179 - val_loss: 0.1818 - lr: 5.9539e-05\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1227\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 5.373353305913042e-05.\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.1227 - val_loss: 0.1864 - lr: 5.6562e-05\n",
      "Epoch 74: early stopping\n",
      "2/2 [==============================] - 6s 133ms/step\n",
      "0.1508, 0.1519, 0.2232\n",
      "______fold 5______, ________repeat 1__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 827ms/step - loss: 0.4708 - val_loss: 0.4709 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4531\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.4531 - val_loss: 0.4712 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4315\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.4315 - val_loss: 0.4750 - lr: 9.5000e-04\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4163 - val_loss: 0.4537 - lr: 9.0250e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4072\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.4072 - val_loss: 0.4565 - lr: 9.0250e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3726\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.3726 - val_loss: 0.4538 - lr: 8.5737e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3701\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.3701 - val_loss: 0.4991 - lr: 8.1451e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.3526 - val_loss: 0.4287 - lr: 7.7378e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.3335 - val_loss: 0.4179 - lr: 7.7378e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.3094 - val_loss: 0.3427 - lr: 7.7378e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2808\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2808 - val_loss: 0.3646 - lr: 7.7378e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2659\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2659 - val_loss: 0.3677 - lr: 7.3509e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2877\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2877 - val_loss: 0.3493 - lr: 6.9834e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2721 - val_loss: 0.3198 - lr: 6.6342e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.2497 - val_loss: 0.2509 - lr: 6.6342e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2543\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2543 - val_loss: 0.3513 - lr: 6.6342e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2423\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2423 - val_loss: 0.2958 - lr: 6.3025e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2526\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2526 - val_loss: 0.2927 - lr: 5.9874e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2215\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2215 - val_loss: 0.3005 - lr: 5.6880e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2070\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2070 - val_loss: 0.2651 - lr: 5.4036e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2024\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2024 - val_loss: 0.2738 - lr: 5.1334e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1795\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1795 - val_loss: 0.2769 - lr: 4.8767e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1883\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1883 - val_loss: 0.2755 - lr: 4.6329e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2127\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2127 - val_loss: 0.2883 - lr: 4.4013e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1930\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1930 - val_loss: 0.2873 - lr: 4.1812e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1881\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1881 - val_loss: 0.2752 - lr: 3.9721e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1940\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1940 - val_loss: 0.2854 - lr: 3.7735e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1968\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1968 - val_loss: 0.3084 - lr: 3.5849e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2089\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2089 - val_loss: 0.2875 - lr: 3.4056e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1798\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1798 - val_loss: 0.2954 - lr: 3.2353e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1804\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1804 - val_loss: 0.2776 - lr: 3.0736e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1801\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1801 - val_loss: 0.2974 - lr: 2.9199e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1815\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1815 - val_loss: 0.2896 - lr: 2.7739e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1642\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1642 - val_loss: 0.2980 - lr: 2.6352e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1617\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1617 - val_loss: 0.2992 - lr: 2.5034e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1690\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1690 - val_loss: 0.2942 - lr: 2.3783e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1763\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1763 - val_loss: 0.3206 - lr: 2.2594e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1806\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1806 - val_loss: 0.3022 - lr: 2.1464e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1576\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1576 - val_loss: 0.2965 - lr: 2.0391e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1713\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.1713 - val_loss: 0.2957 - lr: 1.9371e-04\n",
      "Epoch 40: early stopping\n",
      "2/2 [==============================] - 6s 127ms/step\n",
      "0.2497, 0.2509, 0.5095\n",
      "______fold 5______, ________repeat 2__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 827ms/step - loss: 0.4586 - val_loss: 0.4654 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4416\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.4416 - val_loss: 0.4711 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.4185 - val_loss: 0.4648 - lr: 9.5000e-04\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 8s 443ms/step - loss: 0.4217 - val_loss: 0.4587 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4197\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.4197 - val_loss: 0.4694 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4033\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.4033 - val_loss: 0.4695 - lr: 9.0250e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.3992 - val_loss: 0.4268 - lr: 8.5737e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3853\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.3853 - val_loss: 0.4419 - lr: 8.5737e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.3769 - val_loss: 0.4141 - lr: 8.1451e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.3511 - val_loss: 0.3896 - lr: 8.1451e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.3610 - val_loss: 0.3871 - lr: 8.1451e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3413\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 8s 421ms/step - loss: 0.3413 - val_loss: 0.3925 - lr: 8.1451e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3404\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 8s 422ms/step - loss: 0.3404 - val_loss: 0.4022 - lr: 7.7378e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.3165 - val_loss: 0.3855 - lr: 7.3509e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 8s 418ms/step - loss: 0.3096 - val_loss: 0.3622 - lr: 7.3509e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 412ms/step - loss: 0.2861 - val_loss: 0.3055 - lr: 7.3509e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2652\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 8s 418ms/step - loss: 0.2652 - val_loss: 0.3118 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2538\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.2538 - val_loss: 0.3264 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2371\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.2371 - val_loss: 0.3538 - lr: 6.6342e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 413ms/step - loss: 0.2719 - val_loss: 0.2643 - lr: 6.3025e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2242\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2242 - val_loss: 0.3602 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2204\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.2204 - val_loss: 0.2782 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1926\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 412ms/step - loss: 0.1926 - val_loss: 0.2989 - lr: 5.6880e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2009\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2009 - val_loss: 0.2669 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 7s 415ms/step - loss: 0.2076 - val_loss: 0.2274 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1846\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.1846 - val_loss: 0.2391 - lr: 5.1334e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.1844 - val_loss: 0.2250 - lr: 4.8767e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1888\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1888 - val_loss: 0.2710 - lr: 4.8767e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1805\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1805 - val_loss: 0.2415 - lr: 4.6329e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1631\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1631 - val_loss: 0.2492 - lr: 4.4013e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1654\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1654 - val_loss: 0.2556 - lr: 4.1812e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1666\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1666 - val_loss: 0.2357 - lr: 3.9721e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1694\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1694 - val_loss: 0.2343 - lr: 3.7735e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1668 - val_loss: 0.2146 - lr: 3.5849e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1610\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.1610 - val_loss: 0.2161 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1552\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1552 - val_loss: 0.2357 - lr: 3.4056e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1600\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1600 - val_loss: 0.2436 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1477\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1477 - val_loss: 0.2329 - lr: 3.0736e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1559\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1559 - val_loss: 0.2591 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1494\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1494 - val_loss: 0.2218 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1649\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1649 - val_loss: 0.2663 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1505\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1505 - val_loss: 0.2533 - lr: 2.5034e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1547\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1547 - val_loss: 0.2169 - lr: 2.3783e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.1267 - val_loss: 0.2134 - lr: 2.2594e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.1362 - val_loss: 0.2068 - lr: 2.2594e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1582\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1582 - val_loss: 0.2110 - lr: 2.2594e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1470\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1470 - val_loss: 0.2359 - lr: 2.1464e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1488\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1488 - val_loss: 0.2596 - lr: 2.0391e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1421\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1421 - val_loss: 0.2506 - lr: 1.9371e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1227\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1227 - val_loss: 0.2605 - lr: 1.8403e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1202\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1202 - val_loss: 0.2604 - lr: 1.7482e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1364\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1364 - val_loss: 0.2617 - lr: 1.6608e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1308\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1308 - val_loss: 0.2764 - lr: 1.5778e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1297\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1297 - val_loss: 0.2759 - lr: 1.4989e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1222\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1222 - val_loss: 0.2907 - lr: 1.4240e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1386\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1386 - val_loss: 0.2898 - lr: 1.3528e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1228\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1228 - val_loss: 0.2993 - lr: 1.2851e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1251\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1251 - val_loss: 0.2733 - lr: 1.2209e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1295\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1295 - val_loss: 0.2756 - lr: 1.1598e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1265\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1265 - val_loss: 0.2538 - lr: 1.1018e-04\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.1301\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1301 - val_loss: 0.2854 - lr: 1.0467e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1231\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1231 - val_loss: 0.2842 - lr: 9.9440e-05\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1100\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1100 - val_loss: 0.3023 - lr: 9.4468e-05\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1348\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1348 - val_loss: 0.2934 - lr: 8.9745e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1233\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1233 - val_loss: 0.2770 - lr: 8.5258e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1366\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1366 - val_loss: 0.2795 - lr: 8.0995e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1156\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1156 - val_loss: 0.2980 - lr: 7.6945e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1316\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1316 - val_loss: 0.2762 - lr: 7.3098e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1181\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1181 - val_loss: 0.2750 - lr: 6.9443e-05\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1087\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.1087 - val_loss: 0.2549 - lr: 6.5971e-05\n",
      "Epoch 70: early stopping\n",
      "2/2 [==============================] - 6s 137ms/step\n",
      "0.1362, 0.2068, 0.4720\n",
      "______fold 5______, ________repeat 3__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 825ms/step - loss: 0.4844 - val_loss: 0.4694 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.4663 - val_loss: 0.4676 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4630 - val_loss: 0.4654 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.4569 - val_loss: 0.4597 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4406\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.4406 - val_loss: 0.4639 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.4018 - val_loss: 0.4587 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 418ms/step - loss: 0.3756 - val_loss: 0.4183 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.3392 - val_loss: 0.3897 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.3121 - val_loss: 0.3490 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2574 - val_loss: 0.3415 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2904 - val_loss: 0.3068 - lr: 9.5000e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3019\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3019 - val_loss: 0.4308 - lr: 9.5000e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2988\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2988 - val_loss: 0.3182 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2643\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2643 - val_loss: 0.3188 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2444\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2444 - val_loss: 0.3325 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2127\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2127 - val_loss: 0.3136 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1987 - val_loss: 0.3038 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2182\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.2182 - val_loss: 0.3102 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2046 - val_loss: 0.2891 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2016\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.2016 - val_loss: 0.3112 - lr: 6.9834e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1926\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1926 - val_loss: 0.3016 - lr: 6.6342e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1921\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1921 - val_loss: 0.2970 - lr: 6.3025e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1946\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 8s 427ms/step - loss: 0.1946 - val_loss: 0.2966 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1901\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.1901 - val_loss: 0.3014 - lr: 5.6880e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2036\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2036 - val_loss: 0.2991 - lr: 5.4036e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2018\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2018 - val_loss: 0.2972 - lr: 5.1334e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1837\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1837 - val_loss: 0.2904 - lr: 4.8767e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1776\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1776 - val_loss: 0.3079 - lr: 4.6329e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1654\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1654 - val_loss: 0.2949 - lr: 4.4013e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1768\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1768 - val_loss: 0.2896 - lr: 4.1812e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1717\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1717 - val_loss: 0.3295 - lr: 3.9721e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1486 - val_loss: 0.2619 - lr: 3.7735e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1607\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.1607 - val_loss: 0.2857 - lr: 3.7735e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1573\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1573 - val_loss: 0.2996 - lr: 3.5849e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1363\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1363 - val_loss: 0.2979 - lr: 3.4056e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1610\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1610 - val_loss: 0.3146 - lr: 3.2353e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1698\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1698 - val_loss: 0.3063 - lr: 3.0736e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1400\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1400 - val_loss: 0.3117 - lr: 2.9199e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1462\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1462 - val_loss: 0.3125 - lr: 2.7739e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1519\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1519 - val_loss: 0.3051 - lr: 2.6352e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1637\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1637 - val_loss: 0.3234 - lr: 2.5034e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1501\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1501 - val_loss: 0.3111 - lr: 2.3783e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1395\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1395 - val_loss: 0.3116 - lr: 2.2594e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1484\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1484 - val_loss: 0.3150 - lr: 2.1464e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1457\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1457 - val_loss: 0.3090 - lr: 2.0391e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1508\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1508 - val_loss: 0.3182 - lr: 1.9371e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1409\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1409 - val_loss: 0.3056 - lr: 1.8403e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1473\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1473 - val_loss: 0.2987 - lr: 1.7482e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1429\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1429 - val_loss: 0.2843 - lr: 1.6608e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1426\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1426 - val_loss: 0.2822 - lr: 1.5778e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1206\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1206 - val_loss: 0.2863 - lr: 1.4989e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1531\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1531 - val_loss: 0.2935 - lr: 1.4240e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1390\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1390 - val_loss: 0.3017 - lr: 1.3528e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1403\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1403 - val_loss: 0.2881 - lr: 1.2851e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1360\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1360 - val_loss: 0.2939 - lr: 1.2209e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1358\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1358 - val_loss: 0.2847 - lr: 1.1598e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1251\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.1251 - val_loss: 0.2795 - lr: 1.1018e-04\n",
      "Epoch 57: early stopping\n",
      "2/2 [==============================] - 8s 126ms/step\n",
      "0.1486, 0.2619, 0.5939\n",
      "______fold 5______, ________repeat 4__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 819ms/step - loss: 0.5004 - val_loss: 0.4629 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.4590 - val_loss: 0.4567 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.4321 - val_loss: 0.4479 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.4228 - val_loss: 0.4461 - lr: 0.0010\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 8s 441ms/step - loss: 0.4063 - val_loss: 0.4374 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.3562 - val_loss: 0.4079 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3278\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 418ms/step - loss: 0.3278 - val_loss: 0.4490 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3163\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.3163 - val_loss: 0.4343 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3262 - val_loss: 0.3981 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.2780 - val_loss: 0.3617 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2749 - val_loss: 0.3388 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2559\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2559 - val_loss: 0.3581 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2762\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2762 - val_loss: 0.3422 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2498\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2498 - val_loss: 0.3540 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2742\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2742 - val_loss: 0.3492 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2288\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2288 - val_loss: 0.3466 - lr: 7.3509e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.2338 - val_loss: 0.3224 - lr: 6.9834e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2310\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2310 - val_loss: 0.3287 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.2169 - val_loss: 0.2907 - lr: 6.6342e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 412ms/step - loss: 0.2134 - val_loss: 0.2834 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.2004 - val_loss: 0.2705 - lr: 6.6342e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2034\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2034 - val_loss: 0.2786 - lr: 6.6342e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1807\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1807 - val_loss: 0.3217 - lr: 6.3025e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.1938 - val_loss: 0.2377 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1936\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1936 - val_loss: 0.3093 - lr: 5.9874e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1780\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 414ms/step - loss: 0.1780 - val_loss: 0.2579 - lr: 5.6880e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1856\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1856 - val_loss: 0.2623 - lr: 5.4036e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1869\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1869 - val_loss: 0.2699 - lr: 5.1334e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1733\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1733 - val_loss: 0.2894 - lr: 4.8767e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1736\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1736 - val_loss: 0.2736 - lr: 4.6329e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1652\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1652 - val_loss: 0.2683 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1618\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1618 - val_loss: 0.2447 - lr: 4.1812e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1705\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1705 - val_loss: 0.2651 - lr: 3.9721e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1527\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1527 - val_loss: 0.2728 - lr: 3.7735e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1630\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1630 - val_loss: 0.2671 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1579\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1579 - val_loss: 0.2658 - lr: 3.4056e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1534\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1534 - val_loss: 0.2745 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1488\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1488 - val_loss: 0.2613 - lr: 3.0736e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1395\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1395 - val_loss: 0.2629 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1499\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1499 - val_loss: 0.2564 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1455\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1455 - val_loss: 0.2804 - lr: 2.6352e-04\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.1431\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1431 - val_loss: 0.2549 - lr: 2.5034e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1458\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1458 - val_loss: 0.2569 - lr: 2.3783e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1392\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1392 - val_loss: 0.2640 - lr: 2.2594e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1331\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1331 - val_loss: 0.2507 - lr: 2.1464e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1526\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1526 - val_loss: 0.2582 - lr: 2.0391e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1318\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1318 - val_loss: 0.2427 - lr: 1.9371e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1384\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1384 - val_loss: 0.2503 - lr: 1.8403e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1316\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.1316 - val_loss: 0.2434 - lr: 1.7482e-04\n",
      "Epoch 49: early stopping\n",
      "2/2 [==============================] - 6s 126ms/step\n",
      "0.1938, 0.2377, 0.4428\n",
      "______fold 5______, ________repeat 5__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 865ms/step - loss: 0.4643 - val_loss: 0.4635 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4416\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.4416 - val_loss: 0.4668 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4304\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.4304 - val_loss: 0.4702 - lr: 9.5000e-04\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4195\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.4195 - val_loss: 0.4656 - lr: 9.0250e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4327 - val_loss: 0.4489 - lr: 8.5737e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3927\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.3927 - val_loss: 0.4562 - lr: 8.5737e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.3889 - val_loss: 0.4017 - lr: 8.1451e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3702\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.3702 - val_loss: 0.4114 - lr: 8.1451e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3660\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.3660 - val_loss: 0.4120 - lr: 7.7378e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3224\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3224 - val_loss: 0.4354 - lr: 7.3509e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.3350 - val_loss: 0.3797 - lr: 6.9834e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2821 - val_loss: 0.3531 - lr: 6.9834e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2669\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2669 - val_loss: 0.3822 - lr: 6.9834e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2851\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2851 - val_loss: 0.3922 - lr: 6.6342e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2771\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2771 - val_loss: 0.3540 - lr: 6.3025e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2572 - val_loss: 0.3436 - lr: 5.9874e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 8s 431ms/step - loss: 0.2249 - val_loss: 0.3366 - lr: 5.9874e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2369 - val_loss: 0.2858 - lr: 5.9874e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2246\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.2246 - val_loss: 0.3126 - lr: 5.9874e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2182\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.2182 - val_loss: 0.3173 - lr: 5.6880e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2191\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2191 - val_loss: 0.3008 - lr: 5.4036e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2168\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2168 - val_loss: 0.2883 - lr: 5.1334e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1994\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1994 - val_loss: 0.3050 - lr: 4.8767e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1979 - val_loss: 0.2694 - lr: 4.6329e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1962 - val_loss: 0.2633 - lr: 4.6329e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1779\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1779 - val_loss: 0.2826 - lr: 4.6329e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1693 - val_loss: 0.2574 - lr: 4.4013e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2078\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2078 - val_loss: 0.3202 - lr: 4.4013e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1710\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1710 - val_loss: 0.2588 - lr: 4.1812e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1730\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1730 - val_loss: 0.2627 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1705\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1705 - val_loss: 0.2607 - lr: 3.7735e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1857\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1857 - val_loss: 0.2682 - lr: 3.5849e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1826\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1826 - val_loss: 0.2702 - lr: 3.4056e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.1609 - val_loss: 0.2432 - lr: 3.2353e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.1660 - val_loss: 0.2381 - lr: 3.2353e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1657\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1657 - val_loss: 0.2500 - lr: 3.2353e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1573\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1573 - val_loss: 0.2811 - lr: 3.0736e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1670\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1670 - val_loss: 0.2437 - lr: 2.9199e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.1564 - val_loss: 0.2351 - lr: 2.7739e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1545\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1545 - val_loss: 0.2427 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1694\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1694 - val_loss: 0.2369 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1618\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1618 - val_loss: 0.2519 - lr: 2.5034e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1542\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1542 - val_loss: 0.2539 - lr: 2.3783e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1428\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1428 - val_loss: 0.2623 - lr: 2.2594e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1468\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1468 - val_loss: 0.2378 - lr: 2.1464e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1575\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1575 - val_loss: 0.3006 - lr: 2.0391e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1490\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1490 - val_loss: 0.2644 - lr: 1.9371e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1501\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1501 - val_loss: 0.2540 - lr: 1.8403e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1409\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1409 - val_loss: 0.2464 - lr: 1.7482e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1366\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1366 - val_loss: 0.2637 - lr: 1.6608e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1478\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1478 - val_loss: 0.2560 - lr: 1.5778e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1392\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1392 - val_loss: 0.2624 - lr: 1.4989e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1417\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1417 - val_loss: 0.2604 - lr: 1.4240e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1436\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1436 - val_loss: 0.2542 - lr: 1.3528e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1345\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1345 - val_loss: 0.2499 - lr: 1.2851e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1358\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1358 - val_loss: 0.2546 - lr: 1.2209e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1332\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1332 - val_loss: 0.2550 - lr: 1.1598e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1363\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1363 - val_loss: 0.2572 - lr: 1.1018e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1343\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1343 - val_loss: 0.2632 - lr: 1.0467e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1305\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1305 - val_loss: 0.2714 - lr: 9.9440e-05\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1330\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1330 - val_loss: 0.2661 - lr: 9.4468e-05\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1331\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1331 - val_loss: 0.2614 - lr: 8.9745e-05\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1269\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1269 - val_loss: 0.2567 - lr: 8.5258e-05\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1245\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.1245 - val_loss: 0.2487 - lr: 8.0995e-05\n",
      "Epoch 64: early stopping\n",
      "2/2 [==============================] - 6s 133ms/step\n",
      "0.1564, 0.2351, 0.4992\n",
      "______fold 5______, ________repeat 6__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 793ms/step - loss: 0.4859 - val_loss: 0.4616 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 418ms/step - loss: 0.4417 - val_loss: 0.4598 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.4166 - val_loss: 0.4583 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.4051 - val_loss: 0.4529 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.4014 - val_loss: 0.4427 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.3481 - val_loss: 0.4128 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3431\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.3431 - val_loss: 0.4359 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3227\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.3227 - val_loss: 0.4314 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3186\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3186 - val_loss: 0.4230 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2867\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2867 - val_loss: 0.4345 - lr: 8.5737e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2951\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2951 - val_loss: 0.4274 - lr: 8.1451e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2771 - val_loss: 0.3775 - lr: 7.7378e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2844\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2844 - val_loss: 0.3892 - lr: 7.7378e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2491 - val_loss: 0.3547 - lr: 7.3509e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2635\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2635 - val_loss: 0.3670 - lr: 7.3509e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2425 - val_loss: 0.3322 - lr: 6.9834e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2384\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2384 - val_loss: 0.3335 - lr: 6.9834e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2421 - val_loss: 0.3220 - lr: 6.6342e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2284 - val_loss: 0.3035 - lr: 6.6342e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2238 - val_loss: 0.2984 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2129\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2129 - val_loss: 0.3394 - lr: 6.6342e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2009\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2009 - val_loss: 0.3242 - lr: 6.3025e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2002\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2002 - val_loss: 0.3023 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1877\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1877 - val_loss: 0.3009 - lr: 5.6880e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1940\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1940 - val_loss: 0.3004 - lr: 5.4036e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1818 - val_loss: 0.2668 - lr: 5.1334e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2023\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.2023 - val_loss: 0.3508 - lr: 5.1334e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1938\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1938 - val_loss: 0.2874 - lr: 4.8767e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1744\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1744 - val_loss: 0.2866 - lr: 4.6329e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.1833 - val_loss: 0.2587 - lr: 4.4013e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1692\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1692 - val_loss: 0.2922 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1699\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1699 - val_loss: 0.2588 - lr: 4.1812e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1660\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1660 - val_loss: 0.2888 - lr: 3.9721e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1744\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1744 - val_loss: 0.2909 - lr: 3.7735e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1593\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1593 - val_loss: 0.2780 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1538\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1538 - val_loss: 0.3008 - lr: 3.4056e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1726\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1726 - val_loss: 0.2865 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1535\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1535 - val_loss: 0.2822 - lr: 3.0736e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1422\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1422 - val_loss: 0.2594 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1497\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1497 - val_loss: 0.2590 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1581\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1581 - val_loss: 0.2729 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1563\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1563 - val_loss: 0.2662 - lr: 2.5034e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.1424 - val_loss: 0.2492 - lr: 2.3783e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1488\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1488 - val_loss: 0.2642 - lr: 2.3783e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1547\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1547 - val_loss: 0.2581 - lr: 2.2594e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1498\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1498 - val_loss: 0.2700 - lr: 2.1464e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1397\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1397 - val_loss: 0.2558 - lr: 2.0391e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1450\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1450 - val_loss: 0.2598 - lr: 1.9371e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1322\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1322 - val_loss: 0.2705 - lr: 1.8403e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1406\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1406 - val_loss: 0.2520 - lr: 1.7482e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1263\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1263 - val_loss: 0.2499 - lr: 1.6608e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1325\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1325 - val_loss: 0.2574 - lr: 1.5778e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1393\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1393 - val_loss: 0.2599 - lr: 1.4989e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1400\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1400 - val_loss: 0.2712 - lr: 1.4240e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1266\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1266 - val_loss: 0.2726 - lr: 1.3528e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1307\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1307 - val_loss: 0.2629 - lr: 1.2851e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1343\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1343 - val_loss: 0.2713 - lr: 1.2209e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1391\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1391 - val_loss: 0.2760 - lr: 1.1598e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1340\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1340 - val_loss: 0.2791 - lr: 1.1018e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1276\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1276 - val_loss: 0.2740 - lr: 1.0467e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1231\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1231 - val_loss: 0.2705 - lr: 9.9440e-05\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1141\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1141 - val_loss: 0.2755 - lr: 9.4468e-05\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1257\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1257 - val_loss: 0.2769 - lr: 8.9745e-05\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1256\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1256 - val_loss: 0.2759 - lr: 8.5258e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1313\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1313 - val_loss: 0.2825 - lr: 8.0995e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1208\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1208 - val_loss: 0.2852 - lr: 7.6945e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1147\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1147 - val_loss: 0.2827 - lr: 7.3098e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1094\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1094 - val_loss: 0.2828 - lr: 6.9443e-05\n",
      "Epoch 68: early stopping\n",
      "2/2 [==============================] - 6s 127ms/step\n",
      "0.1424, 0.2492, 0.4954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______fold 5______, ________repeat 7__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 823ms/step - loss: 0.4842 - val_loss: 0.4655 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.4716 - val_loss: 0.4546 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.4483 - val_loss: 0.4478 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.4250 - val_loss: 0.4370 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.4212 - val_loss: 0.4163 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 442ms/step - loss: 0.4177 - val_loss: 0.4152 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.3939 - val_loss: 0.4038 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.3682 - val_loss: 0.3753 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.3487 - val_loss: 0.3565 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3209\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.3209 - val_loss: 0.3569 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2952 - val_loss: 0.3448 - lr: 9.5000e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2795\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2795 - val_loss: 0.3806 - lr: 9.5000e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2844\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2844 - val_loss: 0.3587 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2591\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2591 - val_loss: 0.3717 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2429\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2429 - val_loss: 0.3470 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2453\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2453 - val_loss: 0.3550 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2367\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2367 - val_loss: 0.3669 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2522 - val_loss: 0.3361 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2322\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2322 - val_loss: 0.3488 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2357 - val_loss: 0.3296 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2237\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2237 - val_loss: 0.3611 - lr: 6.6342e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2265\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2265 - val_loss: 0.3301 - lr: 6.3025e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.2161 - val_loss: 0.3140 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2178 - val_loss: 0.3114 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2061\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2061 - val_loss: 0.3180 - lr: 5.9874e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2165\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2165 - val_loss: 0.3225 - lr: 5.6880e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2026\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2026 - val_loss: 0.3197 - lr: 5.4036e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2035\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2035 - val_loss: 0.3339 - lr: 5.1334e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1996\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1996 - val_loss: 0.3359 - lr: 4.8767e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1984\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1984 - val_loss: 0.3133 - lr: 4.6329e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1910\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1910 - val_loss: 0.3261 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1895\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1895 - val_loss: 0.3169 - lr: 4.1812e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1798\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1798 - val_loss: 0.3152 - lr: 3.9721e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1785\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1785 - val_loss: 0.3344 - lr: 3.7735e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1793\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1793 - val_loss: 0.3234 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1941\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1941 - val_loss: 0.3281 - lr: 3.4056e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1783\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1783 - val_loss: 0.3250 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1732\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1732 - val_loss: 0.3225 - lr: 3.0736e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1725 - val_loss: 0.3113 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1768 - val_loss: 0.3078 - lr: 2.9199e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1606\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1606 - val_loss: 0.3268 - lr: 2.9199e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1620\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1620 - val_loss: 0.3107 - lr: 2.7739e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1534\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1534 - val_loss: 0.3323 - lr: 2.6352e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1655\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1655 - val_loss: 0.3145 - lr: 2.5034e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1675 - val_loss: 0.3019 - lr: 2.3783e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1557 - val_loss: 0.2860 - lr: 2.3783e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1675 - val_loss: 0.2838 - lr: 2.3783e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1539\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1539 - val_loss: 0.2976 - lr: 2.3783e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1485\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1485 - val_loss: 0.2985 - lr: 2.2594e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1463\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1463 - val_loss: 0.3095 - lr: 2.1464e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1612\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1612 - val_loss: 0.2938 - lr: 2.0391e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1511\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1511 - val_loss: 0.2924 - lr: 1.9371e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1494\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1494 - val_loss: 0.2914 - lr: 1.8403e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1400\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1400 - val_loss: 0.2893 - lr: 1.7482e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1339\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1339 - val_loss: 0.2877 - lr: 1.6608e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1405\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1405 - val_loss: 0.2922 - lr: 1.5778e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1405\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1405 - val_loss: 0.2907 - lr: 1.4989e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1378\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1378 - val_loss: 0.2855 - lr: 1.4240e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1448 - val_loss: 0.2739 - lr: 1.3528e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1484\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1484 - val_loss: 0.2973 - lr: 1.3528e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1450\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1450 - val_loss: 0.2745 - lr: 1.2851e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1337 - val_loss: 0.2709 - lr: 1.2209e-04\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1342\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1342 - val_loss: 0.2867 - lr: 1.2209e-04\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1302 - val_loss: 0.2569 - lr: 1.1598e-04\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1433\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1433 - val_loss: 0.2821 - lr: 1.1598e-04\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1367\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1367 - val_loss: 0.2625 - lr: 1.1018e-04\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1425\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1425 - val_loss: 0.2650 - lr: 1.0467e-04\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1352\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1352 - val_loss: 0.2688 - lr: 9.9440e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1364\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1364 - val_loss: 0.2945 - lr: 9.4468e-05\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1386\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1386 - val_loss: 0.2955 - lr: 8.9745e-05\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1308\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1308 - val_loss: 0.2944 - lr: 8.5258e-05\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1351\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1351 - val_loss: 0.2995 - lr: 8.0995e-05\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1204\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1204 - val_loss: 0.3044 - lr: 7.6945e-05\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1414\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1414 - val_loss: 0.2839 - lr: 7.3098e-05\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1386\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1386 - val_loss: 0.2876 - lr: 6.9443e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1272\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1272 - val_loss: 0.2925 - lr: 6.5971e-05\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1280\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1280 - val_loss: 0.2937 - lr: 6.2672e-05\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1291\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 5.656161210936261e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1291 - val_loss: 0.2886 - lr: 5.9539e-05\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1312\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 5.373353305913042e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1312 - val_loss: 0.2765 - lr: 5.6562e-05\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1295\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 5.104685606056591e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1295 - val_loss: 0.2751 - lr: 5.3734e-05\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1318\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 4.849451343034161e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1318 - val_loss: 0.2719 - lr: 5.1047e-05\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1311\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 4.606978654919658e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1311 - val_loss: 0.2709 - lr: 4.8495e-05\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1377\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 4.3766295493696814e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1377 - val_loss: 0.2818 - lr: 4.6070e-05\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1325\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 4.1577981755835934e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1325 - val_loss: 0.2809 - lr: 4.3766e-05\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1265\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 3.949908405047608e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1265 - val_loss: 0.2780 - lr: 4.1578e-05\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1207\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 3.752413140318822e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1207 - val_loss: 0.2764 - lr: 3.9499e-05\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1240\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 3.564792586985277e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1240 - val_loss: 0.2780 - lr: 3.7524e-05\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1246\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 3.3865528712340166e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1246 - val_loss: 0.2874 - lr: 3.5648e-05\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1205\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 3.217225348635111e-05.\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1205 - val_loss: 0.2876 - lr: 3.3866e-05\n",
      "Epoch 89: early stopping\n",
      "2/2 [==============================] - 6s 130ms/step\n",
      "0.1302, 0.2569, 0.4992\n",
      "______fold 5______, ________repeat 8__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 862ms/step - loss: 0.4617 - val_loss: 0.4451 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4409\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 8s 418ms/step - loss: 0.4409 - val_loss: 0.4595 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.4193 - val_loss: 0.4322 - lr: 9.5000e-04\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.4041 - val_loss: 0.4288 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.3871 - val_loss: 0.4189 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.3671 - val_loss: 0.4038 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.3378 - val_loss: 0.3782 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.3138 - val_loss: 0.3451 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2807\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2807 - val_loss: 0.3465 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2569\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2569 - val_loss: 0.3497 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2580\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2580 - val_loss: 0.3453 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.2424 - val_loss: 0.3358 - lr: 8.1451e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2372\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 8s 418ms/step - loss: 0.2372 - val_loss: 0.3418 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2179\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2179 - val_loss: 0.3482 - lr: 7.7378e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2228 - val_loss: 0.3306 - lr: 7.3509e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2295\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2295 - val_loss: 0.3324 - lr: 7.3509e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2181\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2181 - val_loss: 0.3410 - lr: 6.9834e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2339\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2339 - val_loss: 0.3548 - lr: 6.6342e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.2198 - val_loss: 0.3191 - lr: 6.3025e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.1890 - val_loss: 0.3124 - lr: 6.3025e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1928\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1928 - val_loss: 0.3298 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2071\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2071 - val_loss: 0.3306 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1848\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1848 - val_loss: 0.3677 - lr: 5.6880e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1902\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1902 - val_loss: 0.3270 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1785\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1785 - val_loss: 0.3182 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1871 - val_loss: 0.3008 - lr: 4.8767e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1745\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1745 - val_loss: 0.3101 - lr: 4.8767e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1608\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1608 - val_loss: 0.3343 - lr: 4.6329e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1621\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1621 - val_loss: 0.3167 - lr: 4.4013e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1604\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1604 - val_loss: 0.3126 - lr: 4.1812e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1641 - val_loss: 0.2857 - lr: 3.9721e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1565 - val_loss: 0.2816 - lr: 3.9721e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1712\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1712 - val_loss: 0.2931 - lr: 3.9721e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1622\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1622 - val_loss: 0.2988 - lr: 3.7735e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1513 - val_loss: 0.2708 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1349\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1349 - val_loss: 0.3511 - lr: 3.5849e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1471\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1471 - val_loss: 0.3218 - lr: 3.4056e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1532\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1532 - val_loss: 0.3401 - lr: 3.2353e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1599\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1599 - val_loss: 0.2911 - lr: 3.0736e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1467\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1467 - val_loss: 0.2957 - lr: 2.9199e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1578\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1578 - val_loss: 0.2888 - lr: 2.7739e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1525\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1525 - val_loss: 0.2756 - lr: 2.6352e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1627\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1627 - val_loss: 0.2840 - lr: 2.5034e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1506\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1506 - val_loss: 0.2884 - lr: 2.3783e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1435 - val_loss: 0.2701 - lr: 2.2594e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1464\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1464 - val_loss: 0.2883 - lr: 2.2594e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1508\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1508 - val_loss: 0.2740 - lr: 2.1464e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1373\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1373 - val_loss: 0.2804 - lr: 2.0391e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1358\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1358 - val_loss: 0.2825 - lr: 1.9371e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1468\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1468 - val_loss: 0.2750 - lr: 1.8403e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1324 - val_loss: 0.2649 - lr: 1.7482e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1419\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1419 - val_loss: 0.2726 - lr: 1.7482e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1327\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1327 - val_loss: 0.2746 - lr: 1.6608e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1462\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1462 - val_loss: 0.2838 - lr: 1.5778e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1230\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1230 - val_loss: 0.2877 - lr: 1.4989e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1305\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1305 - val_loss: 0.2679 - lr: 1.4240e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1454\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1454 - val_loss: 0.2694 - lr: 1.3528e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1317\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1317 - val_loss: 0.2876 - lr: 1.2851e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1312\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1312 - val_loss: 0.2710 - lr: 1.2209e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1329 - val_loss: 0.2547 - lr: 1.1598e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1265\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1265 - val_loss: 0.2863 - lr: 1.1598e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1112\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1112 - val_loss: 0.2690 - lr: 1.1018e-04\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1306\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1306 - val_loss: 0.2822 - lr: 1.0467e-04\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1130\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1130 - val_loss: 0.2636 - lr: 9.9440e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1262 - val_loss: 0.2512 - lr: 9.4468e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1280\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1280 - val_loss: 0.2571 - lr: 9.4468e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1199\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1199 - val_loss: 0.2631 - lr: 8.9745e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1190\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1190 - val_loss: 0.2606 - lr: 8.5258e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1211\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1211 - val_loss: 0.2727 - lr: 8.0995e-05\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1170\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1170 - val_loss: 0.2612 - lr: 7.6945e-05\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1180\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1180 - val_loss: 0.2733 - lr: 7.3098e-05\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1253\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1253 - val_loss: 0.2596 - lr: 6.9443e-05\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1129 - val_loss: 0.2471 - lr: 6.5971e-05\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1137 - val_loss: 0.2455 - lr: 6.5971e-05\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1080\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1080 - val_loss: 0.2689 - lr: 6.5971e-05\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1147\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1147 - val_loss: 0.2620 - lr: 6.2672e-05\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1315\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 5.656161210936261e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1315 - val_loss: 0.2592 - lr: 5.9539e-05\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1103\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 5.373353305913042e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1103 - val_loss: 0.2671 - lr: 5.6562e-05\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1102\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 5.104685606056591e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1102 - val_loss: 0.2624 - lr: 5.3734e-05\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1212\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 4.849451343034161e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1212 - val_loss: 0.2578 - lr: 5.1047e-05\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1284\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 4.606978654919658e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1284 - val_loss: 0.2568 - lr: 4.8495e-05\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1212\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 4.3766295493696814e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1212 - val_loss: 0.2642 - lr: 4.6070e-05\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1150\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 4.1577981755835934e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1150 - val_loss: 0.2682 - lr: 4.3766e-05\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1054\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 3.949908405047608e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1054 - val_loss: 0.2646 - lr: 4.1578e-05\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1128\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 3.752413140318822e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1128 - val_loss: 0.2558 - lr: 3.9499e-05\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1130\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 3.564792586985277e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1130 - val_loss: 0.2570 - lr: 3.7524e-05\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1194\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 3.3865528712340166e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1194 - val_loss: 0.2548 - lr: 3.5648e-05\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1013\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 3.217225348635111e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1013 - val_loss: 0.2581 - lr: 3.3866e-05\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1161\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 3.0563641848857516e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1161 - val_loss: 0.2586 - lr: 3.2172e-05\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1255\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 2.9035460102022626e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1255 - val_loss: 0.2534 - lr: 3.0564e-05\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1077\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 2.7583687096921494e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1077 - val_loss: 0.2629 - lr: 2.9035e-05\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1275\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 2.620450213726144e-05.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1275 - val_loss: 0.2651 - lr: 2.7584e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1182\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 2.4894276339182395e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1182 - val_loss: 0.2665 - lr: 2.6205e-05\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1136\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 2.3649562263017287e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1136 - val_loss: 0.2689 - lr: 2.4894e-05\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1016\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 2.2467083545052444e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1016 - val_loss: 0.2635 - lr: 2.3650e-05\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1111\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 2.134372971340781e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1111 - val_loss: 0.2591 - lr: 2.2467e-05\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1162\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 2.0276544091757387e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1162 - val_loss: 0.2577 - lr: 2.1344e-05\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1015\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 1.9262716887169517e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1015 - val_loss: 0.2559 - lr: 2.0277e-05\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1131\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 1.8299581734027014e-05.\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1131 - val_loss: 0.2576 - lr: 1.9263e-05\n",
      "Epoch 99: early stopping\n",
      "2/2 [==============================] - 6s 134ms/step\n",
      "0.1137, 0.2455, 0.5580\n",
      "______fold 5______, ________repeat 9__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 822ms/step - loss: 0.4786 - val_loss: 0.4679 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.4660 - val_loss: 0.4652 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4529 - val_loss: 0.4552 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.4292 - val_loss: 0.4470 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3955\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.3955 - val_loss: 0.4505 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.3774 - val_loss: 0.4254 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.3248 - val_loss: 0.4043 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2980 - val_loss: 0.3663 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3085\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.3085 - val_loss: 0.3686 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2821 - val_loss: 0.3413 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3044\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.3044 - val_loss: 0.3426 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2836\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2836 - val_loss: 0.3595 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2470 - val_loss: 0.3059 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 8s 424ms/step - loss: 0.2293 - val_loss: 0.2760 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2290\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2290 - val_loss: 0.2784 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2220\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2220 - val_loss: 0.2847 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2134 - val_loss: 0.2659 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2192\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2192 - val_loss: 0.2778 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2205\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2205 - val_loss: 0.2933 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2094\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2094 - val_loss: 0.2704 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2170\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2170 - val_loss: 0.2842 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1920\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1920 - val_loss: 0.2830 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1848\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1848 - val_loss: 0.2800 - lr: 5.6880e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1974\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1974 - val_loss: 0.2704 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1840\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1840 - val_loss: 0.2893 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1662\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1662 - val_loss: 0.2826 - lr: 4.8767e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1882 - val_loss: 0.2566 - lr: 4.6329e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1827\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 418ms/step - loss: 0.1827 - val_loss: 0.2737 - lr: 4.6329e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1684\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1684 - val_loss: 0.2903 - lr: 4.4013e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1664\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1664 - val_loss: 0.2762 - lr: 4.1812e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1649\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1649 - val_loss: 0.2923 - lr: 3.9721e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1747\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1747 - val_loss: 0.2709 - lr: 3.7735e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1657\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1657 - val_loss: 0.2843 - lr: 3.5849e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1602\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1602 - val_loss: 0.3017 - lr: 3.4056e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1527\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1527 - val_loss: 0.2851 - lr: 3.2353e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1388\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1388 - val_loss: 0.2908 - lr: 3.0736e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1526\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1526 - val_loss: 0.3187 - lr: 2.9199e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1551\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1551 - val_loss: 0.2779 - lr: 2.7739e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1588\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1588 - val_loss: 0.2830 - lr: 2.6352e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1593\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1593 - val_loss: 0.2600 - lr: 2.5034e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1579\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1579 - val_loss: 0.2775 - lr: 2.3783e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1476\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1476 - val_loss: 0.2668 - lr: 2.2594e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1357\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1357 - val_loss: 0.2611 - lr: 2.1464e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1519\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1519 - val_loss: 0.2749 - lr: 2.0391e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1484\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1484 - val_loss: 0.2618 - lr: 1.9371e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1397\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1397 - val_loss: 0.2648 - lr: 1.8403e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1465\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1465 - val_loss: 0.2738 - lr: 1.7482e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1575\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1575 - val_loss: 0.2680 - lr: 1.6608e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1318\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1318 - val_loss: 0.2680 - lr: 1.5778e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1253\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1253 - val_loss: 0.2714 - lr: 1.4989e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1458\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1458 - val_loss: 0.2589 - lr: 1.4240e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1402\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.1402 - val_loss: 0.2780 - lr: 1.3528e-04\n",
      "Epoch 52: early stopping\n",
      "2/2 [==============================] - 6s 134ms/step\n",
      "0.1882, 0.2566, 0.5184\n",
      "______fold 5______, ________repeat 10__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 824ms/step - loss: 0.4854 - val_loss: 0.4701 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 433ms/step - loss: 0.4610 - val_loss: 0.4639 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4406\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 8s 418ms/step - loss: 0.4406 - val_loss: 0.4686 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.4294 - val_loss: 0.4629 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.4170 - val_loss: 0.4572 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.3945 - val_loss: 0.4426 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3533\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.3533 - val_loss: 0.4690 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.3336 - val_loss: 0.4097 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.3101 - val_loss: 0.3825 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3014\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.3014 - val_loss: 0.3909 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3036\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.3036 - val_loss: 0.3857 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2779\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2779 - val_loss: 0.3827 - lr: 8.1451e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3005\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3005 - val_loss: 0.3909 - lr: 7.7378e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2817 - val_loss: 0.3400 - lr: 7.3509e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2739\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2739 - val_loss: 0.3844 - lr: 7.3509e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2632\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2632 - val_loss: 0.3469 - lr: 6.9834e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2635\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2635 - val_loss: 0.3560 - lr: 6.6342e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2492\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2492 - val_loss: 0.3716 - lr: 6.3025e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2305\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2305 - val_loss: 0.3655 - lr: 5.9874e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2468\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2468 - val_loss: 0.3534 - lr: 5.6880e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2409\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2409 - val_loss: 0.3517 - lr: 5.4036e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2231\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2231 - val_loss: 0.3601 - lr: 5.1334e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2173\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2173 - val_loss: 0.3570 - lr: 4.8767e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2201\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2201 - val_loss: 0.3578 - lr: 4.6329e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2266\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2266 - val_loss: 0.3406 - lr: 4.4013e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2078 - val_loss: 0.3251 - lr: 4.1812e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2085\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2085 - val_loss: 0.3456 - lr: 4.1812e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2011\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2011 - val_loss: 0.3314 - lr: 3.9721e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1972\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1972 - val_loss: 0.3421 - lr: 3.7735e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1811\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1811 - val_loss: 0.3460 - lr: 3.5849e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1746\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1746 - val_loss: 0.3464 - lr: 3.4056e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1815\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1815 - val_loss: 0.3380 - lr: 3.2353e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1840\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1840 - val_loss: 0.3419 - lr: 3.0736e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1740\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1740 - val_loss: 0.3514 - lr: 2.9199e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1759\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1759 - val_loss: 0.3623 - lr: 2.7739e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1751\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1751 - val_loss: 0.3528 - lr: 2.6352e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1850\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1850 - val_loss: 0.3487 - lr: 2.5034e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1652\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1652 - val_loss: 0.3511 - lr: 2.3783e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1707\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1707 - val_loss: 0.3363 - lr: 2.2594e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1771 - val_loss: 0.3239 - lr: 2.1464e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1633\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1633 - val_loss: 0.3380 - lr: 2.1464e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1824\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1824 - val_loss: 0.3477 - lr: 2.0391e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1686\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1686 - val_loss: 0.3415 - lr: 1.9371e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1806\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1806 - val_loss: 0.3554 - lr: 1.8403e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1748\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1748 - val_loss: 0.3417 - lr: 1.7482e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1724\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1724 - val_loss: 0.3370 - lr: 1.6608e-04\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.1614\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1614 - val_loss: 0.3437 - lr: 1.5778e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1603\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1603 - val_loss: 0.3478 - lr: 1.4989e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1577\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1577 - val_loss: 0.3481 - lr: 1.4240e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1572\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1572 - val_loss: 0.3439 - lr: 1.3528e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1780\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1780 - val_loss: 0.3465 - lr: 1.2851e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1573\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1573 - val_loss: 0.3513 - lr: 1.2209e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1608\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1608 - val_loss: 0.3407 - lr: 1.1598e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1518\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1518 - val_loss: 0.3422 - lr: 1.1018e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1423\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1423 - val_loss: 0.3441 - lr: 1.0467e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1551\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1551 - val_loss: 0.3419 - lr: 9.9440e-05\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1528\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1528 - val_loss: 0.3423 - lr: 9.4468e-05\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1588\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1588 - val_loss: 0.3425 - lr: 8.9745e-05\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1617\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1617 - val_loss: 0.3405 - lr: 8.5258e-05\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1659\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1659 - val_loss: 0.3418 - lr: 8.0995e-05\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1608\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1608 - val_loss: 0.3461 - lr: 7.6945e-05\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1512\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1512 - val_loss: 0.3438 - lr: 7.3098e-05\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1566\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1566 - val_loss: 0.3448 - lr: 6.9443e-05\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1603\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1603 - val_loss: 0.3423 - lr: 6.5971e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1446\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1446 - val_loss: 0.3414 - lr: 6.2672e-05\n",
      "Epoch 65: early stopping\n",
      "2/2 [==============================] - 6s 126ms/step\n",
      "0.1771, 0.3239, 0.7742\n",
      "______fold 6______, ________repeat 1__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 818ms/step - loss: 0.4530 - val_loss: 0.4296 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4510\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.4510 - val_loss: 0.4522 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.4336 - val_loss: 0.4063 - lr: 9.5000e-04\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.4292 - val_loss: 0.3857 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.4018 - val_loss: 0.3821 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 435ms/step - loss: 0.4087 - val_loss: 0.3572 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3803\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.3803 - val_loss: 0.3595 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3721\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.3721 - val_loss: 0.3704 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.3549 - val_loss: 0.3138 - lr: 8.5737e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3499\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.3499 - val_loss: 0.3173 - lr: 8.5737e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3210\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.3210 - val_loss: 0.3179 - lr: 8.1451e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.3249 - val_loss: 0.2985 - lr: 7.7378e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.3163 - val_loss: 0.2820 - lr: 7.7378e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.3083 - val_loss: 0.2769 - lr: 7.7378e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3253\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 415ms/step - loss: 0.3253 - val_loss: 0.2774 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.2848 - val_loss: 0.2329 - lr: 7.3509e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2496 - val_loss: 0.2213 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2373\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2373 - val_loss: 0.2293 - lr: 7.3509e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.2390 - val_loss: 0.1923 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2204\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2204 - val_loss: 0.2350 - lr: 6.9834e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2210\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2210 - val_loss: 0.2258 - lr: 6.6342e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2346\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2346 - val_loss: 0.2190 - lr: 6.3025e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2282 - val_loss: 0.1765 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2206\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2206 - val_loss: 0.2053 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2173\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2173 - val_loss: 0.2110 - lr: 5.6880e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2131\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2131 - val_loss: 0.2022 - lr: 5.4036e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2052\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2052 - val_loss: 0.2113 - lr: 5.1334e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.2078 - val_loss: 0.1674 - lr: 4.8767e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2099\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2099 - val_loss: 0.2354 - lr: 4.8767e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1982\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1982 - val_loss: 0.2015 - lr: 4.6329e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1947\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1947 - val_loss: 0.1845 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2107\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2107 - val_loss: 0.2452 - lr: 4.1812e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1937\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1937 - val_loss: 0.1861 - lr: 3.9721e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1862\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1862 - val_loss: 0.2001 - lr: 3.7735e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1721\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1721 - val_loss: 0.1902 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1786\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1786 - val_loss: 0.1962 - lr: 3.4056e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1701\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1701 - val_loss: 0.1892 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1708\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1708 - val_loss: 0.1893 - lr: 3.0736e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1759\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1759 - val_loss: 0.2088 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1815\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1815 - val_loss: 0.1787 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1585\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1585 - val_loss: 0.2012 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1563\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1563 - val_loss: 0.1832 - lr: 2.5034e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1642\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1642 - val_loss: 0.2187 - lr: 2.3783e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1698\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1698 - val_loss: 0.1739 - lr: 2.2594e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1730\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1730 - val_loss: 0.2047 - lr: 2.1464e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1519\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1519 - val_loss: 0.1802 - lr: 2.0391e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1606\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1606 - val_loss: 0.1901 - lr: 1.9371e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1421\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1421 - val_loss: 0.1955 - lr: 1.8403e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1436\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1436 - val_loss: 0.1920 - lr: 1.7482e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1471\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1471 - val_loss: 0.1889 - lr: 1.6608e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1533\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1533 - val_loss: 0.2065 - lr: 1.5778e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1654\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1654 - val_loss: 0.1963 - lr: 1.4989e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1560\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1560 - val_loss: 0.1811 - lr: 1.4240e-04\n",
      "Epoch 53: early stopping\n",
      "2/2 [==============================] - 6s 126ms/step\n",
      "0.2078, 0.1674, 0.2928\n",
      "______fold 6______, ________repeat 2__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 831ms/step - loss: 0.4809 - val_loss: 0.4680 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 445ms/step - loss: 0.4656 - val_loss: 0.4628 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.4576 - val_loss: 0.4459 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 8s 431ms/step - loss: 0.4477 - val_loss: 0.4377 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 412ms/step - loss: 0.4386 - val_loss: 0.4276 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4133\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.4133 - val_loss: 0.4388 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.4099 - val_loss: 0.4237 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.3915 - val_loss: 0.3938 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4186\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.4186 - val_loss: 0.4436 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.3827 - val_loss: 0.3401 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 8s 422ms/step - loss: 0.3557 - val_loss: 0.3034 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 8s 430ms/step - loss: 0.3246 - val_loss: 0.2522 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 414ms/step - loss: 0.2881 - val_loss: 0.2478 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2672\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.2672 - val_loss: 0.2874 - lr: 9.0250e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2651\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2651 - val_loss: 0.2823 - lr: 8.5737e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.2396 - val_loss: 0.2285 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.2524 - val_loss: 0.2270 - lr: 8.1451e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.2515 - val_loss: 0.2262 - lr: 8.1451e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2312\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2312 - val_loss: 0.3088 - lr: 8.1451e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2385\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2385 - val_loss: 0.2489 - lr: 7.7378e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2107\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2107 - val_loss: 0.3155 - lr: 7.3509e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2129\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2129 - val_loss: 0.3087 - lr: 6.9834e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1978\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1978 - val_loss: 0.2734 - lr: 6.6342e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.2230 - val_loss: 0.1914 - lr: 6.3025e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.2135 - val_loss: 0.1733 - lr: 6.3025e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2183\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.2183 - val_loss: 0.2588 - lr: 6.3025e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1895\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1895 - val_loss: 0.1950 - lr: 5.9874e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1955\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1955 - val_loss: 0.2263 - lr: 5.6880e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2002\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2002 - val_loss: 0.2112 - lr: 5.4036e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1859\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1859 - val_loss: 0.2073 - lr: 5.1334e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1864\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1864 - val_loss: 0.1928 - lr: 4.8767e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1869\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1869 - val_loss: 0.1849 - lr: 4.6329e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1686\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1686 - val_loss: 0.2160 - lr: 4.4013e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1710\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1710 - val_loss: 0.1836 - lr: 4.1812e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1614\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1614 - val_loss: 0.1859 - lr: 3.9721e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1715\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1715 - val_loss: 0.1903 - lr: 3.7735e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1877 - val_loss: 0.1690 - lr: 3.5849e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1635\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1635 - val_loss: 0.1728 - lr: 3.5849e-04\n",
      "Epoch 39/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.1719\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1719 - val_loss: 0.1747 - lr: 3.4056e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1638\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1638 - val_loss: 0.1691 - lr: 3.2353e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1585\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1585 - val_loss: 0.1711 - lr: 3.0736e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1525\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1525 - val_loss: 0.1891 - lr: 2.9199e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1564\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1564 - val_loss: 0.1842 - lr: 2.7739e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1517\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1517 - val_loss: 0.1734 - lr: 2.6352e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1627\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1627 - val_loss: 0.1734 - lr: 2.5034e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1569\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1569 - val_loss: 0.1816 - lr: 2.3783e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1608\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1608 - val_loss: 0.1845 - lr: 2.2594e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1548\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1548 - val_loss: 0.1884 - lr: 2.1464e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1443\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1443 - val_loss: 0.1904 - lr: 2.0391e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1374\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1374 - val_loss: 0.1766 - lr: 1.9371e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1438\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1438 - val_loss: 0.1769 - lr: 1.8403e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1396\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1396 - val_loss: 0.1924 - lr: 1.7482e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1504\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1504 - val_loss: 0.1791 - lr: 1.6608e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1513\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1513 - val_loss: 0.1955 - lr: 1.5778e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1339\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1339 - val_loss: 0.1847 - lr: 1.4989e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1420 - val_loss: 0.1625 - lr: 1.4240e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1484 - val_loss: 0.1547 - lr: 1.4240e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1373\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1373 - val_loss: 0.1766 - lr: 1.4240e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1298\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1298 - val_loss: 0.1744 - lr: 1.3528e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1264\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1264 - val_loss: 0.1890 - lr: 1.2851e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1449\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1449 - val_loss: 0.1795 - lr: 1.2209e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1460\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1460 - val_loss: 0.1767 - lr: 1.1598e-04\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1296\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1296 - val_loss: 0.1755 - lr: 1.1018e-04\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1319\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1319 - val_loss: 0.1768 - lr: 1.0467e-04\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1426\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1426 - val_loss: 0.1853 - lr: 9.9440e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1389\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1389 - val_loss: 0.1869 - lr: 9.4468e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1314\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1314 - val_loss: 0.1741 - lr: 8.9745e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1362\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1362 - val_loss: 0.1764 - lr: 8.5258e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1301\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1301 - val_loss: 0.1816 - lr: 8.0995e-05\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1317\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1317 - val_loss: 0.1853 - lr: 7.6945e-05\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1316\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1316 - val_loss: 0.1821 - lr: 7.3098e-05\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1326\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1326 - val_loss: 0.1833 - lr: 6.9443e-05\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1311\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1311 - val_loss: 0.1912 - lr: 6.5971e-05\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1247\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1247 - val_loss: 0.2002 - lr: 6.2672e-05\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1228\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 5.656161210936261e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1228 - val_loss: 0.2034 - lr: 5.9539e-05\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1329\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 5.373353305913042e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1329 - val_loss: 0.2041 - lr: 5.6562e-05\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1330\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 5.104685606056591e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1330 - val_loss: 0.2046 - lr: 5.3734e-05\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1334\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 4.849451343034161e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1334 - val_loss: 0.1866 - lr: 5.1047e-05\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1201\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 4.606978654919658e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1201 - val_loss: 0.1818 - lr: 4.8495e-05\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1223\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 4.3766295493696814e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1223 - val_loss: 0.1874 - lr: 4.6070e-05\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1325\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 4.1577981755835934e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1325 - val_loss: 0.1921 - lr: 4.3766e-05\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1331\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.949908405047608e-05.\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.1331 - val_loss: 0.1908 - lr: 4.1578e-05\n",
      "Epoch 82: early stopping\n",
      "2/2 [==============================] - 6s 127ms/step\n",
      "0.1484, 0.1547, 0.2372\n",
      "______fold 6______, ________repeat 3__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 833ms/step - loss: 0.4954 - val_loss: 0.4680 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 415ms/step - loss: 0.4633 - val_loss: 0.4635 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.4555 - val_loss: 0.4535 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.4530 - val_loss: 0.4420 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.4424 - val_loss: 0.4341 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.4263 - val_loss: 0.4155 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.4205 - val_loss: 0.3857 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.4087 - val_loss: 0.3606 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3975\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.3975 - val_loss: 0.3999 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.3754 - val_loss: 0.3339 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3403\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.3403 - val_loss: 0.3434 - lr: 9.5000e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.3143 - val_loss: 0.2638 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2809\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.2809 - val_loss: 0.2749 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2816 - val_loss: 0.2088 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2688\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2688 - val_loss: 0.2098 - lr: 8.5737e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.2441 - val_loss: 0.1952 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2538\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.2538 - val_loss: 0.2159 - lr: 8.1451e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2329\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.2329 - val_loss: 0.1955 - lr: 7.7378e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2316\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.2316 - val_loss: 0.1974 - lr: 7.3509e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2220 - val_loss: 0.1866 - lr: 6.9834e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2226\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.2226 - val_loss: 0.2050 - lr: 6.9834e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2141\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.2141 - val_loss: 0.2065 - lr: 6.6342e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2052\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2052 - val_loss: 0.2005 - lr: 6.3025e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2199\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.2199 - val_loss: 0.2032 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1860\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1860 - val_loss: 0.1885 - lr: 5.6880e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1950\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1950 - val_loss: 0.2240 - lr: 5.4036e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1975\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1975 - val_loss: 0.1973 - lr: 5.1334e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1781\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1781 - val_loss: 0.2111 - lr: 4.8767e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1736\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1736 - val_loss: 0.2091 - lr: 4.6329e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1782\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1782 - val_loss: 0.2247 - lr: 4.4013e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1494\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1494 - val_loss: 0.2300 - lr: 4.1812e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1470\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1470 - val_loss: 0.2671 - lr: 3.9721e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1723\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1723 - val_loss: 0.2323 - lr: 3.7735e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1608\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1608 - val_loss: 0.2459 - lr: 3.5849e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1565\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1565 - val_loss: 0.2495 - lr: 3.4056e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1573\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1573 - val_loss: 0.2560 - lr: 3.2353e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1468\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1468 - val_loss: 0.2561 - lr: 3.0736e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1377\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1377 - val_loss: 0.2939 - lr: 2.9199e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1518\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1518 - val_loss: 0.2563 - lr: 2.7739e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1331\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1331 - val_loss: 0.2959 - lr: 2.6352e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1358\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1358 - val_loss: 0.3000 - lr: 2.5034e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1445\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1445 - val_loss: 0.2915 - lr: 2.3783e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1382\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1382 - val_loss: 0.2968 - lr: 2.2594e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1422\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1422 - val_loss: 0.2826 - lr: 2.1464e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1315\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.1315 - val_loss: 0.3100 - lr: 2.0391e-04\n",
      "Epoch 45: early stopping\n",
      "2/2 [==============================] - 6s 127ms/step\n",
      "0.2220, 0.1866, 0.3333\n",
      "______fold 6______, ________repeat 4__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 821ms/step - loss: 0.4680 - val_loss: 0.4789 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 414ms/step - loss: 0.4673 - val_loss: 0.4532 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.4449 - val_loss: 0.4243 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.4269 - val_loss: 0.4109 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 8s 433ms/step - loss: 0.4118 - val_loss: 0.3534 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.3680 - val_loss: 0.3166 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3548\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.3548 - val_loss: 0.3253 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.3277 - val_loss: 0.2216 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3268\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.3268 - val_loss: 0.2845 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2811\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2811 - val_loss: 0.2532 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.2576 - val_loss: 0.1856 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2389 - val_loss: 0.1525 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.2333 - val_loss: 0.1475 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2685\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2685 - val_loss: 0.2080 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2412\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2412 - val_loss: 0.2211 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2369\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2369 - val_loss: 0.1980 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2312\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2312 - val_loss: 0.1972 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2380\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2380 - val_loss: 0.2162 - lr: 6.9834e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2332\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2332 - val_loss: 0.1836 - lr: 6.6342e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2182\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2182 - val_loss: 0.1680 - lr: 6.3025e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1979\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1979 - val_loss: 0.1923 - lr: 5.9874e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1996\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1996 - val_loss: 0.1851 - lr: 5.6880e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1881\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1881 - val_loss: 0.1705 - lr: 5.4036e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2153\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.2153 - val_loss: 0.1546 - lr: 5.1334e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1943\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1943 - val_loss: 0.1939 - lr: 4.8767e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1991\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1991 - val_loss: 0.1974 - lr: 4.6329e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1791\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1791 - val_loss: 0.1820 - lr: 4.4013e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1972\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1972 - val_loss: 0.2196 - lr: 4.1812e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1913\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1913 - val_loss: 0.1507 - lr: 3.9721e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1774\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1774 - val_loss: 0.1587 - lr: 3.7735e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1732\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1732 - val_loss: 0.1827 - lr: 3.5849e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1660\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1660 - val_loss: 0.1713 - lr: 3.4056e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1841\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1841 - val_loss: 0.1694 - lr: 3.2353e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1633\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1633 - val_loss: 0.1647 - lr: 3.0736e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1622\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1622 - val_loss: 0.1757 - lr: 2.9199e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1678\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1678 - val_loss: 0.1616 - lr: 2.7739e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1552\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1552 - val_loss: 0.1577 - lr: 2.6352e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1928\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.1928 - val_loss: 0.1669 - lr: 2.5034e-04\n",
      "Epoch 38: early stopping\n",
      "2/2 [==============================] - 8s 127ms/step\n",
      "0.2333, 0.1475, 0.2718\n",
      "______fold 6______, ________repeat 5__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 814ms/step - loss: 0.4878 - val_loss: 0.4690 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 430ms/step - loss: 0.4658 - val_loss: 0.4537 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.4476 - val_loss: 0.4264 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.4250 - val_loss: 0.3836 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.3985 - val_loss: 0.3404 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.3536 - val_loss: 0.3189 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.3272 - val_loss: 0.3011 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.3198 - val_loss: 0.2570 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3475\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.3475 - val_loss: 0.3109 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2762\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.2762 - val_loss: 0.2681 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2811 - val_loss: 0.2322 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2786\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.2786 - val_loss: 0.2464 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2564\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.2564 - val_loss: 0.3217 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.2375 - val_loss: 0.2092 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2449\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.2449 - val_loss: 0.2434 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2236\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2236 - val_loss: 0.2392 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.2287 - val_loss: 0.1910 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2405\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2405 - val_loss: 0.3624 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2343\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2343 - val_loss: 0.2178 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2300\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2300 - val_loss: 0.2171 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2108 - val_loss: 0.1661 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1981\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 414ms/step - loss: 0.1981 - val_loss: 0.1711 - lr: 6.3025e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2070 - val_loss: 0.1490 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2084\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2084 - val_loss: 0.2201 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1928\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1928 - val_loss: 0.1683 - lr: 5.6880e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2171\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2171 - val_loss: 0.2232 - lr: 5.4036e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1909\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1909 - val_loss: 0.1875 - lr: 5.1334e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1929\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1929 - val_loss: 0.1990 - lr: 4.8767e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1814\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1814 - val_loss: 0.2192 - lr: 4.6329e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1954\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1954 - val_loss: 0.2225 - lr: 4.4013e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1797\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1797 - val_loss: 0.1593 - lr: 4.1812e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1902\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1902 - val_loss: 0.1687 - lr: 3.9721e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1762\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1762 - val_loss: 0.1839 - lr: 3.7735e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1755 - val_loss: 0.1352 - lr: 3.5849e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1902\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1902 - val_loss: 0.1880 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1751\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1751 - val_loss: 0.1545 - lr: 3.4056e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2000\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2000 - val_loss: 0.1937 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1910\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1910 - val_loss: 0.1395 - lr: 3.0736e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1736\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1736 - val_loss: 0.1482 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1809\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1809 - val_loss: 0.1503 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1651\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1651 - val_loss: 0.1577 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1768\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 6s 357ms/step - loss: 0.1768 - val_loss: 0.1444 - lr: 2.5034e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1670\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 6s 357ms/step - loss: 0.1670 - val_loss: 0.1697 - lr: 2.3783e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1832\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1832 - val_loss: 0.1680 - lr: 2.2594e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1708\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1708 - val_loss: 0.1678 - lr: 2.1464e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1733\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1733 - val_loss: 0.2035 - lr: 2.0391e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1635\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1635 - val_loss: 0.1577 - lr: 1.9371e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1743\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1743 - val_loss: 0.1734 - lr: 1.8403e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1620\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1620 - val_loss: 0.1562 - lr: 1.7482e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1677\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1677 - val_loss: 0.1774 - lr: 1.6608e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1759\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1759 - val_loss: 0.1982 - lr: 1.5778e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1696\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1696 - val_loss: 0.1667 - lr: 1.4989e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1625\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1625 - val_loss: 0.1895 - lr: 1.4240e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1594\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1594 - val_loss: 0.1754 - lr: 1.3528e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1662\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 6s 359ms/step - loss: 0.1662 - val_loss: 0.1761 - lr: 1.2851e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1558\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1558 - val_loss: 0.1556 - lr: 1.2209e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1565\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1565 - val_loss: 0.1724 - lr: 1.1598e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1546\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1546 - val_loss: 0.1825 - lr: 1.1018e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1573\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1573 - val_loss: 0.1591 - lr: 1.0467e-04\n",
      "Epoch 59: early stopping\n",
      "2/2 [==============================] - 6s 127ms/step\n",
      "0.1755, 0.1352, 0.2008\n",
      "______fold 6______, ________repeat 6__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 841ms/step - loss: 0.4928 - val_loss: 0.4452 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4627\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.4627 - val_loss: 0.4560 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.4466 - val_loss: 0.4355 - lr: 9.5000e-04\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.4361 - val_loss: 0.4223 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.4247 - val_loss: 0.4210 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.4380 - val_loss: 0.3974 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4250\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.4250 - val_loss: 0.4141 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.4168 - val_loss: 0.3908 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4190\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.4190 - val_loss: 0.4253 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.4217 - val_loss: 0.3772 - lr: 8.5737e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.3907 - val_loss: 0.3566 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.3919 - val_loss: 0.3294 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3760\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.3760 - val_loss: 0.3622 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.3627 - val_loss: 0.3181 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.3486 - val_loss: 0.3130 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.3438 - val_loss: 0.2971 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3026\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3026 - val_loss: 0.3256 - lr: 8.1451e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3214\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.3214 - val_loss: 0.3034 - lr: 7.7378e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.2974 - val_loss: 0.2360 - lr: 7.3509e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2759 - val_loss: 0.2224 - lr: 7.3509e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2758 - val_loss: 0.2164 - lr: 7.3509e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2656\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2656 - val_loss: 0.2256 - lr: 7.3509e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2566 - val_loss: 0.1504 - lr: 6.9834e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2424\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2424 - val_loss: 0.1726 - lr: 6.9834e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2439\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2439 - val_loss: 0.1837 - lr: 6.6342e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2390\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2390 - val_loss: 0.2107 - lr: 6.3025e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2384\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2384 - val_loss: 0.1548 - lr: 5.9874e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2476\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2476 - val_loss: 0.1934 - lr: 5.6880e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2289 - val_loss: 0.1273 - lr: 5.4036e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2186\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2186 - val_loss: 0.1316 - lr: 5.4036e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2068\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.2068 - val_loss: 0.1412 - lr: 5.1334e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2361\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.2361 - val_loss: 0.1359 - lr: 4.8767e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2177\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.2177 - val_loss: 0.1432 - lr: 4.6329e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2172\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.2172 - val_loss: 0.1648 - lr: 4.4013e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2128\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.2128 - val_loss: 0.1533 - lr: 4.1812e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2082\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.2082 - val_loss: 0.1398 - lr: 3.9721e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2119\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.2119 - val_loss: 0.1311 - lr: 3.7735e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2150\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.2150 - val_loss: 0.1301 - lr: 3.5849e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2048\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.2048 - val_loss: 0.1468 - lr: 3.4056e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1898 - val_loss: 0.1211 - lr: 3.2353e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1958\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1958 - val_loss: 0.1372 - lr: 3.2353e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2021 - val_loss: 0.1159 - lr: 3.0736e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1780\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1780 - val_loss: 0.1294 - lr: 3.0736e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.1806 - val_loss: 0.1099 - lr: 2.9199e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1837\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1837 - val_loss: 0.1159 - lr: 2.9199e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1827\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1827 - val_loss: 0.1338 - lr: 2.7739e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1856\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1856 - val_loss: 0.1352 - lr: 2.6352e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1899\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1899 - val_loss: 0.1169 - lr: 2.5034e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1775\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.1775 - val_loss: 0.1099 - lr: 2.3783e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1764 - val_loss: 0.1084 - lr: 2.2594e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1700 - val_loss: 0.1071 - lr: 2.2594e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1847\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1847 - val_loss: 0.1192 - lr: 2.2594e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1716\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1716 - val_loss: 0.1082 - lr: 2.1464e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1785\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1785 - val_loss: 0.1081 - lr: 2.0391e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1700\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1700 - val_loss: 0.1275 - lr: 1.9371e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1772\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1772 - val_loss: 0.1134 - lr: 1.8403e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1675\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 6s 362ms/step - loss: 0.1675 - val_loss: 0.1271 - lr: 1.7482e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1704\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1704 - val_loss: 0.1083 - lr: 1.6608e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1573\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.1573 - val_loss: 0.1252 - lr: 1.5778e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1559\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1559 - val_loss: 0.1196 - lr: 1.4989e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1607\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1607 - val_loss: 0.1437 - lr: 1.4240e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1727\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1727 - val_loss: 0.1241 - lr: 1.3528e-04\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1591\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 6s 362ms/step - loss: 0.1591 - val_loss: 0.1275 - lr: 1.2851e-04\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1705\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.1705 - val_loss: 0.1420 - lr: 1.2209e-04\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1744\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1744 - val_loss: 0.1178 - lr: 1.1598e-04\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1693\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1693 - val_loss: 0.1115 - lr: 1.1018e-04\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1641\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1641 - val_loss: 0.1164 - lr: 1.0467e-04\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1640\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1640 - val_loss: 0.1211 - lr: 9.9440e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1624\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1624 - val_loss: 0.1227 - lr: 9.4468e-05\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1587\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1587 - val_loss: 0.1189 - lr: 8.9745e-05\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1616\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1616 - val_loss: 0.1169 - lr: 8.5258e-05\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1611\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1611 - val_loss: 0.1213 - lr: 8.0995e-05\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1619\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1619 - val_loss: 0.1162 - lr: 7.6945e-05\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1626\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.1626 - val_loss: 0.1209 - lr: 7.3098e-05\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1573\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1573 - val_loss: 0.1235 - lr: 6.9443e-05\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1573\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.1573 - val_loss: 0.1218 - lr: 6.5971e-05\n",
      "Epoch 76: early stopping\n",
      "2/2 [==============================] - 6s 156ms/step\n",
      "0.1700, 0.1071, 0.1904\n",
      "______fold 6______, ________repeat 7__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 829ms/step - loss: 0.4840 - val_loss: 0.4677 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 413ms/step - loss: 0.4621 - val_loss: 0.4395 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.4325 - val_loss: 0.4097 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.4217 - val_loss: 0.3826 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.3888 - val_loss: 0.3360 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.3720 - val_loss: 0.3030 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3424\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.3424 - val_loss: 0.3493 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3029\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.3029 - val_loss: 0.3489 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.3135 - val_loss: 0.2764 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2893\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2893 - val_loss: 0.2898 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2841 - val_loss: 0.2549 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2793 - val_loss: 0.2037 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2681\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.2681 - val_loss: 0.2593 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2421\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2421 - val_loss: 0.2579 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2501\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2501 - val_loss: 0.2458 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2266\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.2266 - val_loss: 0.2180 - lr: 7.3509e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2246\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2246 - val_loss: 0.3007 - lr: 6.9834e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2160\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2160 - val_loss: 0.2307 - lr: 6.6342e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2258 - val_loss: 0.1756 - lr: 6.3025e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.2032 - val_loss: 0.1600 - lr: 6.3025e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1844\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1844 - val_loss: 0.1949 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2012 - val_loss: 0.1560 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.1821 - val_loss: 0.1524 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1889\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1889 - val_loss: 0.1573 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 9s 493ms/step - loss: 0.1694 - val_loss: 0.1444 - lr: 5.6880e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1992\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 9s 475ms/step - loss: 0.1992 - val_loss: 0.1935 - lr: 5.6880e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1866\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 9s 475ms/step - loss: 0.1866 - val_loss: 0.1462 - lr: 5.4036e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1845\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 9s 476ms/step - loss: 0.1845 - val_loss: 0.1828 - lr: 5.1334e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1878\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 9s 475ms/step - loss: 0.1878 - val_loss: 0.1467 - lr: 4.8767e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1867\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.1867 - val_loss: 0.1524 - lr: 4.6329e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1643\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1643 - val_loss: 0.1454 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1478\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1478 - val_loss: 0.1552 - lr: 4.1812e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1680\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1680 - val_loss: 0.1671 - lr: 3.9721e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1615\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1615 - val_loss: 0.1497 - lr: 3.7735e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1484\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1484 - val_loss: 0.1707 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1500\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1500 - val_loss: 0.1800 - lr: 3.4056e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1582\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1582 - val_loss: 0.1758 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1698\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1698 - val_loss: 0.1646 - lr: 3.0736e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1544\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1544 - val_loss: 0.1738 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1489\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.1489 - val_loss: 0.1451 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1323 - val_loss: 0.1374 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1394\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1394 - val_loss: 0.1430 - lr: 2.6352e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1478\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1478 - val_loss: 0.1538 - lr: 2.5034e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1347 - val_loss: 0.1365 - lr: 2.3783e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1418\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1418 - val_loss: 0.1413 - lr: 2.3783e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1401\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1401 - val_loss: 0.1426 - lr: 2.2594e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1254\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1254 - val_loss: 0.1461 - lr: 2.1464e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1327\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1327 - val_loss: 0.1448 - lr: 2.0391e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1183\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1183 - val_loss: 0.1574 - lr: 1.9371e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1172\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1172 - val_loss: 0.1610 - lr: 1.8403e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1218\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1218 - val_loss: 0.1720 - lr: 1.7482e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1261\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1261 - val_loss: 0.1726 - lr: 1.6608e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1382\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1382 - val_loss: 0.1455 - lr: 1.5778e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1133\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1133 - val_loss: 0.1641 - lr: 1.4989e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1148\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1148 - val_loss: 0.1736 - lr: 1.4240e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1269\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1269 - val_loss: 0.1577 - lr: 1.3528e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1071\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1071 - val_loss: 0.1524 - lr: 1.2851e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1092\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1092 - val_loss: 0.1544 - lr: 1.2209e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1255\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1255 - val_loss: 0.1593 - lr: 1.1598e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1238\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1238 - val_loss: 0.1639 - lr: 1.1018e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1271\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1271 - val_loss: 0.1825 - lr: 1.0467e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1092\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1092 - val_loss: 0.1660 - lr: 9.9440e-05\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1050\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1050 - val_loss: 0.1805 - lr: 9.4468e-05\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1241\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1241 - val_loss: 0.1813 - lr: 8.9745e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1179\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1179 - val_loss: 0.1729 - lr: 8.5258e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1140\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1140 - val_loss: 0.1620 - lr: 8.0995e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1100\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1100 - val_loss: 0.1553 - lr: 7.6945e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1216\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1216 - val_loss: 0.1715 - lr: 7.3098e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1047\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.1047 - val_loss: 0.1779 - lr: 6.9443e-05\n",
      "Epoch 69: early stopping\n",
      "2/2 [==============================] - 6s 118ms/step\n",
      "0.1347, 0.1365, 0.1992\n",
      "______fold 6______, ________repeat 8__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 826ms/step - loss: 0.5090 - val_loss: 0.4582 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.4527 - val_loss: 0.4440 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.4432 - val_loss: 0.4278 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 8s 435ms/step - loss: 0.4400 - val_loss: 0.4101 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4106\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 8s 430ms/step - loss: 0.4106 - val_loss: 0.4215 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3885 - val_loss: 0.3703 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.4128 - val_loss: 0.3475 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.3691 - val_loss: 0.3274 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3551\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.3551 - val_loss: 0.3367 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3608 - val_loss: 0.2996 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.3053 - val_loss: 0.2618 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2745 - val_loss: 0.2471 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3033 - val_loss: 0.2321 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2825\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 418ms/step - loss: 0.2825 - val_loss: 0.2350 - lr: 9.0250e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2646\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2646 - val_loss: 0.2493 - lr: 8.5737e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 413ms/step - loss: 0.2534 - val_loss: 0.1917 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2446\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 8s 422ms/step - loss: 0.2446 - val_loss: 0.2439 - lr: 8.1451e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 8s 432ms/step - loss: 0.2412 - val_loss: 0.1682 - lr: 7.7378e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2329\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 8s 423ms/step - loss: 0.2329 - val_loss: 0.1698 - lr: 7.7378e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2274\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 8s 423ms/step - loss: 0.2274 - val_loss: 0.1692 - lr: 7.3509e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2311\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.2311 - val_loss: 0.1988 - lr: 6.9834e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2288\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.2288 - val_loss: 0.1776 - lr: 6.6342e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 8s 435ms/step - loss: 0.2151 - val_loss: 0.1588 - lr: 6.3025e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1992\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 8s 422ms/step - loss: 0.1992 - val_loss: 0.1871 - lr: 6.3025e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 8s 442ms/step - loss: 0.2143 - val_loss: 0.1577 - lr: 5.9874e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2474\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2474 - val_loss: 0.1817 - lr: 5.9874e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2183\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2183 - val_loss: 0.1661 - lr: 5.6880e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.2106 - val_loss: 0.1526 - lr: 5.4036e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2093\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.2093 - val_loss: 0.1540 - lr: 5.4036e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2190\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2190 - val_loss: 0.1718 - lr: 5.1334e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1953 - val_loss: 0.1483 - lr: 4.8767e-04\n",
      "Epoch 32/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.1850\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1850 - val_loss: 0.1531 - lr: 4.8767e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2015\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2015 - val_loss: 0.1528 - lr: 4.6329e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1804\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1804 - val_loss: 0.1653 - lr: 4.4013e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1849\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1849 - val_loss: 0.1648 - lr: 4.1812e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1838 - val_loss: 0.1430 - lr: 3.9721e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1792\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1792 - val_loss: 0.1618 - lr: 3.9721e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1954\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1954 - val_loss: 0.1652 - lr: 3.7735e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1881\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 8s 473ms/step - loss: 0.1881 - val_loss: 0.1626 - lr: 3.5849e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1774\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 8s 456ms/step - loss: 0.1774 - val_loss: 0.1534 - lr: 3.4056e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1774\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1774 - val_loss: 0.1654 - lr: 3.2353e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1741\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1741 - val_loss: 0.1481 - lr: 3.0736e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1654\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1654 - val_loss: 0.1607 - lr: 2.9199e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1681\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1681 - val_loss: 0.1708 - lr: 2.7739e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1491\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.1491 - val_loss: 0.1883 - lr: 2.6352e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1597\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.1597 - val_loss: 0.1484 - lr: 2.5034e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1620\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.1620 - val_loss: 0.1555 - lr: 2.3783e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1531\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.1531 - val_loss: 0.1627 - lr: 2.2594e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1480\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.1480 - val_loss: 0.1510 - lr: 2.1464e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1396\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1396 - val_loss: 0.1579 - lr: 2.0391e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1487\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1487 - val_loss: 0.1661 - lr: 1.9371e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1600\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1600 - val_loss: 0.1768 - lr: 1.8403e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1614\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1614 - val_loss: 0.1531 - lr: 1.7482e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1589\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.1589 - val_loss: 0.1762 - lr: 1.6608e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1772\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.1772 - val_loss: 0.1564 - lr: 1.5778e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1552\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.1552 - val_loss: 0.1596 - lr: 1.4989e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1509\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.1509 - val_loss: 0.1572 - lr: 1.4240e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1445\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1445 - val_loss: 0.1628 - lr: 1.3528e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1514\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1514 - val_loss: 0.1694 - lr: 1.2851e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1443\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1443 - val_loss: 0.1640 - lr: 1.2209e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1540\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1540 - val_loss: 0.1631 - lr: 1.1598e-04\n",
      "Epoch 61: early stopping\n",
      "2/2 [==============================] - 8s 122ms/step\n",
      "0.1838, 0.1430, 0.2189\n",
      "______fold 6______, ________repeat 9__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 824ms/step - loss: 0.5090 - val_loss: 0.4625 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.4583 - val_loss: 0.4568 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.4505 - val_loss: 0.4452 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.4419 - val_loss: 0.4291 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4260 - val_loss: 0.4239 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.4167 - val_loss: 0.3903 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.3725 - val_loss: 0.3236 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.3158 - val_loss: 0.2437 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3467\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.3467 - val_loss: 0.3047 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2906 - val_loss: 0.2377 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2899 - val_loss: 0.2258 - lr: 9.5000e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2733 - val_loss: 0.2085 - lr: 9.5000e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2493 - val_loss: 0.1989 - lr: 9.5000e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2665\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2665 - val_loss: 0.2114 - lr: 9.5000e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2406\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2406 - val_loss: 0.2295 - lr: 9.0250e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2330 - val_loss: 0.1606 - lr: 8.5737e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2459\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.2459 - val_loss: 0.1641 - lr: 8.5737e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2307\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2307 - val_loss: 0.2161 - lr: 8.1451e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2221\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.2221 - val_loss: 0.1917 - lr: 7.7378e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2279 - val_loss: 0.1494 - lr: 7.3509e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2077\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.2077 - val_loss: 0.1520 - lr: 7.3509e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2007\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.2007 - val_loss: 0.1594 - lr: 6.9834e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1886\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1886 - val_loss: 0.1717 - lr: 6.6342e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2039 - val_loss: 0.1326 - lr: 6.3025e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1942\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1942 - val_loss: 0.1439 - lr: 6.3025e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1875\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1875 - val_loss: 0.1490 - lr: 5.9874e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1852\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1852 - val_loss: 0.1510 - lr: 5.6880e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1980\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1980 - val_loss: 0.1546 - lr: 5.4036e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.1838 - val_loss: 0.1309 - lr: 5.1334e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1736\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.1736 - val_loss: 0.1472 - lr: 5.1334e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1720\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1720 - val_loss: 0.1434 - lr: 4.8767e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1879\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1879 - val_loss: 0.1384 - lr: 4.6329e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1672\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1672 - val_loss: 0.1431 - lr: 4.4013e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1700\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1700 - val_loss: 0.1437 - lr: 4.1812e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1695\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1695 - val_loss: 0.1449 - lr: 3.9721e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1592\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1592 - val_loss: 0.1363 - lr: 3.7735e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1659\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1659 - val_loss: 0.1421 - lr: 3.5849e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1610\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1610 - val_loss: 0.1371 - lr: 3.4056e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1664\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.1664 - val_loss: 0.1405 - lr: 3.2353e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1557\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 6s 362ms/step - loss: 0.1557 - val_loss: 0.1357 - lr: 3.0736e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1581\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1581 - val_loss: 0.1446 - lr: 2.9199e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1441\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1441 - val_loss: 0.1414 - lr: 2.7739e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1564\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1564 - val_loss: 0.1569 - lr: 2.6352e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1562\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1562 - val_loss: 0.1380 - lr: 2.5034e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1609\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1609 - val_loss: 0.1388 - lr: 2.3783e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1631\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1631 - val_loss: 0.1565 - lr: 2.2594e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1538\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1538 - val_loss: 0.1506 - lr: 2.1464e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1599\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1599 - val_loss: 0.1446 - lr: 2.0391e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1343\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1343 - val_loss: 0.1528 - lr: 1.9371e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1412\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1412 - val_loss: 0.1435 - lr: 1.8403e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1495\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1495 - val_loss: 0.1465 - lr: 1.7482e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1454\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.1454 - val_loss: 0.1521 - lr: 1.6608e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1353\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1353 - val_loss: 0.1455 - lr: 1.5778e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1351\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1351 - val_loss: 0.1446 - lr: 1.4989e-04\n",
      "Epoch 54: early stopping\n",
      "2/2 [==============================] - 6s 128ms/step\n",
      "0.1838, 0.1309, 0.1575\n",
      "______fold 6______, ________repeat 10__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 815ms/step - loss: 0.4995 - val_loss: 0.4659 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.4614 - val_loss: 0.4622 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.4564 - val_loss: 0.4397 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4480\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.4480 - val_loss: 0.4416 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.4289 - val_loss: 0.4079 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.3912 - val_loss: 0.3730 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3917\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.3917 - val_loss: 0.4013 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.3543 - val_loss: 0.2995 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.3482 - val_loss: 0.2752 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2936 - val_loss: 0.2441 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2788 - val_loss: 0.2160 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2914\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.2914 - val_loss: 0.2454 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.2699 - val_loss: 0.2154 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2499\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2499 - val_loss: 0.2158 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2527 - val_loss: 0.1752 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 8s 424ms/step - loss: 0.2405 - val_loss: 0.1726 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 8s 430ms/step - loss: 0.2299 - val_loss: 0.1609 - lr: 8.1451e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2362\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2362 - val_loss: 0.1846 - lr: 8.1451e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2384\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2384 - val_loss: 0.1893 - lr: 7.7378e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1999\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1999 - val_loss: 0.1888 - lr: 7.3509e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2170\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2170 - val_loss: 0.1705 - lr: 6.9834e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2268\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2268 - val_loss: 0.1873 - lr: 6.6342e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2105\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2105 - val_loss: 0.2080 - lr: 6.3025e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2170\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2170 - val_loss: 0.1615 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1960\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1960 - val_loss: 0.1796 - lr: 5.6880e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2033\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.2033 - val_loss: 0.1957 - lr: 5.4036e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1855\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1855 - val_loss: 0.1693 - lr: 5.1334e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2018\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2018 - val_loss: 0.2012 - lr: 4.8767e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1941 - val_loss: 0.1557 - lr: 4.6329e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1885\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1885 - val_loss: 0.1620 - lr: 4.6329e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1671\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1671 - val_loss: 0.1736 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1650\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1650 - val_loss: 0.1712 - lr: 4.1812e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1858\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1858 - val_loss: 0.1578 - lr: 3.9721e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1596\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1596 - val_loss: 0.1737 - lr: 3.7735e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1638\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1638 - val_loss: 0.1839 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1676\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1676 - val_loss: 0.1678 - lr: 3.4056e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1691\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1691 - val_loss: 0.1562 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1664\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1664 - val_loss: 0.1753 - lr: 3.0736e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1652\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1652 - val_loss: 0.1721 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1542\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1542 - val_loss: 0.1586 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1674\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.1674 - val_loss: 0.1642 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1526\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 418ms/step - loss: 0.1526 - val_loss: 0.1619 - lr: 2.5034e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1575\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 8s 421ms/step - loss: 0.1575 - val_loss: 0.1617 - lr: 2.3783e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1546\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.1546 - val_loss: 0.1576 - lr: 2.2594e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.1588 - val_loss: 0.1464 - lr: 2.1464e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1572\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.1572 - val_loss: 0.1495 - lr: 2.1464e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1638\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1638 - val_loss: 0.1614 - lr: 2.0391e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1509\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1509 - val_loss: 0.1553 - lr: 1.9371e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1457 - val_loss: 0.1445 - lr: 1.8403e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1471\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.1471 - val_loss: 0.1476 - lr: 1.8403e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1536\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1536 - val_loss: 0.1609 - lr: 1.7482e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1414\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1414 - val_loss: 0.1742 - lr: 1.6608e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1548\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1548 - val_loss: 0.1523 - lr: 1.5778e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1435\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1435 - val_loss: 0.1631 - lr: 1.4989e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1341\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1341 - val_loss: 0.1662 - lr: 1.4240e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1284\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1284 - val_loss: 0.1755 - lr: 1.3528e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1414\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1414 - val_loss: 0.1747 - lr: 1.2851e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1377\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1377 - val_loss: 0.1603 - lr: 1.2209e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1461\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1461 - val_loss: 0.1504 - lr: 1.1598e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1256\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1256 - val_loss: 0.1552 - lr: 1.1018e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1325\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1325 - val_loss: 0.1791 - lr: 1.0467e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1228\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1228 - val_loss: 0.1829 - lr: 9.9440e-05\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1445\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1445 - val_loss: 0.1570 - lr: 9.4468e-05\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1395\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1395 - val_loss: 0.1646 - lr: 8.9745e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1269\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1269 - val_loss: 0.1731 - lr: 8.5258e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1426\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1426 - val_loss: 0.1879 - lr: 8.0995e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1437\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1437 - val_loss: 0.1862 - lr: 7.6945e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1496\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1496 - val_loss: 0.1714 - lr: 7.3098e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1380\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 415ms/step - loss: 0.1380 - val_loss: 0.1946 - lr: 6.9443e-05\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1275\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 7s 414ms/step - loss: 0.1275 - val_loss: 0.1919 - lr: 6.5971e-05\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1311\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1311 - val_loss: 0.1905 - lr: 6.2672e-05\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1284\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 5.656161210936261e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1284 - val_loss: 0.1860 - lr: 5.9539e-05\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1574\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 5.373353305913042e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1574 - val_loss: 0.1568 - lr: 5.6562e-05\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1375\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 5.104685606056591e-05.\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "18/18 [==============================] - 7s 412ms/step - loss: 0.1375 - val_loss: 0.1598 - lr: 5.3734e-05\n",
      "Epoch 74: early stopping\n",
      "2/2 [==============================] - 6s 126ms/step\n",
      "0.1457, 0.1445, 0.2327\n",
      "______fold 7______, ________repeat 1__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 828ms/step - loss: 0.4933 - val_loss: 0.4730 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.4564 - val_loss: 0.4572 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.4424 - val_loss: 0.4167 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.4177 - val_loss: 0.3579 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4205\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 418ms/step - loss: 0.4205 - val_loss: 0.4017 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4066\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.4066 - val_loss: 0.4450 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3883\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.3883 - val_loss: 0.4668 - lr: 9.0250e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.3778 - val_loss: 0.3137 - lr: 8.5737e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3564\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.3564 - val_loss: 0.3870 - lr: 8.5737e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3128\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.3128 - val_loss: 0.4366 - lr: 8.1451e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3237\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.3237 - val_loss: 0.3596 - lr: 7.7378e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2975\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2975 - val_loss: 0.3288 - lr: 7.3509e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2673\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2673 - val_loss: 0.3673 - lr: 6.9834e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2561 - val_loss: 0.2781 - lr: 6.6342e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2908\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2908 - val_loss: 0.2961 - lr: 6.6342e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2622\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.2622 - val_loss: 0.3231 - lr: 6.3025e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.2623 - val_loss: 0.2332 - lr: 5.9874e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2620\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2620 - val_loss: 0.3287 - lr: 5.9874e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2437\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2437 - val_loss: 0.2944 - lr: 5.6880e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2333\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2333 - val_loss: 0.2652 - lr: 5.4036e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2312\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2312 - val_loss: 0.2536 - lr: 5.1334e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2398\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 8s 472ms/step - loss: 0.2398 - val_loss: 0.3004 - lr: 4.8767e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2161\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 9s 474ms/step - loss: 0.2161 - val_loss: 0.2564 - lr: 4.6329e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2291\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2291 - val_loss: 0.2377 - lr: 4.4013e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2270\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2270 - val_loss: 0.2451 - lr: 4.1812e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2329\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2329 - val_loss: 0.2691 - lr: 3.9721e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2075\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2075 - val_loss: 0.2803 - lr: 3.7735e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2169 - val_loss: 0.2272 - lr: 3.5849e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2073\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2073 - val_loss: 0.2409 - lr: 3.5849e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2167 - val_loss: 0.2170 - lr: 3.4056e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2130 - val_loss: 0.2163 - lr: 3.4056e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2034\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2034 - val_loss: 0.2227 - lr: 3.4056e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2204\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2204 - val_loss: 0.2328 - lr: 3.2353e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2055\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2055 - val_loss: 0.2522 - lr: 3.0736e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2021\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2021 - val_loss: 0.2632 - lr: 2.9199e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2036\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2036 - val_loss: 0.2446 - lr: 2.7739e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1918\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1918 - val_loss: 0.2573 - lr: 2.6352e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1865\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1865 - val_loss: 0.2287 - lr: 2.5034e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1969\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1969 - val_loss: 0.2229 - lr: 2.3783e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2006 - val_loss: 0.2095 - lr: 2.2594e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1879\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1879 - val_loss: 0.2416 - lr: 2.2594e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1979\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1979 - val_loss: 0.2242 - lr: 2.1464e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1909\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1909 - val_loss: 0.2210 - lr: 2.0391e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1900\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1900 - val_loss: 0.2228 - lr: 1.9371e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1855\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1855 - val_loss: 0.2104 - lr: 1.8403e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1817\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1817 - val_loss: 0.2520 - lr: 1.7482e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1760\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1760 - val_loss: 0.2185 - lr: 1.6608e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1856\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1856 - val_loss: 0.2120 - lr: 1.5778e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1751\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1751 - val_loss: 0.2366 - lr: 1.4989e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1751\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1751 - val_loss: 0.2115 - lr: 1.4240e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1894\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1894 - val_loss: 0.2165 - lr: 1.3528e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.1825 - val_loss: 0.2006 - lr: 1.2851e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1786\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1786 - val_loss: 0.2039 - lr: 1.2851e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1871\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1871 - val_loss: 0.2070 - lr: 1.2209e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1863\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1863 - val_loss: 0.2069 - lr: 1.1598e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1834\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1834 - val_loss: 0.2109 - lr: 1.1018e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1838\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1838 - val_loss: 0.2086 - lr: 1.0467e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1777\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1777 - val_loss: 0.2064 - lr: 9.9440e-05\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1784\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1784 - val_loss: 0.2079 - lr: 9.4468e-05\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1898\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1898 - val_loss: 0.2131 - lr: 8.9745e-05\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1775\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1775 - val_loss: 0.2086 - lr: 8.5258e-05\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1844\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1844 - val_loss: 0.2062 - lr: 8.0995e-05\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1786\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1786 - val_loss: 0.2083 - lr: 7.6945e-05\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1773\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1773 - val_loss: 0.2099 - lr: 7.3098e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1727\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1727 - val_loss: 0.2152 - lr: 6.9443e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1583\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1583 - val_loss: 0.2205 - lr: 6.5971e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1712\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1712 - val_loss: 0.2107 - lr: 6.2672e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1677\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 5.656161210936261e-05.\n",
      "18/18 [==============================] - 8s 418ms/step - loss: 0.1677 - val_loss: 0.2037 - lr: 5.9539e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1821\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 5.373353305913042e-05.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1821 - val_loss: 0.2031 - lr: 5.6562e-05\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1795\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 5.104685606056591e-05.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1795 - val_loss: 0.2159 - lr: 5.3734e-05\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1769\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 4.849451343034161e-05.\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.1769 - val_loss: 0.2097 - lr: 5.1047e-05\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1722\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 4.606978654919658e-05.\n",
      "18/18 [==============================] - 8s 421ms/step - loss: 0.1722 - val_loss: 0.2096 - lr: 4.8495e-05\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1757\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 4.3766295493696814e-05.\n",
      "18/18 [==============================] - 7s 360ms/step - loss: 0.1757 - val_loss: 0.2075 - lr: 4.6070e-05\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1707\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 4.1577981755835934e-05.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.1707 - val_loss: 0.2030 - lr: 4.3766e-05\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1824\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 3.949908405047608e-05.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1824 - val_loss: 0.2034 - lr: 4.1578e-05\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1669\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 3.752413140318822e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1669 - val_loss: 0.2052 - lr: 3.9499e-05\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1535\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 3.564792586985277e-05.\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1535 - val_loss: 0.2091 - lr: 3.7524e-05\n",
      "Epoch 77: early stopping\n",
      "2/2 [==============================] - 6s 129ms/step\n",
      "0.1825, 0.2006, 0.3706\n",
      "______fold 7______, ________repeat 2__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 824ms/step - loss: 0.5033 - val_loss: 0.4975 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.4613 - val_loss: 0.4875 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.4579 - val_loss: 0.4713 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.4417 - val_loss: 0.4387 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.4119 - val_loss: 0.3638 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3780\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.3780 - val_loss: 0.4110 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.3661 - val_loss: 0.3279 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 8s 422ms/step - loss: 0.3359 - val_loss: 0.2999 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3548\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 413ms/step - loss: 0.3548 - val_loss: 0.3702 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.3247 - val_loss: 0.2996 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.2929 - val_loss: 0.2690 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2807\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2807 - val_loss: 0.2855 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2659\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2659 - val_loss: 0.2813 - lr: 8.5737e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.2668 - val_loss: 0.2479 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2583\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.2583 - val_loss: 0.2523 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2501\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2501 - val_loss: 0.2941 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2310\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2310 - val_loss: 0.2636 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2333\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2333 - val_loss: 0.2582 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2222\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2222 - val_loss: 0.2817 - lr: 6.6342e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2187\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2187 - val_loss: 0.2718 - lr: 6.3025e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2109\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2109 - val_loss: 0.2559 - lr: 5.9874e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1943\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1943 - val_loss: 0.2741 - lr: 5.6880e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2062\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.2062 - val_loss: 0.2478 - lr: 5.4036e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.1936 - val_loss: 0.2440 - lr: 5.1334e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1959\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.1959 - val_loss: 0.2456 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1938\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1938 - val_loss: 0.2579 - lr: 4.8767e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1852\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1852 - val_loss: 0.2696 - lr: 4.6329e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1886\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1886 - val_loss: 0.2543 - lr: 4.4013e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1992\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1992 - val_loss: 0.2758 - lr: 4.1812e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1682\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1682 - val_loss: 0.2938 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1868\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1868 - val_loss: 0.2552 - lr: 3.7735e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1635\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1635 - val_loss: 0.2744 - lr: 3.5849e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1890\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1890 - val_loss: 0.2501 - lr: 3.4056e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1975\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1975 - val_loss: 0.2564 - lr: 3.2353e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1747 - val_loss: 0.2425 - lr: 3.0736e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1657 - val_loss: 0.2406 - lr: 3.0736e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1854\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1854 - val_loss: 0.2590 - lr: 3.0736e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1671\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1671 - val_loss: 0.2655 - lr: 2.9199e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1604\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1604 - val_loss: 0.2606 - lr: 2.7739e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1650\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1650 - val_loss: 0.2587 - lr: 2.6352e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1516\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1516 - val_loss: 0.2511 - lr: 2.5034e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1506\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1506 - val_loss: 0.2596 - lr: 2.3783e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1545\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1545 - val_loss: 0.2485 - lr: 2.2594e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1731 - val_loss: 0.2364 - lr: 2.1464e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1530\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1530 - val_loss: 0.2389 - lr: 2.1464e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1444\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1444 - val_loss: 0.2533 - lr: 2.0391e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1458\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1458 - val_loss: 0.2597 - lr: 1.9371e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1506\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1506 - val_loss: 0.2594 - lr: 1.8403e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1374\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1374 - val_loss: 0.2686 - lr: 1.7482e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1507\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1507 - val_loss: 0.2545 - lr: 1.6608e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1446\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1446 - val_loss: 0.2521 - lr: 1.5778e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1463\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1463 - val_loss: 0.2569 - lr: 1.4989e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1356\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1356 - val_loss: 0.2570 - lr: 1.4240e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1405\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1405 - val_loss: 0.2589 - lr: 1.3528e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1439\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1439 - val_loss: 0.2557 - lr: 1.2851e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1414\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1414 - val_loss: 0.2589 - lr: 1.2209e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1296\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1296 - val_loss: 0.2701 - lr: 1.1598e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1292\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1292 - val_loss: 0.2700 - lr: 1.1018e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1368\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1368 - val_loss: 0.2722 - lr: 1.0467e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1135\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1135 - val_loss: 0.2722 - lr: 9.9440e-05\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1405\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1405 - val_loss: 0.2802 - lr: 9.4468e-05\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1301\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1301 - val_loss: 0.2746 - lr: 8.9745e-05\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1384\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1384 - val_loss: 0.2787 - lr: 8.5258e-05\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1427\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1427 - val_loss: 0.2822 - lr: 8.0995e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1296\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1296 - val_loss: 0.2803 - lr: 7.6945e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1260\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1260 - val_loss: 0.2772 - lr: 7.3098e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1235\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1235 - val_loss: 0.2790 - lr: 6.9443e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1258\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1258 - val_loss: 0.2814 - lr: 6.5971e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1297\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.1297 - val_loss: 0.2858 - lr: 6.2672e-05\n",
      "Epoch 69: early stopping\n",
      "2/2 [==============================] - 6s 137ms/step\n",
      "0.1731, 0.2364, 0.4494\n",
      "______fold 7______, ________repeat 3__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 826ms/step - loss: 0.5085 - val_loss: 0.4900 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 421ms/step - loss: 0.4589 - val_loss: 0.4897 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.4584 - val_loss: 0.4853 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.4558 - val_loss: 0.4733 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 8s 423ms/step - loss: 0.4484 - val_loss: 0.4585 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.4362 - val_loss: 0.4033 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.4040 - val_loss: 0.3594 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.3560 - val_loss: 0.2775 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.3075 - val_loss: 0.2748 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3032\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3032 - val_loss: 0.2758 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2936\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2936 - val_loss: 0.3096 - lr: 9.5000e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2816\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2816 - val_loss: 0.3092 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2636\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2636 - val_loss: 0.3033 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2575\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2575 - val_loss: 0.3065 - lr: 8.1451e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2565 - val_loss: 0.2325 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2467\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2467 - val_loss: 0.2652 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2222\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2222 - val_loss: 0.2486 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2338 - val_loss: 0.2032 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2171\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2171 - val_loss: 0.2659 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2244\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2244 - val_loss: 0.2319 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2347\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2347 - val_loss: 0.2680 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2157\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2157 - val_loss: 0.2346 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2035\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2035 - val_loss: 0.2317 - lr: 5.6880e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1988\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1988 - val_loss: 0.2194 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1964\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1964 - val_loss: 0.2361 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1910\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1910 - val_loss: 0.2564 - lr: 4.8767e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1767\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1767 - val_loss: 0.2526 - lr: 4.6329e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1903\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1903 - val_loss: 0.2171 - lr: 4.4013e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1875\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.1875 - val_loss: 0.2267 - lr: 4.1812e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1879\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1879 - val_loss: 0.2404 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2037\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2037 - val_loss: 0.2269 - lr: 3.7735e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1758\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1758 - val_loss: 0.2354 - lr: 3.5849e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1764\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1764 - val_loss: 0.2331 - lr: 3.4056e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1922\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1922 - val_loss: 0.2299 - lr: 3.2353e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1664\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1664 - val_loss: 0.2365 - lr: 3.0736e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2071\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2071 - val_loss: 0.2286 - lr: 2.9199e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1724\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1724 - val_loss: 0.2490 - lr: 2.7739e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1707\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1707 - val_loss: 0.2253 - lr: 2.6352e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1739\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1739 - val_loss: 0.2277 - lr: 2.5034e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1550\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1550 - val_loss: 0.2258 - lr: 2.3783e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1735\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1735 - val_loss: 0.2226 - lr: 2.2594e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1566\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1566 - val_loss: 0.2039 - lr: 2.1464e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1668\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1668 - val_loss: 0.2077 - lr: 2.0391e-04\n",
      "Epoch 43: early stopping\n",
      "2/2 [==============================] - 6s 125ms/step\n",
      "0.2338, 0.2032, 0.3484\n",
      "______fold 7______, ________repeat 4__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 825ms/step - loss: 0.4927 - val_loss: 0.4896 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.4593 - val_loss: 0.4889 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.4562 - val_loss: 0.4767 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.4506 - val_loss: 0.4655 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.4455 - val_loss: 0.4537 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.4388 - val_loss: 0.4285 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.4197 - val_loss: 0.3980 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.3910 - val_loss: 0.3510 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.3550 - val_loss: 0.3421 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.3692 - val_loss: 0.3129 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.3257 - val_loss: 0.2858 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2914 - val_loss: 0.2485 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3200\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.3200 - val_loss: 0.2679 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2938 - val_loss: 0.2366 - lr: 9.5000e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2839\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2839 - val_loss: 0.2423 - lr: 9.5000e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2521\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2521 - val_loss: 0.2542 - lr: 9.0250e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2512 - val_loss: 0.2012 - lr: 8.5737e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2473\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2473 - val_loss: 0.2453 - lr: 8.5737e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2249\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2249 - val_loss: 0.2212 - lr: 8.1451e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2167\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2167 - val_loss: 0.2062 - lr: 7.7378e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2112\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2112 - val_loss: 0.2126 - lr: 7.3509e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2116\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2116 - val_loss: 0.2358 - lr: 6.9834e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2242 - val_loss: 0.1808 - lr: 6.6342e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1981\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1981 - val_loss: 0.2163 - lr: 6.6342e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1857\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1857 - val_loss: 0.2119 - lr: 6.3025e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1951\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1951 - val_loss: 0.2200 - lr: 5.9874e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1838\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1838 - val_loss: 0.2007 - lr: 5.6880e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.1790 - val_loss: 0.1770 - lr: 5.4036e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1855\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 412ms/step - loss: 0.1855 - val_loss: 0.1911 - lr: 5.4036e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1908\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1908 - val_loss: 0.2388 - lr: 5.1334e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1769\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1769 - val_loss: 0.2113 - lr: 4.8767e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1907\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1907 - val_loss: 0.2307 - lr: 4.6329e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1750\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1750 - val_loss: 0.2369 - lr: 4.4013e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1839\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1839 - val_loss: 0.2408 - lr: 4.1812e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1690\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1690 - val_loss: 0.1911 - lr: 3.9721e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1650\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1650 - val_loss: 0.1911 - lr: 3.7735e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1720\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1720 - val_loss: 0.2648 - lr: 3.5849e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1783\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1783 - val_loss: 0.1885 - lr: 3.4056e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1625\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1625 - val_loss: 0.2210 - lr: 3.2353e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1736\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1736 - val_loss: 0.2117 - lr: 3.0736e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1655\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1655 - val_loss: 0.2143 - lr: 2.9199e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1640\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1640 - val_loss: 0.2635 - lr: 2.7739e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1488\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1488 - val_loss: 0.2534 - lr: 2.6352e-04\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.1431\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1431 - val_loss: 0.2309 - lr: 2.5034e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1574\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1574 - val_loss: 0.2181 - lr: 2.3783e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1489\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1489 - val_loss: 0.2529 - lr: 2.2594e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1564\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1564 - val_loss: 0.2214 - lr: 2.1464e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1434\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1434 - val_loss: 0.2324 - lr: 2.0391e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1487\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1487 - val_loss: 0.2393 - lr: 1.9371e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1516\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1516 - val_loss: 0.2386 - lr: 1.8403e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1511\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1511 - val_loss: 0.2503 - lr: 1.7482e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1410\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1410 - val_loss: 0.2397 - lr: 1.6608e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1374\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1374 - val_loss: 0.2526 - lr: 1.5778e-04\n",
      "Epoch 53: early stopping\n",
      "2/2 [==============================] - 6s 129ms/step\n",
      "0.1790, 0.1770, 0.2715\n",
      "______fold 7______, ________repeat 5__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 832ms/step - loss: 0.4898 - val_loss: 0.4920 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 443ms/step - loss: 0.4622 - val_loss: 0.4876 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.4576 - val_loss: 0.4663 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.4490 - val_loss: 0.4398 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.4285 - val_loss: 0.3500 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.4102 - val_loss: 0.3148 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.3798 - val_loss: 0.2954 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.3748 - val_loss: 0.2749 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.3511 - val_loss: 0.2659 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3526\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.3526 - val_loss: 0.2913 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3116\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.3116 - val_loss: 0.2749 - lr: 9.5000e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.3010 - val_loss: 0.2239 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2781\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2781 - val_loss: 0.2376 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2669 - val_loss: 0.2188 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2554\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2554 - val_loss: 0.2188 - lr: 8.5737e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2531 - val_loss: 0.2180 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2415\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 415ms/step - loss: 0.2415 - val_loss: 0.2510 - lr: 8.1451e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2557 - val_loss: 0.1878 - lr: 7.7378e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2215\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2215 - val_loss: 0.2001 - lr: 7.7378e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2316 - val_loss: 0.1818 - lr: 7.3509e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2184\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2184 - val_loss: 0.1982 - lr: 7.3509e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2141\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2141 - val_loss: 0.2107 - lr: 6.9834e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2371\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2371 - val_loss: 0.1871 - lr: 6.6342e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2012\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2012 - val_loss: 0.1900 - lr: 6.3025e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1981\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1981 - val_loss: 0.2066 - lr: 5.9874e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1765\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1765 - val_loss: 0.3011 - lr: 5.6880e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1724\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1724 - val_loss: 0.2767 - lr: 5.4036e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1790\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1790 - val_loss: 0.2405 - lr: 5.1334e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1669\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1669 - val_loss: 0.2155 - lr: 4.8767e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1697\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1697 - val_loss: 0.2905 - lr: 4.6329e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1755\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1755 - val_loss: 0.2363 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1745\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1745 - val_loss: 0.2907 - lr: 4.1812e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1732\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1732 - val_loss: 0.2508 - lr: 3.9721e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1757\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1757 - val_loss: 0.3278 - lr: 3.7735e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1728\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1728 - val_loss: 0.2854 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1672\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1672 - val_loss: 0.2614 - lr: 3.4056e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1595\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1595 - val_loss: 0.2727 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1507\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1507 - val_loss: 0.2519 - lr: 3.0736e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1549\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1549 - val_loss: 0.2429 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1402\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1402 - val_loss: 0.2390 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1551\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1551 - val_loss: 0.2562 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1402\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1402 - val_loss: 0.2709 - lr: 2.5034e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1360\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1360 - val_loss: 0.2833 - lr: 2.3783e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1314\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1314 - val_loss: 0.2820 - lr: 2.2594e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1294\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.1294 - val_loss: 0.2680 - lr: 2.1464e-04\n",
      "Epoch 45: early stopping\n",
      "2/2 [==============================] - 6s 128ms/step\n",
      "0.2316, 0.1818, 0.2910\n",
      "______fold 7______, ________repeat 6__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 875ms/step - loss: 0.5026 - val_loss: 0.4693 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.4538 - val_loss: 0.4296 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.4351 - val_loss: 0.3643 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4241\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.4241 - val_loss: 0.3981 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4291\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.4291 - val_loss: 0.3898 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4210 - val_loss: 0.3631 - lr: 9.0250e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.4130 - val_loss: 0.3545 - lr: 9.0250e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.3816 - val_loss: 0.3177 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 414ms/step - loss: 0.3362 - val_loss: 0.3131 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.3341 - val_loss: 0.3004 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3131\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.3131 - val_loss: 0.3402 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3058\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.3058 - val_loss: 0.3718 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2931\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2931 - val_loss: 0.3423 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3016\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.3016 - val_loss: 0.3445 - lr: 7.7378e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3039\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.3039 - val_loss: 0.3611 - lr: 7.3509e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2816\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2816 - val_loss: 0.3208 - lr: 6.9834e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2706 - val_loss: 0.2885 - lr: 6.6342e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.2543 - val_loss: 0.2835 - lr: 6.6342e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.2707 - val_loss: 0.2585 - lr: 6.6342e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2326 - val_loss: 0.2214 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2245\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 8s 421ms/step - loss: 0.2245 - val_loss: 0.2804 - lr: 6.6342e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2436\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2436 - val_loss: 0.3469 - lr: 6.3025e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2206\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2206 - val_loss: 0.2753 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2110\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2110 - val_loss: 0.2327 - lr: 5.6880e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2369\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2369 - val_loss: 0.3395 - lr: 5.4036e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2400\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2400 - val_loss: 0.2217 - lr: 5.1334e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1965\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1965 - val_loss: 0.2394 - lr: 4.8767e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1886\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1886 - val_loss: 0.2272 - lr: 4.6329e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1944\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1944 - val_loss: 0.2389 - lr: 4.4013e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2036\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2036 - val_loss: 0.2444 - lr: 4.1812e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2056 - val_loss: 0.2019 - lr: 3.9721e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1968\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1968 - val_loss: 0.2390 - lr: 3.9721e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2025\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2025 - val_loss: 0.2258 - lr: 3.7735e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1875\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1875 - val_loss: 0.2110 - lr: 3.5849e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1906\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1906 - val_loss: 0.2253 - lr: 3.4056e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1803\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1803 - val_loss: 0.2401 - lr: 3.2353e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1810\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1810 - val_loss: 0.2300 - lr: 3.0736e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1783\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1783 - val_loss: 0.2352 - lr: 2.9199e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1816\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1816 - val_loss: 0.2300 - lr: 2.7739e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1804\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1804 - val_loss: 0.2423 - lr: 2.6352e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1895\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1895 - val_loss: 0.2263 - lr: 2.5034e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1754\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1754 - val_loss: 0.2624 - lr: 2.3783e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1832\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1832 - val_loss: 0.2409 - lr: 2.2594e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1778\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1778 - val_loss: 0.2373 - lr: 2.1464e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1795\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1795 - val_loss: 0.2172 - lr: 2.0391e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1626\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1626 - val_loss: 0.2467 - lr: 1.9371e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1863\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1863 - val_loss: 0.2342 - lr: 1.8403e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1739\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1739 - val_loss: 0.2305 - lr: 1.7482e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1625\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1625 - val_loss: 0.2388 - lr: 1.6608e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1802\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1802 - val_loss: 0.2346 - lr: 1.5778e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1644\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1644 - val_loss: 0.2243 - lr: 1.4989e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1697\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1697 - val_loss: 0.2155 - lr: 1.4240e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1672\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1672 - val_loss: 0.2134 - lr: 1.3528e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1573\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1573 - val_loss: 0.2152 - lr: 1.2851e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1669\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.1669 - val_loss: 0.2280 - lr: 1.2209e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1806\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.1806 - val_loss: 0.2227 - lr: 1.1598e-04\n",
      "Epoch 56: early stopping\n",
      "2/2 [==============================] - 7s 134ms/step\n",
      "0.2056, 0.2019, 0.3547\n",
      "______fold 7______, ________repeat 7__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 835ms/step - loss: 0.5013 - val_loss: 0.4877 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 443ms/step - loss: 0.4552 - val_loss: 0.4601 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.4497 - val_loss: 0.4294 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.4389 - val_loss: 0.4258 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.4217 - val_loss: 0.3585 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.4077 - val_loss: 0.3471 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.3627 - val_loss: 0.3229 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.3512 - val_loss: 0.2925 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3008 - val_loss: 0.2708 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2894\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.2894 - val_loss: 0.2821 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2764\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2764 - val_loss: 0.3024 - lr: 9.5000e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2770\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2770 - val_loss: 0.2988 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2654\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.2654 - val_loss: 0.3118 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2744\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2744 - val_loss: 0.3354 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2750\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2750 - val_loss: 0.3827 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2440\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2440 - val_loss: 0.3386 - lr: 7.3509e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2434 - val_loss: 0.2692 - lr: 6.9834e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2394\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2394 - val_loss: 0.3087 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2189\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2189 - val_loss: 0.3696 - lr: 6.6342e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2088\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2088 - val_loss: 0.3128 - lr: 6.3025e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2164\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2164 - val_loss: 0.3882 - lr: 5.9874e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2125\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2125 - val_loss: 0.3644 - lr: 5.6880e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2033\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2033 - val_loss: 0.3091 - lr: 5.4036e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2177\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2177 - val_loss: 0.2876 - lr: 5.1334e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1953\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1953 - val_loss: 0.2979 - lr: 4.8767e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1932\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1932 - val_loss: 0.3700 - lr: 4.6329e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1978\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1978 - val_loss: 0.3401 - lr: 4.4013e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1964\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1964 - val_loss: 0.3673 - lr: 4.1812e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1817\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1817 - val_loss: 0.3502 - lr: 3.9721e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1928\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1928 - val_loss: 0.3229 - lr: 3.7735e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1850\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1850 - val_loss: 0.3432 - lr: 3.5849e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1809\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1809 - val_loss: 0.3381 - lr: 3.4056e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1867\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1867 - val_loss: 0.3558 - lr: 3.2353e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1912\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1912 - val_loss: 0.3474 - lr: 3.0736e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1810\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1810 - val_loss: 0.3843 - lr: 2.9199e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1965\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1965 - val_loss: 0.3663 - lr: 2.7739e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1935\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1935 - val_loss: 0.3123 - lr: 2.6352e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1865\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1865 - val_loss: 0.3277 - lr: 2.5034e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1826\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1826 - val_loss: 0.3799 - lr: 2.3783e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1653\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1653 - val_loss: 0.3601 - lr: 2.2594e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1571\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1571 - val_loss: 0.3873 - lr: 2.1464e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1629\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1629 - val_loss: 0.3835 - lr: 2.0391e-04\n",
      "Epoch 42: early stopping\n",
      "2/2 [==============================] - 6s 130ms/step\n",
      "0.2434, 0.2692, 0.4417\n",
      "______fold 7______, ________repeat 8__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 830ms/step - loss: 0.5014 - val_loss: 0.4881 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.4605 - val_loss: 0.4828 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.4558 - val_loss: 0.4728 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4470 - val_loss: 0.4518 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.4321 - val_loss: 0.4281 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.4191 - val_loss: 0.3946 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.3713 - val_loss: 0.3362 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.3651 - val_loss: 0.3216 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3547 - val_loss: 0.2993 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.3456 - val_loss: 0.2924 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.3182 - val_loss: 0.2629 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2677\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2677 - val_loss: 0.2740 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2455 - val_loss: 0.2570 - lr: 9.5000e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 8s 449ms/step - loss: 0.2288 - val_loss: 0.2199 - lr: 9.5000e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2331\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 418ms/step - loss: 0.2331 - val_loss: 0.2519 - lr: 9.5000e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2140\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2140 - val_loss: 0.2801 - lr: 9.0250e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2131 - val_loss: 0.1905 - lr: 8.5737e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2037\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2037 - val_loss: 0.2231 - lr: 8.5737e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2098\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2098 - val_loss: 0.2108 - lr: 8.1451e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.1880 - val_loss: 0.1814 - lr: 7.7378e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1865\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.1865 - val_loss: 0.2736 - lr: 7.7378e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1804\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1804 - val_loss: 0.2076 - lr: 7.3509e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1929\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1929 - val_loss: 0.1951 - lr: 6.9834e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1812\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1812 - val_loss: 0.1948 - lr: 6.6342e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1757\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1757 - val_loss: 0.2471 - lr: 6.3025e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1652\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1652 - val_loss: 0.2094 - lr: 5.9874e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1737\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1737 - val_loss: 0.2116 - lr: 5.6880e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1591\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1591 - val_loss: 0.2043 - lr: 5.4036e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1511\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1511 - val_loss: 0.2249 - lr: 5.1334e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1599\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1599 - val_loss: 0.2183 - lr: 4.8767e-04\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.1424\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1424 - val_loss: 0.2040 - lr: 4.6329e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1723\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1723 - val_loss: 0.2338 - lr: 4.4013e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1494\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1494 - val_loss: 0.1911 - lr: 4.1812e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1585\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1585 - val_loss: 0.2037 - lr: 3.9721e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1495\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1495 - val_loss: 0.2070 - lr: 3.7735e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1301\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1301 - val_loss: 0.1951 - lr: 3.5849e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1305\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1305 - val_loss: 0.2130 - lr: 3.4056e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1309\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1309 - val_loss: 0.1907 - lr: 3.2353e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1339\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1339 - val_loss: 0.2192 - lr: 3.0736e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1527\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1527 - val_loss: 0.2249 - lr: 2.9199e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1391\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1391 - val_loss: 0.2356 - lr: 2.7739e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1398\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1398 - val_loss: 0.2214 - lr: 2.6352e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1200\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1200 - val_loss: 0.2414 - lr: 2.5034e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1186\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1186 - val_loss: 0.2428 - lr: 2.3783e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1409\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.1409 - val_loss: 0.2238 - lr: 2.2594e-04\n",
      "Epoch 45: early stopping\n",
      "2/2 [==============================] - 6s 134ms/step\n",
      "0.1880, 0.1814, 0.3137\n",
      "______fold 7______, ________repeat 9__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 831ms/step - loss: 0.5012 - val_loss: 0.4861 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.4541 - val_loss: 0.4672 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4408 - val_loss: 0.4146 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.4292 - val_loss: 0.3719 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 8s 442ms/step - loss: 0.3894 - val_loss: 0.3078 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3513\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.3513 - val_loss: 0.3819 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3333\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.3333 - val_loss: 0.3232 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3118\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3118 - val_loss: 0.3466 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2816\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2816 - val_loss: 0.3763 - lr: 8.5737e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2599 - val_loss: 0.2411 - lr: 8.1451e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2753\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2753 - val_loss: 0.2425 - lr: 8.1451e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2409\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2409 - val_loss: 0.3051 - lr: 7.7378e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2359\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2359 - val_loss: 0.3910 - lr: 7.3509e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2628\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2628 - val_loss: 0.2739 - lr: 6.9834e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2421\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2421 - val_loss: 0.2540 - lr: 6.6342e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2135\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2135 - val_loss: 0.2507 - lr: 6.3025e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2402\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2402 - val_loss: 0.2738 - lr: 5.9874e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2120 - val_loss: 0.1891 - lr: 5.6880e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2250\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2250 - val_loss: 0.3009 - lr: 5.6880e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1946\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1946 - val_loss: 0.2603 - lr: 5.4036e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1972\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1972 - val_loss: 0.2299 - lr: 5.1334e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2091\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2091 - val_loss: 0.2991 - lr: 4.8767e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2023\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2023 - val_loss: 0.2107 - lr: 4.6329e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1954\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1954 - val_loss: 0.1944 - lr: 4.4013e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1925\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1925 - val_loss: 0.2141 - lr: 4.1812e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1921\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1921 - val_loss: 0.2528 - lr: 3.9721e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1774\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1774 - val_loss: 0.2183 - lr: 3.7735e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1687\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1687 - val_loss: 0.2763 - lr: 3.5849e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1605\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1605 - val_loss: 0.2331 - lr: 3.4056e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1764\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1764 - val_loss: 0.2726 - lr: 3.2353e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1716\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1716 - val_loss: 0.2223 - lr: 3.0736e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1760\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1760 - val_loss: 0.2245 - lr: 2.9199e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1636\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1636 - val_loss: 0.2450 - lr: 2.7739e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1768\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1768 - val_loss: 0.2312 - lr: 2.6352e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1793\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.1793 - val_loss: 0.2501 - lr: 2.5034e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1691\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1691 - val_loss: 0.2193 - lr: 2.3783e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1573\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1573 - val_loss: 0.2377 - lr: 2.2594e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1564\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.1564 - val_loss: 0.2218 - lr: 2.1464e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1511\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.1511 - val_loss: 0.2414 - lr: 2.0391e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1613\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1613 - val_loss: 0.2301 - lr: 1.9371e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1585\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.1585 - val_loss: 0.2395 - lr: 1.8403e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1595\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1595 - val_loss: 0.2378 - lr: 1.7482e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1586\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.1586 - val_loss: 0.2335 - lr: 1.6608e-04\n",
      "Epoch 43: early stopping\n",
      "2/2 [==============================] - 7s 136ms/step\n",
      "0.2120, 0.1891, 0.2901\n",
      "______fold 7______, ________repeat 10__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 832ms/step - loss: 0.5226 - val_loss: 0.4860 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.4551 - val_loss: 0.4385 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.4489 - val_loss: 0.4220 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.4296 - val_loss: 0.4081 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.4085 - val_loss: 0.3362 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.3566 - val_loss: 0.2914 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3530\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 414ms/step - loss: 0.3530 - val_loss: 0.3729 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3222\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.3222 - val_loss: 0.3051 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2749 - val_loss: 0.2756 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2584 - val_loss: 0.2703 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2508\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2508 - val_loss: 0.2858 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 413ms/step - loss: 0.2440 - val_loss: 0.1868 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2410\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2410 - val_loss: 0.2070 - lr: 8.5737e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2173\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2173 - val_loss: 0.2186 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2280\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2280 - val_loss: 0.2197 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2064\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2064 - val_loss: 0.2135 - lr: 7.3509e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2137\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2137 - val_loss: 0.2264 - lr: 6.9834e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2126\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2126 - val_loss: 0.2634 - lr: 6.6342e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1938\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1938 - val_loss: 0.2479 - lr: 6.3025e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1949\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1949 - val_loss: 0.2073 - lr: 5.9874e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1989\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1989 - val_loss: 0.2797 - lr: 5.6880e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1960\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1960 - val_loss: 0.2438 - lr: 5.4036e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1732\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1732 - val_loss: 0.2002 - lr: 5.1334e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1861\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1861 - val_loss: 0.1895 - lr: 4.8767e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1764\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1764 - val_loss: 0.2049 - lr: 4.6329e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1699\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1699 - val_loss: 0.2246 - lr: 4.4013e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1710\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1710 - val_loss: 0.2168 - lr: 4.1812e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1814\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1814 - val_loss: 0.1947 - lr: 3.9721e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1715\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1715 - val_loss: 0.1993 - lr: 3.7735e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1626\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1626 - val_loss: 0.2009 - lr: 3.5849e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1653\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1653 - val_loss: 0.2107 - lr: 3.4056e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1714\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1714 - val_loss: 0.2029 - lr: 3.2353e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1537\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1537 - val_loss: 0.2033 - lr: 3.0736e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1557\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1557 - val_loss: 0.1941 - lr: 2.9199e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1377\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1377 - val_loss: 0.1904 - lr: 2.7739e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1474 - val_loss: 0.1761 - lr: 2.6352e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1588\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1588 - val_loss: 0.1954 - lr: 2.6352e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1553 - val_loss: 0.1697 - lr: 2.5034e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1487\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1487 - val_loss: 0.1918 - lr: 2.5034e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1396\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1396 - val_loss: 0.1991 - lr: 2.3783e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1453\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1453 - val_loss: 0.1876 - lr: 2.2594e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1424\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1424 - val_loss: 0.1798 - lr: 2.1464e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1387\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1387 - val_loss: 0.1948 - lr: 2.0391e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1471\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1471 - val_loss: 0.2138 - lr: 1.9371e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1615\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1615 - val_loss: 0.1946 - lr: 1.8403e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1628\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1628 - val_loss: 0.2024 - lr: 1.7482e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1456\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1456 - val_loss: 0.1920 - lr: 1.6608e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1497\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1497 - val_loss: 0.1943 - lr: 1.5778e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1347\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1347 - val_loss: 0.1953 - lr: 1.4989e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1333\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1333 - val_loss: 0.1978 - lr: 1.4240e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1413\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1413 - val_loss: 0.1955 - lr: 1.3528e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1315\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1315 - val_loss: 0.1861 - lr: 1.2851e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1290\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1290 - val_loss: 0.1926 - lr: 1.2209e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1289\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1289 - val_loss: 0.2033 - lr: 1.1598e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1327\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1327 - val_loss: 0.2003 - lr: 1.1018e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1413\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1413 - val_loss: 0.2033 - lr: 1.0467e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1283\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1283 - val_loss: 0.2043 - lr: 9.9440e-05\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1256\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1256 - val_loss: 0.1980 - lr: 9.4468e-05\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1314\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1314 - val_loss: 0.1930 - lr: 8.9745e-05\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1235\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1235 - val_loss: 0.1948 - lr: 8.5258e-05\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1259\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1259 - val_loss: 0.1877 - lr: 8.0995e-05\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1225\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1225 - val_loss: 0.1884 - lr: 7.6945e-05\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1337\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.1337 - val_loss: 0.1871 - lr: 7.3098e-05\n",
      "Epoch 63: early stopping\n",
      "2/2 [==============================] - 8s 135ms/step\n",
      "0.1553, 0.1697, 0.3492\n",
      "______fold 8______, ________repeat 1__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 829ms/step - loss: 0.5123 - val_loss: 0.4403 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.4618 - val_loss: 0.4274 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.4463 - val_loss: 0.4078 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.4273 - val_loss: 0.3855 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.4256 - val_loss: 0.3822 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.3769 - val_loss: 0.3296 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.3652 - val_loss: 0.3273 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3608\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.3608 - val_loss: 0.3274 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3274\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.3274 - val_loss: 0.3395 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.3511 - val_loss: 0.3230 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3211\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.3211 - val_loss: 0.3255 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3129\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.3129 - val_loss: 0.3237 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2899 - val_loss: 0.3183 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2834 - val_loss: 0.3171 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2817\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2817 - val_loss: 0.3210 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2886\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2886 - val_loss: 0.3199 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2719\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2719 - val_loss: 0.3354 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2629 - val_loss: 0.3139 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2471 - val_loss: 0.3031 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2548\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.2548 - val_loss: 0.3573 - lr: 6.9834e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2445\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2445 - val_loss: 0.3042 - lr: 6.6342e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2336 - val_loss: 0.2921 - lr: 6.3025e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2295 - val_loss: 0.2780 - lr: 6.3025e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2138\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2138 - val_loss: 0.2952 - lr: 6.3025e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2182\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2182 - val_loss: 0.2863 - lr: 5.9874e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2075\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2075 - val_loss: 0.2884 - lr: 5.6880e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2048 - val_loss: 0.2743 - lr: 5.4036e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2139\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.2139 - val_loss: 0.2825 - lr: 5.4036e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2019 - val_loss: 0.2733 - lr: 5.1334e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1908\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1908 - val_loss: 0.2849 - lr: 5.1334e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2014\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2014 - val_loss: 0.2734 - lr: 4.8767e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1890\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1890 - val_loss: 0.2779 - lr: 4.6329e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2002\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2002 - val_loss: 0.2902 - lr: 4.4013e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2035\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2035 - val_loss: 0.2959 - lr: 4.1812e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1815\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1815 - val_loss: 0.2856 - lr: 3.9721e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1804\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1804 - val_loss: 0.2735 - lr: 3.7735e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.1774 - val_loss: 0.2682 - lr: 3.5849e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1700 - val_loss: 0.2573 - lr: 3.5849e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.1892 - val_loss: 0.2497 - lr: 3.5849e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1731\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 8s 421ms/step - loss: 0.1731 - val_loss: 0.2519 - lr: 3.5849e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1799\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1799 - val_loss: 0.2500 - lr: 3.4056e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1532\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1532 - val_loss: 0.2581 - lr: 3.2353e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1672\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1672 - val_loss: 0.2617 - lr: 3.0736e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1706\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1706 - val_loss: 0.2574 - lr: 2.9199e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1536\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1536 - val_loss: 0.2601 - lr: 2.7739e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1445\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1445 - val_loss: 0.2507 - lr: 2.6352e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1460 - val_loss: 0.2494 - lr: 2.5034e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1550\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1550 - val_loss: 0.2495 - lr: 2.5034e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1413 - val_loss: 0.2387 - lr: 2.3783e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.1616 - val_loss: 0.2340 - lr: 2.3783e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.1485 - val_loss: 0.2281 - lr: 2.3783e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.1408 - val_loss: 0.2212 - lr: 2.3783e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1363\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.1363 - val_loss: 0.2482 - lr: 2.3783e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1519\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1519 - val_loss: 0.2294 - lr: 2.2594e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1497\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1497 - val_loss: 0.2288 - lr: 2.1464e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1445\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1445 - val_loss: 0.2323 - lr: 2.0391e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1314\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1314 - val_loss: 0.2383 - lr: 1.9371e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1466\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1466 - val_loss: 0.2232 - lr: 1.8403e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1414\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1414 - val_loss: 0.2257 - lr: 1.7482e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.1338 - val_loss: 0.2173 - lr: 1.6608e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1200\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 413ms/step - loss: 0.1200 - val_loss: 0.2307 - lr: 1.6608e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1295\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1295 - val_loss: 0.2222 - lr: 1.5778e-04\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.1570 - val_loss: 0.2115 - lr: 1.4989e-04\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1376\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1376 - val_loss: 0.2313 - lr: 1.4989e-04\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1245\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1245 - val_loss: 0.2419 - lr: 1.4240e-04\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1246\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1246 - val_loss: 0.2259 - lr: 1.3528e-04\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1356\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1356 - val_loss: 0.2228 - lr: 1.2851e-04\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1276\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.1276 - val_loss: 0.2298 - lr: 1.2209e-04\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1337\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.1337 - val_loss: 0.2316 - lr: 1.1598e-04\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1267\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1267 - val_loss: 0.2346 - lr: 1.1018e-04\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1286\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1286 - val_loss: 0.2334 - lr: 1.0467e-04\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1440\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1440 - val_loss: 0.2212 - lr: 9.9440e-05\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1387\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1387 - val_loss: 0.2249 - lr: 9.4468e-05\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1219\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1219 - val_loss: 0.2235 - lr: 8.9745e-05\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1254\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1254 - val_loss: 0.2138 - lr: 8.5258e-05\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1292\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1292 - val_loss: 0.2300 - lr: 8.0995e-05\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1169\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1169 - val_loss: 0.2309 - lr: 7.6945e-05\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1326\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1326 - val_loss: 0.2296 - lr: 7.3098e-05\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1198\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1198 - val_loss: 0.2347 - lr: 6.9443e-05\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1304\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1304 - val_loss: 0.2310 - lr: 6.5971e-05\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1254\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1254 - val_loss: 0.2415 - lr: 6.2672e-05\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1200\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 5.656161210936261e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1200 - val_loss: 0.2336 - lr: 5.9539e-05\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1272\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 5.373353305913042e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1272 - val_loss: 0.2478 - lr: 5.6562e-05\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1094\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 5.104685606056591e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1094 - val_loss: 0.2462 - lr: 5.3734e-05\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1226\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 4.849451343034161e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1226 - val_loss: 0.2341 - lr: 5.1047e-05\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1216 - val_loss: 0.1995 - lr: 4.8495e-05\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1225\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 4.606978654919658e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1225 - val_loss: 0.2248 - lr: 4.8495e-05\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1199\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 4.3766295493696814e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1199 - val_loss: 0.2491 - lr: 4.6070e-05\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1147\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 4.1577981755835934e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1147 - val_loss: 0.2531 - lr: 4.3766e-05\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1316\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 3.949908405047608e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1316 - val_loss: 0.2548 - lr: 4.1578e-05\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1261\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 3.752413140318822e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1261 - val_loss: 0.2549 - lr: 3.9499e-05\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1229\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 3.564792586985277e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1229 - val_loss: 0.2542 - lr: 3.7524e-05\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1266\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 3.3865528712340166e-05.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1266 - val_loss: 0.2515 - lr: 3.5648e-05\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1218\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 3.217225348635111e-05.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1218 - val_loss: 0.2477 - lr: 3.3866e-05\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1232\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 3.0563641848857516e-05.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1232 - val_loss: 0.2471 - lr: 3.2172e-05\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1056\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 2.9035460102022626e-05.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1056 - val_loss: 0.2477 - lr: 3.0564e-05\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1315\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 2.7583687096921494e-05.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1315 - val_loss: 0.2413 - lr: 2.9035e-05\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1177\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 2.620450213726144e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1177 - val_loss: 0.2403 - lr: 2.7584e-05\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1176\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 2.4894276339182395e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1176 - val_loss: 0.2326 - lr: 2.6205e-05\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1194\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 2.3649562263017287e-05.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1194 - val_loss: 0.2400 - lr: 2.4894e-05\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1115\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 2.2467083545052444e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1115 - val_loss: 0.2444 - lr: 2.3650e-05\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1152\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 2.134372971340781e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1152 - val_loss: 0.2423 - lr: 2.2467e-05\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1071\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 2.0276544091757387e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1071 - val_loss: 0.2526 - lr: 2.1344e-05\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1247\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 1.9262716887169517e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1247 - val_loss: 0.2443 - lr: 2.0277e-05\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1279\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 1.8299581734027014e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1279 - val_loss: 0.2473 - lr: 1.9263e-05\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1260\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 1.7384601869707693e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1260 - val_loss: 0.2442 - lr: 1.8300e-05\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1170\n",
      "Epoch 107: ReduceLROnPlateau reducing learning rate to 1.6515371862624305e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1170 - val_loss: 0.2567 - lr: 1.7385e-05\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1195\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 1.568960378790507e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1195 - val_loss: 0.2631 - lr: 1.6515e-05\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1321\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 1.490512377131381e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1321 - val_loss: 0.2592 - lr: 1.5690e-05\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1245\n",
      "Epoch 110: ReduceLROnPlateau reducing learning rate to 1.4159867669150115e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1245 - val_loss: 0.2551 - lr: 1.4905e-05\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1220\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 1.3451874156089615e-05.\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.1220 - val_loss: 0.2510 - lr: 1.4160e-05\n",
      "Epoch 111: early stopping\n",
      "2/2 [==============================] - 6s 132ms/step\n",
      "0.1216, 0.1995, 0.4787\n",
      "______fold 8______, ________repeat 2__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 869ms/step - loss: 0.5320 - val_loss: 0.4449 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.4627 - val_loss: 0.4361 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.4568 - val_loss: 0.4227 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.4440 - val_loss: 0.4160 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4235 - val_loss: 0.3940 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.4051 - val_loss: 0.3696 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.3737 - val_loss: 0.3388 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.3343 - val_loss: 0.3347 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.3186 - val_loss: 0.2891 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3036\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.3036 - val_loss: 0.2993 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2791\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2791 - val_loss: 0.3333 - lr: 9.5000e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2795 - val_loss: 0.2813 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.2560 - val_loss: 0.2591 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2629\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2629 - val_loss: 0.2716 - lr: 9.0250e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2291\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2291 - val_loss: 0.3119 - lr: 8.5737e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2469\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2469 - val_loss: 0.2765 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2349\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2349 - val_loss: 0.3100 - lr: 7.7378e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2127\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2127 - val_loss: 0.3026 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2064\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2064 - val_loss: 0.2922 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2312\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2312 - val_loss: 0.3153 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2157\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2157 - val_loss: 0.2739 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2009\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2009 - val_loss: 0.3018 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1929\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1929 - val_loss: 0.3010 - lr: 5.6880e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1957\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1957 - val_loss: 0.2912 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1862\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1862 - val_loss: 0.2737 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1868\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1868 - val_loss: 0.2806 - lr: 4.8767e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1720\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1720 - val_loss: 0.2747 - lr: 4.6329e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1917\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1917 - val_loss: 0.2837 - lr: 4.4013e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1825\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1825 - val_loss: 0.2725 - lr: 4.1812e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1790\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1790 - val_loss: 0.2769 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1826\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1826 - val_loss: 0.2933 - lr: 3.7735e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1865\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1865 - val_loss: 0.3029 - lr: 3.5849e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1773\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1773 - val_loss: 0.3102 - lr: 3.4056e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1749\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1749 - val_loss: 0.3009 - lr: 3.2353e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1827\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1827 - val_loss: 0.3086 - lr: 3.0736e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1686\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1686 - val_loss: 0.3016 - lr: 2.9199e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1714\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1714 - val_loss: 0.3049 - lr: 2.7739e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1643\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "18/18 [==============================] - 7s 414ms/step - loss: 0.1643 - val_loss: 0.2977 - lr: 2.6352e-04\n",
      "Epoch 38: early stopping\n",
      "2/2 [==============================] - 6s 123ms/step\n",
      "0.2560, 0.2591, 0.5461\n",
      "______fold 8______, ________repeat 3__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 829ms/step - loss: 0.5054 - val_loss: 0.4452 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.4634 - val_loss: 0.4421 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.4606 - val_loss: 0.4354 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.4538 - val_loss: 0.4144 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.4393 - val_loss: 0.3933 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.4305 - val_loss: 0.3833 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.4187 - val_loss: 0.3812 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.3846 - val_loss: 0.3257 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.3497 - val_loss: 0.2918 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.3220 - val_loss: 0.2775 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3024\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.3024 - val_loss: 0.3049 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3307\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.3307 - val_loss: 0.3041 - lr: 9.5000e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2791\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2791 - val_loss: 0.2858 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2538\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2538 - val_loss: 0.2930 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2446\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2446 - val_loss: 0.3020 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2551\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2551 - val_loss: 0.2819 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2349\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2349 - val_loss: 0.3099 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2253 - val_loss: 0.2664 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2023 - val_loss: 0.2621 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2118 - val_loss: 0.2594 - lr: 6.9834e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.1992 - val_loss: 0.2220 - lr: 6.9834e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2010\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 8s 418ms/step - loss: 0.2010 - val_loss: 0.2733 - lr: 6.9834e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2152\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2152 - val_loss: 0.2403 - lr: 6.6342e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2011 - val_loss: 0.2053 - lr: 6.3025e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1920\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1920 - val_loss: 0.2330 - lr: 6.3025e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2074\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2074 - val_loss: 0.2421 - lr: 5.9874e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1861\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1861 - val_loss: 0.2713 - lr: 5.6880e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1963\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1963 - val_loss: 0.2281 - lr: 5.4036e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1834\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1834 - val_loss: 0.2324 - lr: 5.1334e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1945\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1945 - val_loss: 0.2606 - lr: 4.8767e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1726\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1726 - val_loss: 0.2442 - lr: 4.6329e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1798\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1798 - val_loss: 0.2356 - lr: 4.4013e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1686\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1686 - val_loss: 0.2545 - lr: 4.1812e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1632\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1632 - val_loss: 0.2519 - lr: 3.9721e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1779\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1779 - val_loss: 0.2497 - lr: 3.7735e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1505\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1505 - val_loss: 0.2404 - lr: 3.5849e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1664\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.1664 - val_loss: 0.2671 - lr: 3.4056e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1718\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1718 - val_loss: 0.2460 - lr: 3.2353e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1550\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1550 - val_loss: 0.2514 - lr: 3.0736e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1591\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1591 - val_loss: 0.2289 - lr: 2.9199e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1677\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1677 - val_loss: 0.2309 - lr: 2.7739e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1504\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1504 - val_loss: 0.2720 - lr: 2.6352e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1510\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1510 - val_loss: 0.2539 - lr: 2.5034e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1546\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1546 - val_loss: 0.2476 - lr: 2.3783e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1540\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1540 - val_loss: 0.2363 - lr: 2.2594e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1429\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1429 - val_loss: 0.2515 - lr: 2.1464e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1562\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.1562 - val_loss: 0.2589 - lr: 2.0391e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1563\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1563 - val_loss: 0.2605 - lr: 1.9371e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1474\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "18/18 [==============================] - 7s 412ms/step - loss: 0.1474 - val_loss: 0.2492 - lr: 1.8403e-04\n",
      "Epoch 49: early stopping\n",
      "2/2 [==============================] - 7s 109ms/step\n",
      "0.2011, 0.2053, 0.5110\n",
      "______fold 8______, ________repeat 4__________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 828ms/step - loss: 0.4908 - val_loss: 0.4460 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.4646 - val_loss: 0.4450 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.4644 - val_loss: 0.4426 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4603 - val_loss: 0.4359 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.4539 - val_loss: 0.4255 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.4330 - val_loss: 0.4064 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.4156 - val_loss: 0.3955 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.3805 - val_loss: 0.3708 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3627\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.3627 - val_loss: 0.3825 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3677 - val_loss: 0.3521 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.3405 - val_loss: 0.3304 - lr: 9.5000e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3118\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.3118 - val_loss: 0.3502 - lr: 9.5000e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.2944 - val_loss: 0.2905 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2650 - val_loss: 0.2679 - lr: 9.0250e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2370\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2370 - val_loss: 0.3241 - lr: 9.0250e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2253\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2253 - val_loss: 0.2696 - lr: 8.5737e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2134\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2134 - val_loss: 0.3614 - lr: 8.1451e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2302\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2302 - val_loss: 0.3017 - lr: 7.7378e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2034 - val_loss: 0.2658 - lr: 7.3509e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2161\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2161 - val_loss: 0.3479 - lr: 7.3509e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2072\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2072 - val_loss: 0.3273 - lr: 6.9834e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1835\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1835 - val_loss: 0.3290 - lr: 6.6342e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2029\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2029 - val_loss: 0.3507 - lr: 6.3025e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1678\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1678 - val_loss: 0.3386 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1785\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1785 - val_loss: 0.3353 - lr: 5.6880e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1727\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1727 - val_loss: 0.2956 - lr: 5.4036e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1779\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1779 - val_loss: 0.3482 - lr: 5.1334e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1602\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1602 - val_loss: 0.3184 - lr: 4.8767e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1772\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1772 - val_loss: 0.3289 - lr: 4.6329e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1691\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1691 - val_loss: 0.3566 - lr: 4.4013e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1446\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1446 - val_loss: 0.3304 - lr: 4.1812e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1750\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1750 - val_loss: 0.3064 - lr: 3.9721e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1595\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1595 - val_loss: 0.3827 - lr: 3.7735e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1620\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1620 - val_loss: 0.3297 - lr: 3.5849e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1585\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1585 - val_loss: 0.3560 - lr: 3.4056e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1453\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1453 - val_loss: 0.3594 - lr: 3.2353e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1503\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1503 - val_loss: 0.3535 - lr: 3.0736e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1602\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1602 - val_loss: 0.3723 - lr: 2.9199e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1478\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 8s 418ms/step - loss: 0.1478 - val_loss: 0.3608 - lr: 2.7739e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1486\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1486 - val_loss: 0.3397 - lr: 2.6352e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1446\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1446 - val_loss: 0.3737 - lr: 2.5034e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1608\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1608 - val_loss: 0.3627 - lr: 2.3783e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1442\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1442 - val_loss: 0.3743 - lr: 2.2594e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1410\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1410 - val_loss: 0.3587 - lr: 2.1464e-04\n",
      "Epoch 44: early stopping\n",
      "2/2 [==============================] - 8s 127ms/step\n",
      "0.2034, 0.2658, 0.5644\n",
      "______fold 8______, ________repeat 5__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 809ms/step - loss: 0.5112 - val_loss: 0.4424 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 443ms/step - loss: 0.4650 - val_loss: 0.4351 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.4567 - val_loss: 0.4138 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.4444 - val_loss: 0.4007 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.4293 - val_loss: 0.3916 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.3861 - val_loss: 0.3503 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.3649 - val_loss: 0.3365 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.3295 - val_loss: 0.3342 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2959\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2959 - val_loss: 0.3366 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2934\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2934 - val_loss: 0.3376 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2747\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2747 - val_loss: 0.3842 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2873 - val_loss: 0.3337 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.2542 - val_loss: 0.3328 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.2695 - val_loss: 0.3133 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2281\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2281 - val_loss: 0.3302 - lr: 8.5737e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2239\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2239 - val_loss: 0.3139 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2370\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2370 - val_loss: 0.3450 - lr: 7.7378e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2137\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2137 - val_loss: 0.3170 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2237 - val_loss: 0.3121 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2024\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2024 - val_loss: 0.3330 - lr: 6.9834e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1870\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1870 - val_loss: 0.3374 - lr: 6.6342e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1808\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1808 - val_loss: 0.3431 - lr: 6.3025e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1872\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1872 - val_loss: 0.3481 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1845\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1845 - val_loss: 0.3554 - lr: 5.6880e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1950\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1950 - val_loss: 0.3124 - lr: 5.4036e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1810\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1810 - val_loss: 0.3512 - lr: 5.1334e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1774\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1774 - val_loss: 0.3296 - lr: 4.8767e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.1891 - val_loss: 0.3044 - lr: 4.6329e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1646\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1646 - val_loss: 0.3487 - lr: 4.6329e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1661\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1661 - val_loss: 0.3266 - lr: 4.4013e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1736\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1736 - val_loss: 0.3130 - lr: 4.1812e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1739 - val_loss: 0.3031 - lr: 3.9721e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1562\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1562 - val_loss: 0.3593 - lr: 3.9721e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1579\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1579 - val_loss: 0.3223 - lr: 3.7735e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1537\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1537 - val_loss: 0.3278 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1548\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1548 - val_loss: 0.3409 - lr: 3.4056e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1519\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1519 - val_loss: 0.3348 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1505\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1505 - val_loss: 0.3314 - lr: 3.0736e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1384\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1384 - val_loss: 0.3278 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1426\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1426 - val_loss: 0.3573 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1359\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1359 - val_loss: 0.3666 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1481\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1481 - val_loss: 0.3448 - lr: 2.5034e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1510\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1510 - val_loss: 0.3416 - lr: 2.3783e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1352\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1352 - val_loss: 0.3366 - lr: 2.2594e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1260\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1260 - val_loss: 0.3550 - lr: 2.1464e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1358\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1358 - val_loss: 0.3564 - lr: 2.0391e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1433\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1433 - val_loss: 0.3426 - lr: 1.9371e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1512\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1512 - val_loss: 0.3410 - lr: 1.8403e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1251\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1251 - val_loss: 0.3401 - lr: 1.7482e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1242\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1242 - val_loss: 0.3397 - lr: 1.6608e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1330\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1330 - val_loss: 0.3417 - lr: 1.5778e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1304\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1304 - val_loss: 0.3466 - lr: 1.4989e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1453\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1453 - val_loss: 0.3543 - lr: 1.4240e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1371\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1371 - val_loss: 0.3369 - lr: 1.3528e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1335\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1335 - val_loss: 0.3415 - lr: 1.2851e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1291\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1291 - val_loss: 0.3388 - lr: 1.2209e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1240\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.1240 - val_loss: 0.3401 - lr: 1.1598e-04\n",
      "Epoch 57: early stopping\n",
      "2/2 [==============================] - 6s 134ms/step\n",
      "0.1739, 0.3031, 0.7112\n",
      "______fold 8______, ________repeat 6__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 876ms/step - loss: 0.4887 - val_loss: 0.4281 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4606\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.4606 - val_loss: 0.4407 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.4508 - val_loss: 0.4101 - lr: 9.5000e-04\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.4370 - val_loss: 0.3822 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4161 - val_loss: 0.3518 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 430ms/step - loss: 0.3730 - val_loss: 0.3387 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.3385 - val_loss: 0.3364 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.3392 - val_loss: 0.3160 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2797\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.2797 - val_loss: 0.3263 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.2641 - val_loss: 0.3148 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2567\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2567 - val_loss: 0.3542 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2691\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2691 - val_loss: 0.3643 - lr: 8.5737e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2495\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2495 - val_loss: 0.3213 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.2289 - val_loss: 0.3108 - lr: 7.7378e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2314\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 413ms/step - loss: 0.2314 - val_loss: 0.3525 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2149 - val_loss: 0.2999 - lr: 7.3509e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.2229 - val_loss: 0.2818 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2034\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2034 - val_loss: 0.3317 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2026\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2026 - val_loss: 0.3075 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2173\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2173 - val_loss: 0.3205 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.2121 - val_loss: 0.2805 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1961\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1961 - val_loss: 0.3442 - lr: 6.3025e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2226\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2226 - val_loss: 0.2974 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1966\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1966 - val_loss: 0.2941 - lr: 5.6880e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1902\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1902 - val_loss: 0.3152 - lr: 5.4036e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1897\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1897 - val_loss: 0.3356 - lr: 5.1334e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1875\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1875 - val_loss: 0.3467 - lr: 4.8767e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1832\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1832 - val_loss: 0.3416 - lr: 4.6329e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1926\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1926 - val_loss: 0.3238 - lr: 4.4013e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1901\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1901 - val_loss: 0.3299 - lr: 4.1812e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1928\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1928 - val_loss: 0.2839 - lr: 3.9721e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1919\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1919 - val_loss: 0.3037 - lr: 3.7735e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1730\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1730 - val_loss: 0.3323 - lr: 3.5849e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1787\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1787 - val_loss: 0.2954 - lr: 3.4056e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1775\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1775 - val_loss: 0.3105 - lr: 3.2353e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1720 - val_loss: 0.2730 - lr: 3.0736e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1652\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1652 - val_loss: 0.3153 - lr: 3.0736e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1707\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1707 - val_loss: 0.3274 - lr: 2.9199e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1770\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1770 - val_loss: 0.3233 - lr: 2.7739e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1609\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1609 - val_loss: 0.3000 - lr: 2.6352e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1632\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1632 - val_loss: 0.3023 - lr: 2.5034e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1612\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1612 - val_loss: 0.2969 - lr: 2.3783e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1742\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1742 - val_loss: 0.3047 - lr: 2.2594e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1653\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1653 - val_loss: 0.2960 - lr: 2.1464e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1538\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1538 - val_loss: 0.3181 - lr: 2.0391e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1521\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1521 - val_loss: 0.2926 - lr: 1.9371e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1643\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1643 - val_loss: 0.3070 - lr: 1.8403e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1422\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1422 - val_loss: 0.3226 - lr: 1.7482e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1587\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1587 - val_loss: 0.3196 - lr: 1.6608e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1475\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1475 - val_loss: 0.3062 - lr: 1.5778e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1462\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1462 - val_loss: 0.3072 - lr: 1.4989e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1597\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1597 - val_loss: 0.3150 - lr: 1.4240e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1559\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1559 - val_loss: 0.2985 - lr: 1.3528e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1474\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1474 - val_loss: 0.2993 - lr: 1.2851e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1418\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1418 - val_loss: 0.3051 - lr: 1.2209e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1527\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1527 - val_loss: 0.3117 - lr: 1.1598e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1469\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1469 - val_loss: 0.3244 - lr: 1.1018e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1420\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1420 - val_loss: 0.3295 - lr: 1.0467e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1484\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1484 - val_loss: 0.3283 - lr: 9.9440e-05\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1514\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1514 - val_loss: 0.3230 - lr: 9.4468e-05\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1465\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1465 - val_loss: 0.3151 - lr: 8.9745e-05\n",
      "Epoch 61: early stopping\n",
      "2/2 [==============================] - 6s 127ms/step\n",
      "0.1720, 0.2730, 0.5877\n",
      "______fold 8______, ________repeat 7__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 823ms/step - loss: 0.5398 - val_loss: 0.4540 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.4650 - val_loss: 0.4369 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.4553 - val_loss: 0.4270 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.4441 - val_loss: 0.4123 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.4263 - val_loss: 0.3818 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.4061 - val_loss: 0.3716 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.3925 - val_loss: 0.3675 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.3600 - val_loss: 0.3075 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.3094 - val_loss: 0.2936 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.3295 - val_loss: 0.2899 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3247\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3247 - val_loss: 0.2942 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2989 - val_loss: 0.2818 - lr: 9.5000e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2815\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2815 - val_loss: 0.3055 - lr: 9.5000e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2647\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2647 - val_loss: 0.3165 - lr: 9.0250e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2738\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2738 - val_loss: 0.3192 - lr: 8.5737e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2678\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2678 - val_loss: 0.2876 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2490\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2490 - val_loss: 0.2900 - lr: 7.7378e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2417 - val_loss: 0.2803 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2442 - val_loss: 0.2680 - lr: 7.3509e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2528\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2528 - val_loss: 0.3070 - lr: 7.3509e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2367\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2367 - val_loss: 0.3078 - lr: 6.9834e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2430\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2430 - val_loss: 0.2923 - lr: 6.6342e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2215\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2215 - val_loss: 0.2979 - lr: 6.3025e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2125\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2125 - val_loss: 0.2727 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2294\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2294 - val_loss: 0.2715 - lr: 5.6880e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2232\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2232 - val_loss: 0.2777 - lr: 5.4036e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2068\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2068 - val_loss: 0.2815 - lr: 5.1334e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2122 - val_loss: 0.2544 - lr: 4.8767e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2037\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2037 - val_loss: 0.2681 - lr: 4.8767e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1972\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1972 - val_loss: 0.2745 - lr: 4.6329e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1851 - val_loss: 0.2427 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1974\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1974 - val_loss: 0.2563 - lr: 4.4013e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1752\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1752 - val_loss: 0.2929 - lr: 4.1812e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1872\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1872 - val_loss: 0.2885 - lr: 3.9721e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1885\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1885 - val_loss: 0.2562 - lr: 3.7735e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1854\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1854 - val_loss: 0.2608 - lr: 3.5849e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1778\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1778 - val_loss: 0.2820 - lr: 3.4056e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1766\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1766 - val_loss: 0.2968 - lr: 3.2353e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1629\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1629 - val_loss: 0.2857 - lr: 3.0736e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1638\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1638 - val_loss: 0.3063 - lr: 2.9199e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1724\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1724 - val_loss: 0.2769 - lr: 2.7739e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1824\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1824 - val_loss: 0.2696 - lr: 2.6352e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1726\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1726 - val_loss: 0.2913 - lr: 2.5034e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1567\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1567 - val_loss: 0.2951 - lr: 2.3783e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1579\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1579 - val_loss: 0.2918 - lr: 2.2594e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1609\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1609 - val_loss: 0.2990 - lr: 2.1464e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1595\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1595 - val_loss: 0.2938 - lr: 2.0391e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1594\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1594 - val_loss: 0.2940 - lr: 1.9371e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1550\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1550 - val_loss: 0.2752 - lr: 1.8403e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1518\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1518 - val_loss: 0.2848 - lr: 1.7482e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1621\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1621 - val_loss: 0.2887 - lr: 1.6608e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1528\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1528 - val_loss: 0.2915 - lr: 1.5778e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1460\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1460 - val_loss: 0.2809 - lr: 1.4989e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1536\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1536 - val_loss: 0.2764 - lr: 1.4240e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1551\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1551 - val_loss: 0.2817 - lr: 1.3528e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1451\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 31.\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1451 - val_loss: 0.2781 - lr: 1.2851e-04\n",
      "Epoch 56: early stopping\n",
      "2/2 [==============================] - 6s 129ms/step\n",
      "0.1851, 0.2427, 0.6047\n",
      "______fold 8______, ________repeat 8__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 825ms/step - loss: 0.4861 - val_loss: 0.4414 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.4618 - val_loss: 0.4323 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.4524 - val_loss: 0.4217 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 8s 426ms/step - loss: 0.4401 - val_loss: 0.3932 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4312\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.4312 - val_loss: 0.4023 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3987\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.3987 - val_loss: 0.4059 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.3910 - val_loss: 0.3637 - lr: 9.0250e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3604 - val_loss: 0.3576 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.3431 - val_loss: 0.3334 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3385\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.3385 - val_loss: 0.3348 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3820\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.3820 - val_loss: 0.3387 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3470\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.3470 - val_loss: 0.3344 - lr: 8.1451e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2858 - val_loss: 0.2981 - lr: 7.7378e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2956\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2956 - val_loss: 0.3207 - lr: 7.7378e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2671\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2671 - val_loss: 0.3062 - lr: 7.3509e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2343 - val_loss: 0.2952 - lr: 6.9834e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2331\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2331 - val_loss: 0.3388 - lr: 6.9834e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2260\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2260 - val_loss: 0.3376 - lr: 6.6342e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2324\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2324 - val_loss: 0.3319 - lr: 6.3025e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2233\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2233 - val_loss: 0.3098 - lr: 5.9874e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2252\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2252 - val_loss: 0.3151 - lr: 5.6880e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2183\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2183 - val_loss: 0.3152 - lr: 5.4036e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.2019 - val_loss: 0.2940 - lr: 5.1334e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1881\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.1881 - val_loss: 0.3272 - lr: 5.1334e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.1931 - val_loss: 0.2857 - lr: 4.8767e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2072\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2072 - val_loss: 0.3122 - lr: 4.8767e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2003\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2003 - val_loss: 0.2884 - lr: 4.6329e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1884\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1884 - val_loss: 0.2869 - lr: 4.4013e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1881\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1881 - val_loss: 0.3063 - lr: 4.1812e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1768\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1768 - val_loss: 0.2939 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1611\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1611 - val_loss: 0.2869 - lr: 3.7735e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1959\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1959 - val_loss: 0.3029 - lr: 3.5849e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1992\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1992 - val_loss: 0.3239 - lr: 3.4056e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1711\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1711 - val_loss: 0.3051 - lr: 3.2353e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1810\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.1810 - val_loss: 0.2914 - lr: 3.0736e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1818\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1818 - val_loss: 0.3108 - lr: 2.9199e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1728\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1728 - val_loss: 0.2962 - lr: 2.7739e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1552\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1552 - val_loss: 0.3062 - lr: 2.6352e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1800\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1800 - val_loss: 0.3028 - lr: 2.5034e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1674\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1674 - val_loss: 0.3109 - lr: 2.3783e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1631\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1631 - val_loss: 0.3064 - lr: 2.2594e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1623\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1623 - val_loss: 0.3062 - lr: 2.1464e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1529\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1529 - val_loss: 0.3141 - lr: 2.0391e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1546\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1546 - val_loss: 0.3300 - lr: 1.9371e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1459\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1459 - val_loss: 0.3170 - lr: 1.8403e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1638\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1638 - val_loss: 0.3069 - lr: 1.7482e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1606\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1606 - val_loss: 0.3120 - lr: 1.6608e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1687\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1687 - val_loss: 0.3250 - lr: 1.5778e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1524\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1524 - val_loss: 0.3211 - lr: 1.4989e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1690\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.1690 - val_loss: 0.3128 - lr: 1.4240e-04\n",
      "Epoch 50: early stopping\n",
      "2/2 [==============================] - 6s 134ms/step\n",
      "0.1931, 0.2857, 0.6859\n",
      "______fold 8______, ________repeat 9__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 868ms/step - loss: 0.4892 - val_loss: 0.4416 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 442ms/step - loss: 0.4569 - val_loss: 0.4254 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.4463 - val_loss: 0.4073 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.4394 - val_loss: 0.3973 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.4257 - val_loss: 0.3835 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3819\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.3819 - val_loss: 0.4032 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3682\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3682 - val_loss: 0.4247 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.3348 - val_loss: 0.3150 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.3140 - val_loss: 0.2878 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3127\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 8s 421ms/step - loss: 0.3127 - val_loss: 0.2910 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2988\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2988 - val_loss: 0.2921 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2843\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2843 - val_loss: 0.3046 - lr: 8.1451e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2434 - val_loss: 0.2657 - lr: 7.7378e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2391\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2391 - val_loss: 0.3322 - lr: 7.7378e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2147\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2147 - val_loss: 0.3278 - lr: 7.3509e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2364 - val_loss: 0.2458 - lr: 6.9834e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2250\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2250 - val_loss: 0.2744 - lr: 6.9834e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1942\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1942 - val_loss: 0.2709 - lr: 6.6342e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1804\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1804 - val_loss: 0.3641 - lr: 6.3025e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2139\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2139 - val_loss: 0.2784 - lr: 5.9874e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1854\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1854 - val_loss: 0.2597 - lr: 5.6880e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1876\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1876 - val_loss: 0.2811 - lr: 5.4036e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1736\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1736 - val_loss: 0.2723 - lr: 5.1334e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1809\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1809 - val_loss: 0.2871 - lr: 4.8767e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1644\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1644 - val_loss: 0.2849 - lr: 4.6329e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1611\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1611 - val_loss: 0.2633 - lr: 4.4013e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1686\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1686 - val_loss: 0.2854 - lr: 4.1812e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1631\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1631 - val_loss: 0.2783 - lr: 3.9721e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1499\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1499 - val_loss: 0.2880 - lr: 3.7735e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1691\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1691 - val_loss: 0.2879 - lr: 3.5849e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1598\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1598 - val_loss: 0.2883 - lr: 3.4056e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1652\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1652 - val_loss: 0.2754 - lr: 3.2353e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1470\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1470 - val_loss: 0.2970 - lr: 3.0736e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1446\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1446 - val_loss: 0.2862 - lr: 2.9199e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1524\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1524 - val_loss: 0.2572 - lr: 2.7739e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1374\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1374 - val_loss: 0.2895 - lr: 2.6352e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1531\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1531 - val_loss: 0.2842 - lr: 2.5034e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1375\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1375 - val_loss: 0.2939 - lr: 2.3783e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1561\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1561 - val_loss: 0.2794 - lr: 2.2594e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1354\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1354 - val_loss: 0.2979 - lr: 2.1464e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1503\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.1503 - val_loss: 0.2861 - lr: 2.0391e-04\n",
      "Epoch 41: early stopping\n",
      "2/2 [==============================] - 7s 128ms/step\n",
      "0.2364, 0.2458, 0.5457\n",
      "______fold 8______, ________repeat 10__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 831ms/step - loss: 0.4980 - val_loss: 0.4501 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.4543 - val_loss: 0.4130 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.4347 - val_loss: 0.3696 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4240\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.4240 - val_loss: 0.3761 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.3830 - val_loss: 0.3388 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3665 - val_loss: 0.3192 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.3483 - val_loss: 0.3178 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3035\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3035 - val_loss: 0.3428 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.3289 - val_loss: 0.3090 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.3235 - val_loss: 0.2919 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2795\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2795 - val_loss: 0.3239 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3711\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.3711 - val_loss: 0.3102 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3115\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.3115 - val_loss: 0.3123 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2855 - val_loss: 0.2835 - lr: 7.7378e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2649 - val_loss: 0.2833 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2535\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2535 - val_loss: 0.3029 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2334\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2334 - val_loss: 0.3363 - lr: 7.3509e-04\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.2375\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2375 - val_loss: 0.3066 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2083\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2083 - val_loss: 0.3348 - lr: 6.6342e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2175\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2175 - val_loss: 0.3267 - lr: 6.3025e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1990 - val_loss: 0.2822 - lr: 5.9874e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1989\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.1989 - val_loss: 0.2945 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1885\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1885 - val_loss: 0.3208 - lr: 5.6880e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2005\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2005 - val_loss: 0.2883 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1912\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1912 - val_loss: 0.3142 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1949\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1949 - val_loss: 0.3575 - lr: 4.8767e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1842\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1842 - val_loss: 0.3312 - lr: 4.6329e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1958\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1958 - val_loss: 0.3162 - lr: 4.4013e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1910\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1910 - val_loss: 0.2952 - lr: 4.1812e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1848 - val_loss: 0.2767 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1733 - val_loss: 0.2765 - lr: 3.9721e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1858 - val_loss: 0.2655 - lr: 3.9721e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1709\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1709 - val_loss: 0.3130 - lr: 3.9721e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1698\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1698 - val_loss: 0.3049 - lr: 3.7735e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1590\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1590 - val_loss: 0.3149 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1661\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1661 - val_loss: 0.3084 - lr: 3.4056e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1714\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1714 - val_loss: 0.3240 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1684\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1684 - val_loss: 0.3089 - lr: 3.0736e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1545\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1545 - val_loss: 0.2766 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1589\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1589 - val_loss: 0.3079 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1599\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1599 - val_loss: 0.2878 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1537\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1537 - val_loss: 0.2896 - lr: 2.5034e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1642\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1642 - val_loss: 0.2953 - lr: 2.3783e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1621\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1621 - val_loss: 0.2896 - lr: 2.2594e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1464\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1464 - val_loss: 0.3178 - lr: 2.1464e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1539\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1539 - val_loss: 0.3096 - lr: 2.0391e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1423\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1423 - val_loss: 0.3275 - lr: 1.9371e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1527\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1527 - val_loss: 0.3032 - lr: 1.8403e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1557\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1557 - val_loss: 0.3161 - lr: 1.7482e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1468\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1468 - val_loss: 0.3076 - lr: 1.6608e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1382\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1382 - val_loss: 0.3308 - lr: 1.5778e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1371\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1371 - val_loss: 0.3128 - lr: 1.4989e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1445\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1445 - val_loss: 0.3086 - lr: 1.4240e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1395\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1395 - val_loss: 0.3220 - lr: 1.3528e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1440\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1440 - val_loss: 0.3183 - lr: 1.2851e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1318\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1318 - val_loss: 0.3292 - lr: 1.2209e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1302\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "18/18 [==============================] - 7s 414ms/step - loss: 0.1302 - val_loss: 0.3156 - lr: 1.1598e-04\n",
      "Epoch 57: early stopping\n",
      "2/2 [==============================] - 6s 127ms/step\n",
      "0.1858, 0.2655, 0.6289\n",
      "______fold 9______, ________repeat 1__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 830ms/step - loss: 0.4829 - val_loss: 0.4459 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 415ms/step - loss: 0.4607 - val_loss: 0.4326 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.4500 - val_loss: 0.4209 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.4297 - val_loss: 0.4047 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.4055 - val_loss: 0.3773 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3732\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.3732 - val_loss: 0.3964 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.3591 - val_loss: 0.3319 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 8s 433ms/step - loss: 0.3248 - val_loss: 0.3279 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.2979 - val_loss: 0.3225 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.2929 - val_loss: 0.2972 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3117\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.3117 - val_loss: 0.3309 - lr: 9.5000e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2603\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2603 - val_loss: 0.3252 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.2570 - val_loss: 0.2358 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2325 - val_loss: 0.2201 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2364\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2364 - val_loss: 0.2639 - lr: 8.5737e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2359\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2359 - val_loss: 0.2242 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2187\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2187 - val_loss: 0.2794 - lr: 7.7378e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2162\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2162 - val_loss: 0.2411 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2119\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2119 - val_loss: 0.2327 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2272\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2272 - val_loss: 0.2402 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2001\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2001 - val_loss: 0.2399 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1940\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1940 - val_loss: 0.2365 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1944\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1944 - val_loss: 0.2599 - lr: 5.6880e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2010\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2010 - val_loss: 0.2397 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1953\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1953 - val_loss: 0.2665 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1947\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1947 - val_loss: 0.2570 - lr: 4.8767e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1882\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1882 - val_loss: 0.2359 - lr: 4.6329e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1986\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1986 - val_loss: 0.2346 - lr: 4.4013e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1975\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1975 - val_loss: 0.2576 - lr: 4.1812e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1725 - val_loss: 0.2069 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1771\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1771 - val_loss: 0.2263 - lr: 3.9721e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1867\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1867 - val_loss: 0.2546 - lr: 3.7735e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1768\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1768 - val_loss: 0.2128 - lr: 3.5849e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1858\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1858 - val_loss: 0.2431 - lr: 3.4056e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1722\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1722 - val_loss: 0.2123 - lr: 3.2353e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1765\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1765 - val_loss: 0.2188 - lr: 3.0736e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1629\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1629 - val_loss: 0.2121 - lr: 2.9199e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1811 - val_loss: 0.2039 - lr: 2.7739e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1648\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 418ms/step - loss: 0.1648 - val_loss: 0.2278 - lr: 2.7739e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1826\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1826 - val_loss: 0.2249 - lr: 2.6352e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1606\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1606 - val_loss: 0.2196 - lr: 2.5034e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1592\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1592 - val_loss: 0.2291 - lr: 2.3783e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1571\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1571 - val_loss: 0.2151 - lr: 2.2594e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1645\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1645 - val_loss: 0.2107 - lr: 2.1464e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1609\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1609 - val_loss: 0.2279 - lr: 2.0391e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1684\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1684 - val_loss: 0.2164 - lr: 1.9371e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1674\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1674 - val_loss: 0.2156 - lr: 1.8403e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1550\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1550 - val_loss: 0.2117 - lr: 1.7482e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1601\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1601 - val_loss: 0.2288 - lr: 1.6608e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1546\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1546 - val_loss: 0.2254 - lr: 1.5778e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1528\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1528 - val_loss: 0.2324 - lr: 1.4989e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1565\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1565 - val_loss: 0.2138 - lr: 1.4240e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1455\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1455 - val_loss: 0.2070 - lr: 1.3528e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1540\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1540 - val_loss: 0.2074 - lr: 1.2851e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1481\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1481 - val_loss: 0.2137 - lr: 1.2209e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1456\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1456 - val_loss: 0.2073 - lr: 1.1598e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1603\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1603 - val_loss: 0.2119 - lr: 1.1018e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1541\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1541 - val_loss: 0.2160 - lr: 1.0467e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1403\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1403 - val_loss: 0.2131 - lr: 9.9440e-05\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1370\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1370 - val_loss: 0.2078 - lr: 9.4468e-05\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1514\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1514 - val_loss: 0.2063 - lr: 8.9745e-05\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1477\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1477 - val_loss: 0.2053 - lr: 8.5258e-05\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1381 - val_loss: 0.2012 - lr: 8.0995e-05\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1322\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1322 - val_loss: 0.2015 - lr: 8.0995e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1308 - val_loss: 0.2000 - lr: 7.6945e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1307 - val_loss: 0.1992 - lr: 7.6945e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1450\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1450 - val_loss: 0.2015 - lr: 7.6945e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1386\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1386 - val_loss: 0.2040 - lr: 7.3098e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1447\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1447 - val_loss: 0.2120 - lr: 6.9443e-05\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1264\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1264 - val_loss: 0.2044 - lr: 6.5971e-05\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1352\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1352 - val_loss: 0.2034 - lr: 6.2672e-05\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1430\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 5.656161210936261e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1430 - val_loss: 0.2096 - lr: 5.9539e-05\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1438\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 5.373353305913042e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1438 - val_loss: 0.2043 - lr: 5.6562e-05\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1469\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 5.104685606056591e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1469 - val_loss: 0.2031 - lr: 5.3734e-05\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1333\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 4.849451343034161e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1333 - val_loss: 0.2012 - lr: 5.1047e-05\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1362\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 4.606978654919658e-05.\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.1362 - val_loss: 0.1992 - lr: 4.8495e-05\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1321\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 4.3766295493696814e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1321 - val_loss: 0.1999 - lr: 4.6070e-05\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1268\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 4.1577981755835934e-05.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1268 - val_loss: 0.2004 - lr: 4.3766e-05\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1427\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 3.949908405047608e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1427 - val_loss: 0.1998 - lr: 4.1578e-05\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1269\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 3.752413140318822e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1269 - val_loss: 0.2017 - lr: 3.9499e-05\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1350\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.564792586985277e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1350 - val_loss: 0.1998 - lr: 3.7524e-05\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1270 - val_loss: 0.1990 - lr: 3.5648e-05\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1338\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.3865528712340166e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1338 - val_loss: 0.1997 - lr: 3.5648e-05\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1377\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 3.217225348635111e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1377 - val_loss: 0.2004 - lr: 3.3866e-05\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1351\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 3.0563641848857516e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1351 - val_loss: 0.1996 - lr: 3.2172e-05\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1172\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 2.9035460102022626e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1172 - val_loss: 0.2016 - lr: 3.0564e-05\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1250\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 2.7583687096921494e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1250 - val_loss: 0.2021 - lr: 2.9035e-05\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1275\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 2.620450213726144e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1275 - val_loss: 0.2033 - lr: 2.7584e-05\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1348\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 2.4894276339182395e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1348 - val_loss: 0.2040 - lr: 2.6205e-05\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1244\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 2.3649562263017287e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1244 - val_loss: 0.2034 - lr: 2.4894e-05\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1400\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 2.2467083545052444e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1400 - val_loss: 0.2040 - lr: 2.3650e-05\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1376\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 2.134372971340781e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1376 - val_loss: 0.2044 - lr: 2.2467e-05\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1429\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 2.0276544091757387e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1429 - val_loss: 0.2043 - lr: 2.1344e-05\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1368\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.9262716887169517e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1368 - val_loss: 0.2036 - lr: 2.0277e-05\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1359\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 1.8299581734027014e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1359 - val_loss: 0.2045 - lr: 1.9263e-05\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1360\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 1.7384601869707693e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1360 - val_loss: 0.2040 - lr: 1.8300e-05\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1229\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 1.6515371862624305e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1229 - val_loss: 0.2039 - lr: 1.7385e-05\n",
      "Epoch 98/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.1314\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 1.568960378790507e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1314 - val_loss: 0.2037 - lr: 1.6515e-05\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1212\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 1.490512377131381e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1212 - val_loss: 0.2027 - lr: 1.5690e-05\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1250\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 1.4159867669150115e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1250 - val_loss: 0.2024 - lr: 1.4905e-05\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1414\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 1.3451874156089615e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1414 - val_loss: 0.2034 - lr: 1.4160e-05\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1440\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 1.2779280405084136e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1440 - val_loss: 0.2039 - lr: 1.3452e-05\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1226\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 1.2140316039221942e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1226 - val_loss: 0.2046 - lr: 1.2779e-05\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1359\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 1.1533300539667834e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1359 - val_loss: 0.2046 - lr: 1.2140e-05\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1396\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 1.0956635469483444e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1396 - val_loss: 0.2045 - lr: 1.1533e-05\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1156\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 1.0408803609607275e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1156 - val_loss: 0.2046 - lr: 1.0957e-05\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1370\n",
      "Epoch 107: ReduceLROnPlateau reducing learning rate to 9.888363774734898e-06.\n",
      "Restoring model weights from the end of the best epoch: 82.\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.1370 - val_loss: 0.2044 - lr: 1.0409e-05\n",
      "Epoch 107: early stopping\n",
      "2/2 [==============================] - 6s 129ms/step\n",
      "0.1270, 0.1990, 0.3891\n",
      "______fold 9______, ________repeat 2__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 868ms/step - loss: 0.4785 - val_loss: 0.4449 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.4637 - val_loss: 0.4344 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.4461 - val_loss: 0.4320 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4130\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.4130 - val_loss: 0.4531 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4012\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.4012 - val_loss: 0.4397 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.3862 - val_loss: 0.4066 - lr: 9.0250e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.3580 - val_loss: 0.3883 - lr: 9.0250e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.3336 - val_loss: 0.3815 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3445\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3445 - val_loss: 0.3972 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3188 - val_loss: 0.3498 - lr: 8.5737e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.3101 - val_loss: 0.3413 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2945 - val_loss: 0.3293 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.2784 - val_loss: 0.3176 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2490\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.2490 - val_loss: 0.3472 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2657\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 8s 418ms/step - loss: 0.2657 - val_loss: 0.3751 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2359 - val_loss: 0.2854 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2298\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2298 - val_loss: 0.3368 - lr: 7.7378e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2329 - val_loss: 0.2684 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2127\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.2127 - val_loss: 0.2684 - lr: 7.3509e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2308\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2308 - val_loss: 0.2711 - lr: 6.9834e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2349 - val_loss: 0.2515 - lr: 6.6342e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.2221 - val_loss: 0.2463 - lr: 6.6342e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.2251 - val_loss: 0.2367 - lr: 6.6342e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.2045 - val_loss: 0.2221 - lr: 6.6342e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2044\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.2044 - val_loss: 0.2411 - lr: 6.6342e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2054\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2054 - val_loss: 0.2540 - lr: 6.3025e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1985\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1985 - val_loss: 0.2360 - lr: 5.9874e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.1986 - val_loss: 0.2012 - lr: 5.6880e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2059\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.2059 - val_loss: 0.2428 - lr: 5.6880e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2004\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2004 - val_loss: 0.2109 - lr: 5.4036e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1863\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1863 - val_loss: 0.2078 - lr: 5.1334e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1799 - val_loss: 0.2010 - lr: 4.8767e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1750 - val_loss: 0.1696 - lr: 4.8767e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1868\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.1868 - val_loss: 0.1815 - lr: 4.8767e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1858 - val_loss: 0.1687 - lr: 4.6329e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1734\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.1734 - val_loss: 0.1925 - lr: 4.6329e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1795\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1795 - val_loss: 0.1811 - lr: 4.4013e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1719\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1719 - val_loss: 0.1765 - lr: 4.1812e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1677\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1677 - val_loss: 0.1928 - lr: 3.9721e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1719\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1719 - val_loss: 0.1918 - lr: 3.7735e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1632\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1632 - val_loss: 0.1716 - lr: 3.5849e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1616\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1616 - val_loss: 0.1838 - lr: 3.4056e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1700\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1700 - val_loss: 0.1690 - lr: 3.2353e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1611\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1611 - val_loss: 0.1942 - lr: 3.0736e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1688\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1688 - val_loss: 0.1924 - lr: 2.9199e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 8s 422ms/step - loss: 0.1648 - val_loss: 0.1681 - lr: 2.7739e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.1467 - val_loss: 0.1584 - lr: 2.7739e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1581 - val_loss: 0.1517 - lr: 2.7739e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1625\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1625 - val_loss: 0.2114 - lr: 2.7739e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1715\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1715 - val_loss: 0.1859 - lr: 2.6352e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1524 - val_loss: 0.1481 - lr: 2.5034e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1828\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1828 - val_loss: 0.1586 - lr: 2.5034e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1553\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1553 - val_loss: 0.1538 - lr: 2.3783e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1648\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1648 - val_loss: 0.1699 - lr: 2.2594e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1466\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1466 - val_loss: 0.1843 - lr: 2.1464e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1497\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1497 - val_loss: 0.1708 - lr: 2.0391e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1445\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1445 - val_loss: 0.1757 - lr: 1.9371e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1490\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1490 - val_loss: 0.1726 - lr: 1.8403e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1416\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1416 - val_loss: 0.1680 - lr: 1.7482e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1503\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1503 - val_loss: 0.1649 - lr: 1.6608e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1477\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1477 - val_loss: 0.1756 - lr: 1.5778e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1393\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.1393 - val_loss: 0.1715 - lr: 1.4989e-04\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1418\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1418 - val_loss: 0.1761 - lr: 1.4240e-04\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1502\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1502 - val_loss: 0.1712 - lr: 1.3528e-04\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1501\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 6s 362ms/step - loss: 0.1501 - val_loss: 0.1726 - lr: 1.2851e-04\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1441\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.1441 - val_loss: 0.1741 - lr: 1.2209e-04\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1440\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1440 - val_loss: 0.1802 - lr: 1.1598e-04\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1342\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1342 - val_loss: 0.1792 - lr: 1.1018e-04\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1456\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1456 - val_loss: 0.1818 - lr: 1.0467e-04\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1516\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1516 - val_loss: 0.1743 - lr: 9.9440e-05\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1452\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.1452 - val_loss: 0.1673 - lr: 9.4468e-05\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1389\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1389 - val_loss: 0.1699 - lr: 8.9745e-05\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1493\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1493 - val_loss: 0.1734 - lr: 8.5258e-05\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1294\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1294 - val_loss: 0.1726 - lr: 8.0995e-05\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1376\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1376 - val_loss: 0.1729 - lr: 7.6945e-05\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1396\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "18/18 [==============================] - 8s 422ms/step - loss: 0.1396 - val_loss: 0.1702 - lr: 7.3098e-05\n",
      "Epoch 76: early stopping\n",
      "2/2 [==============================] - 7s 121ms/step\n",
      "0.1524, 0.1481, 0.3545\n",
      "______fold 9______, ________repeat 3__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 56s 839ms/step - loss: 0.4765 - val_loss: 0.4442 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 424ms/step - loss: 0.4617 - val_loss: 0.4348 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.4411 - val_loss: 0.4332 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.4259 - val_loss: 0.4156 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 414ms/step - loss: 0.3855 - val_loss: 0.3876 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3534\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.3534 - val_loss: 0.3917 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3293\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.3293 - val_loss: 0.4156 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.2966 - val_loss: 0.3661 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2921\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.2921 - val_loss: 0.3976 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2632 - val_loss: 0.3500 - lr: 8.5737e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2782\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2782 - val_loss: 0.3969 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2559 - val_loss: 0.3352 - lr: 8.1451e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2429\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.2429 - val_loss: 0.3362 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2357\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.2357 - val_loss: 0.3569 - lr: 7.7378e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2436\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.2436 - val_loss: 0.3397 - lr: 7.3509e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2429\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 6s 362ms/step - loss: 0.2429 - val_loss: 0.3550 - lr: 6.9834e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2165\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.2165 - val_loss: 0.3554 - lr: 6.6342e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2195\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.2195 - val_loss: 0.3449 - lr: 6.3025e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2198\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.2198 - val_loss: 0.3526 - lr: 5.9874e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2062\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.2062 - val_loss: 0.3733 - lr: 5.6880e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2166\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2166 - val_loss: 0.3713 - lr: 5.4036e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2056\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2056 - val_loss: 0.3579 - lr: 5.1334e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2132\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 361ms/step - loss: 0.2132 - val_loss: 0.3606 - lr: 4.8767e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2074\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2074 - val_loss: 0.3755 - lr: 4.6329e-04\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.1929\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 415ms/step - loss: 0.1929 - val_loss: 0.3607 - lr: 4.4013e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1792\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1792 - val_loss: 0.3649 - lr: 4.1812e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1963\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1963 - val_loss: 0.3508 - lr: 3.9721e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1875\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1875 - val_loss: 0.3521 - lr: 3.7735e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1896\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1896 - val_loss: 0.3893 - lr: 3.5849e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1723\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1723 - val_loss: 0.3694 - lr: 3.4056e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1939\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1939 - val_loss: 0.3451 - lr: 3.2353e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1843\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1843 - val_loss: 0.3505 - lr: 3.0736e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1866\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1866 - val_loss: 0.3405 - lr: 2.9199e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1828\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1828 - val_loss: 0.3495 - lr: 2.7739e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1878 - val_loss: 0.3141 - lr: 2.6352e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1788\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.1788 - val_loss: 0.3565 - lr: 2.6352e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1794\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1794 - val_loss: 0.3229 - lr: 2.5034e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1946\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1946 - val_loss: 0.3403 - lr: 2.3783e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1911\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 6s 362ms/step - loss: 0.1911 - val_loss: 0.3302 - lr: 2.2594e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1816\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1816 - val_loss: 0.3419 - lr: 2.1464e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1820\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1820 - val_loss: 0.3146 - lr: 2.0391e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1627\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1627 - val_loss: 0.3442 - lr: 1.9371e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1680\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1680 - val_loss: 0.3325 - lr: 1.8403e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1716\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1716 - val_loss: 0.3161 - lr: 1.7482e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1597 - val_loss: 0.3090 - lr: 1.6608e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1678\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 6s 362ms/step - loss: 0.1678 - val_loss: 0.3209 - lr: 1.6608e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1600 - val_loss: 0.2935 - lr: 1.5778e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1532\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1532 - val_loss: 0.3106 - lr: 1.5778e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1499\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.1499 - val_loss: 0.3225 - lr: 1.4989e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1735 - val_loss: 0.2898 - lr: 1.4240e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1790\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1790 - val_loss: 0.3205 - lr: 1.4240e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1708\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 6s 362ms/step - loss: 0.1708 - val_loss: 0.2965 - lr: 1.3528e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1448\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1448 - val_loss: 0.2905 - lr: 1.2851e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1556 - val_loss: 0.2787 - lr: 1.2209e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1571 - val_loss: 0.2744 - lr: 1.2209e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1643\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1643 - val_loss: 0.2853 - lr: 1.2209e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1459\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1459 - val_loss: 0.2818 - lr: 1.1598e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1440\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1440 - val_loss: 0.2832 - lr: 1.1018e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1547\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1547 - val_loss: 0.3013 - lr: 1.0467e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1380 - val_loss: 0.2725 - lr: 9.9440e-05\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1594\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1594 - val_loss: 0.2828 - lr: 9.9440e-05\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1523\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.1523 - val_loss: 0.2769 - lr: 9.4468e-05\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1416\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.1416 - val_loss: 0.2765 - lr: 8.9745e-05\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1388 - val_loss: 0.2702 - lr: 8.5258e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1478\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1478 - val_loss: 0.2908 - lr: 8.5258e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1633\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1633 - val_loss: 0.3031 - lr: 8.0995e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1550 - val_loss: 0.2667 - lr: 7.6945e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1397\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1397 - val_loss: 0.2710 - lr: 7.6945e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1560\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1560 - val_loss: 0.2901 - lr: 7.3098e-05\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.1495 - val_loss: 0.2665 - lr: 6.9443e-05\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1439\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 9s 477ms/step - loss: 0.1439 - val_loss: 0.2801 - lr: 6.9443e-05\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 8s 464ms/step - loss: 0.1574 - val_loss: 0.2589 - lr: 6.5971e-05\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1662\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1662 - val_loss: 0.2633 - lr: 6.5971e-05\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1284\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1284 - val_loss: 0.2638 - lr: 6.2672e-05\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1442\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 5.656161210936261e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1442 - val_loss: 0.2817 - lr: 5.9539e-05\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1489\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 5.373353305913042e-05.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1489 - val_loss: 0.2758 - lr: 5.6562e-05\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1475\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 5.104685606056591e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1475 - val_loss: 0.2674 - lr: 5.3734e-05\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1469 - val_loss: 0.2577 - lr: 5.1047e-05\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.1465 - val_loss: 0.2541 - lr: 5.1047e-05\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1450\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 4.849451343034161e-05.\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.1450 - val_loss: 0.2577 - lr: 5.1047e-05\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.1380 - val_loss: 0.2525 - lr: 4.8495e-05\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.1447 - val_loss: 0.2402 - lr: 4.8495e-05\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.1512 - val_loss: 0.2344 - lr: 4.8495e-05\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1488\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 4.606978654919658e-05.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1488 - val_loss: 0.2429 - lr: 4.8495e-05\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1327\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 4.3766295493696814e-05.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1327 - val_loss: 0.2399 - lr: 4.6070e-05\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1469\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 4.1577981755835934e-05.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1469 - val_loss: 0.2415 - lr: 4.3766e-05\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1478\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 3.949908405047608e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1478 - val_loss: 0.2526 - lr: 4.1578e-05\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1332\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 3.752413140318822e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1332 - val_loss: 0.2464 - lr: 3.9499e-05\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1444\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 3.564792586985277e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1444 - val_loss: 0.2400 - lr: 3.7524e-05\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1351\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 3.3865528712340166e-05.\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.1351 - val_loss: 0.2376 - lr: 3.5648e-05\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1396\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 3.217225348635111e-05.\n",
      "18/18 [==============================] - 8s 421ms/step - loss: 0.1396 - val_loss: 0.2383 - lr: 3.3866e-05\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1368\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 3.0563641848857516e-05.\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1368 - val_loss: 0.2397 - lr: 3.2172e-05\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1319\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 2.9035460102022626e-05.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1319 - val_loss: 0.2363 - lr: 3.0564e-05\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1398\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 2.7583687096921494e-05.\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.1398 - val_loss: 0.2414 - lr: 2.9035e-05\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1433\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 2.620450213726144e-05.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1433 - val_loss: 0.2422 - lr: 2.7584e-05\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1519\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 2.4894276339182395e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1519 - val_loss: 0.2422 - lr: 2.6205e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1425\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 2.3649562263017287e-05.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1425 - val_loss: 0.2452 - lr: 2.4894e-05\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1317\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 2.2467083545052444e-05.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1317 - val_loss: 0.2474 - lr: 2.3650e-05\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1345\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 2.134372971340781e-05.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1345 - val_loss: 0.2445 - lr: 2.2467e-05\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1379\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 2.0276544091757387e-05.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.1379 - val_loss: 0.2478 - lr: 2.1344e-05\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1313\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 1.9262716887169517e-05.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1313 - val_loss: 0.2532 - lr: 2.0277e-05\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1359\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 1.8299581734027014e-05.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.1359 - val_loss: 0.2546 - lr: 1.9263e-05\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1345\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 1.7384601869707693e-05.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1345 - val_loss: 0.2525 - lr: 1.8300e-05\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1436\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 1.6515371862624305e-05.\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.1436 - val_loss: 0.2466 - lr: 1.7385e-05\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1328\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 1.568960378790507e-05.\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.1328 - val_loss: 0.2474 - lr: 1.6515e-05\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1429\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 1.490512377131381e-05.\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.1429 - val_loss: 0.2496 - lr: 1.5690e-05\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1496\n",
      "Epoch 107: ReduceLROnPlateau reducing learning rate to 1.4159867669150115e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1496 - val_loss: 0.2513 - lr: 1.4905e-05\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1335\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 1.3451874156089615e-05.\n",
      "Restoring model weights from the end of the best epoch: 83.\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.1335 - val_loss: 0.2554 - lr: 1.4160e-05\n",
      "Epoch 108: early stopping\n",
      "2/2 [==============================] - 6s 126ms/step\n",
      "0.1512, 0.2344, 0.4681\n",
      "______fold 9______, ________repeat 4__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 822ms/step - loss: 0.4827 - val_loss: 0.4397 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4540\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.4540 - val_loss: 0.4483 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.4523 - val_loss: 0.4205 - lr: 9.5000e-04\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4474\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.4474 - val_loss: 0.4537 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4439\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.4439 - val_loss: 0.4228 - lr: 9.0250e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4383\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.4383 - val_loss: 0.4216 - lr: 8.5737e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.4180 - val_loss: 0.4109 - lr: 8.1451e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.4003 - val_loss: 0.3929 - lr: 8.1451e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.3637 - val_loss: 0.3533 - lr: 8.1451e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3632\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 8s 421ms/step - loss: 0.3632 - val_loss: 0.3556 - lr: 8.1451e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3373\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 8s 422ms/step - loss: 0.3373 - val_loss: 0.3599 - lr: 7.7378e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.3336 - val_loss: 0.3220 - lr: 7.3509e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3143\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 412ms/step - loss: 0.3143 - val_loss: 0.3698 - lr: 7.3509e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3223\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.3223 - val_loss: 0.3590 - lr: 6.9834e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2922\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2922 - val_loss: 0.3550 - lr: 6.6342e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2652\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2652 - val_loss: 0.3278 - lr: 6.3025e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.2657 - val_loss: 0.3166 - lr: 5.9874e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2661\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.2661 - val_loss: 0.3258 - lr: 5.9874e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2534\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 413ms/step - loss: 0.2534 - val_loss: 0.3404 - lr: 5.6880e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 9s 474ms/step - loss: 0.2405 - val_loss: 0.3044 - lr: 5.4036e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2595\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2595 - val_loss: 0.3300 - lr: 5.4036e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2361 - val_loss: 0.2642 - lr: 5.1334e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2536\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.2536 - val_loss: 0.2971 - lr: 5.1334e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.2338 - val_loss: 0.2617 - lr: 4.8767e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2005\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2005 - val_loss: 0.2741 - lr: 4.8767e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2159\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2159 - val_loss: 0.3162 - lr: 4.6329e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2170\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2170 - val_loss: 0.3109 - lr: 4.4013e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2387 - val_loss: 0.2521 - lr: 4.1812e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2143\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2143 - val_loss: 0.3056 - lr: 4.1812e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2205\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2205 - val_loss: 0.2575 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2139 - val_loss: 0.2390 - lr: 3.7735e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2138 - val_loss: 0.2327 - lr: 3.7735e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2090\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2090 - val_loss: 0.2633 - lr: 3.7735e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2077\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2077 - val_loss: 0.2715 - lr: 3.5849e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2024\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2024 - val_loss: 0.2504 - lr: 3.4056e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1957\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1957 - val_loss: 0.2667 - lr: 3.2353e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1882\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1882 - val_loss: 0.2678 - lr: 3.0736e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1965 - val_loss: 0.2118 - lr: 2.9199e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1993\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1993 - val_loss: 0.2211 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1920\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1920 - val_loss: 0.2384 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1943\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1943 - val_loss: 0.2137 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1823\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1823 - val_loss: 0.2346 - lr: 2.5034e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1800\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.1800 - val_loss: 0.2379 - lr: 2.3783e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1785\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1785 - val_loss: 0.2642 - lr: 2.2594e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1900\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1900 - val_loss: 0.2313 - lr: 2.1464e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1680\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1680 - val_loss: 0.2541 - lr: 2.0391e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1727\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1727 - val_loss: 0.2357 - lr: 1.9371e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1807\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.1807 - val_loss: 0.2320 - lr: 1.8403e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1692\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1692 - val_loss: 0.2350 - lr: 1.7482e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1714\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1714 - val_loss: 0.2250 - lr: 1.6608e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1593\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1593 - val_loss: 0.2311 - lr: 1.5778e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1730\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.1730 - val_loss: 0.2281 - lr: 1.4989e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1846\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.1846 - val_loss: 0.2334 - lr: 1.4240e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1711\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.1711 - val_loss: 0.2322 - lr: 1.3528e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1664\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1664 - val_loss: 0.2149 - lr: 1.2851e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1768\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1768 - val_loss: 0.2238 - lr: 1.2209e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1699\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1699 - val_loss: 0.2120 - lr: 1.1598e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1695\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1695 - val_loss: 0.2246 - lr: 1.1018e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1581\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1581 - val_loss: 0.2286 - lr: 1.0467e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1641\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1641 - val_loss: 0.2305 - lr: 9.9440e-05\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1560\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1560 - val_loss: 0.2400 - lr: 9.4468e-05\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1596\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1596 - val_loss: 0.2371 - lr: 8.9745e-05\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1692\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.1692 - val_loss: 0.2320 - lr: 8.5258e-05\n",
      "Epoch 63: early stopping\n",
      "2/2 [==============================] - 6s 129ms/step\n",
      "0.1965, 0.2118, 0.4684\n",
      "______fold 9______, ________repeat 5__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 874ms/step - loss: 0.4784 - val_loss: 0.4443 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 422ms/step - loss: 0.4590 - val_loss: 0.4284 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 8s 422ms/step - loss: 0.4307 - val_loss: 0.4161 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3948\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.3948 - val_loss: 0.4193 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3655\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.3655 - val_loss: 0.4297 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3559\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.3559 - val_loss: 0.4274 - lr: 9.0250e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.3659 - val_loss: 0.3991 - lr: 8.5737e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.3375 - val_loss: 0.3767 - lr: 8.5737e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.3187 - val_loss: 0.3455 - lr: 8.5737e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2955 - val_loss: 0.3200 - lr: 8.5737e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2851\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2851 - val_loss: 0.3465 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2864 - val_loss: 0.2777 - lr: 8.1451e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2617\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2617 - val_loss: 0.2876 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2480\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2480 - val_loss: 0.2891 - lr: 7.7378e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2369\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2369 - val_loss: 0.2882 - lr: 7.3509e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.2273 - val_loss: 0.2736 - lr: 6.9834e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2386 - val_loss: 0.2350 - lr: 6.9834e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.2258 - val_loss: 0.2132 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2017\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.2017 - val_loss: 0.2225 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2182\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2182 - val_loss: 0.3554 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2080\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2080 - val_loss: 0.3044 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1985 - val_loss: 0.1985 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2026\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.2026 - val_loss: 0.2780 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1912\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1912 - val_loss: 0.2268 - lr: 5.6880e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1697\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1697 - val_loss: 0.2055 - lr: 5.4036e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1641\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1641 - val_loss: 0.2783 - lr: 5.1334e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1906\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1906 - val_loss: 0.3009 - lr: 4.8767e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1697 - val_loss: 0.1976 - lr: 4.6329e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1808\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1808 - val_loss: 0.2183 - lr: 4.6329e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1783\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1783 - val_loss: 0.2488 - lr: 4.4013e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1724\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 363ms/step - loss: 0.1724 - val_loss: 0.2164 - lr: 4.1812e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1624\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1624 - val_loss: 0.1996 - lr: 3.9721e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1631 - val_loss: 0.1937 - lr: 3.7735e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1875\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1875 - val_loss: 0.2149 - lr: 3.7735e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1573\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1573 - val_loss: 0.2405 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1514\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1514 - val_loss: 0.2285 - lr: 3.4056e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1520\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1520 - val_loss: 0.2297 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1579\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1579 - val_loss: 0.2267 - lr: 3.0736e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1598\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1598 - val_loss: 0.2435 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1518\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1518 - val_loss: 0.2338 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1448\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.1448 - val_loss: 0.2394 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1427\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 9s 476ms/step - loss: 0.1427 - val_loss: 0.2531 - lr: 2.5034e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1414\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1414 - val_loss: 0.2307 - lr: 2.3783e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1443\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 8s 451ms/step - loss: 0.1443 - val_loss: 0.2425 - lr: 2.2594e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1352\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1352 - val_loss: 0.2350 - lr: 2.1464e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1239\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1239 - val_loss: 0.2360 - lr: 2.0391e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1289\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1289 - val_loss: 0.2512 - lr: 1.9371e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1469\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1469 - val_loss: 0.2518 - lr: 1.8403e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1268\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1268 - val_loss: 0.2610 - lr: 1.7482e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1298\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1298 - val_loss: 0.2661 - lr: 1.6608e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1171\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 8s 420ms/step - loss: 0.1171 - val_loss: 0.2640 - lr: 1.5778e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1242\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.1242 - val_loss: 0.2566 - lr: 1.4989e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1262\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1262 - val_loss: 0.2758 - lr: 1.4240e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1333\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1333 - val_loss: 0.2763 - lr: 1.3528e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1206\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.1206 - val_loss: 0.2758 - lr: 1.2851e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1312\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1312 - val_loss: 0.2724 - lr: 1.2209e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1392\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 9s 477ms/step - loss: 0.1392 - val_loss: 0.2934 - lr: 1.1598e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1226\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "18/18 [==============================] - 9s 501ms/step - loss: 0.1226 - val_loss: 0.3130 - lr: 1.1018e-04\n",
      "Epoch 58: early stopping\n",
      "2/2 [==============================] - 7s 120ms/step\n",
      "0.1631, 0.1937, 0.3872\n",
      "______fold 9______, ________repeat 6__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 825ms/step - loss: 0.4856 - val_loss: 0.4388 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 428ms/step - loss: 0.4397 - val_loss: 0.4258 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4289\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.4289 - val_loss: 0.4294 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4021\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.4021 - val_loss: 0.4288 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.4142 - val_loss: 0.4205 - lr: 9.0250e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3904\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.3904 - val_loss: 0.4237 - lr: 9.0250e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.3782 - val_loss: 0.3867 - lr: 8.5737e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.3510 - val_loss: 0.3801 - lr: 8.5737e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3576\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.3576 - val_loss: 0.3916 - lr: 8.5737e-04\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.3392\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.3392 - val_loss: 0.3916 - lr: 8.1451e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3345\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.3345 - val_loss: 0.3922 - lr: 7.7378e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3191\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.3191 - val_loss: 0.3807 - lr: 7.3509e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3181 - val_loss: 0.3681 - lr: 6.9834e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2969 - val_loss: 0.3640 - lr: 6.9834e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3054\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.3054 - val_loss: 0.3906 - lr: 6.9834e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2774\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2774 - val_loss: 0.3643 - lr: 6.6342e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2754\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.2754 - val_loss: 0.3674 - lr: 6.3025e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2653 - val_loss: 0.3630 - lr: 5.9874e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2432 - val_loss: 0.3109 - lr: 5.9874e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2478\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.2478 - val_loss: 0.3367 - lr: 5.9874e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2316\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 6s 362ms/step - loss: 0.2316 - val_loss: 0.3346 - lr: 5.6880e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2373\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.2373 - val_loss: 0.3377 - lr: 5.4036e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2129 - val_loss: 0.2839 - lr: 5.1334e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2086\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.2086 - val_loss: 0.3042 - lr: 5.1334e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2017\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.2017 - val_loss: 0.3065 - lr: 4.8767e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2054\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 9s 477ms/step - loss: 0.2054 - val_loss: 0.3104 - lr: 4.6329e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.2115 - val_loss: 0.2791 - lr: 4.4013e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2094\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2094 - val_loss: 0.3079 - lr: 4.4013e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2089\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2089 - val_loss: 0.3080 - lr: 4.1812e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 7s 406ms/step - loss: 0.2176 - val_loss: 0.2783 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1857 - val_loss: 0.2423 - lr: 3.9721e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1887\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1887 - val_loss: 0.2513 - lr: 3.9721e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1958\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 6s 362ms/step - loss: 0.1958 - val_loss: 0.2778 - lr: 3.7735e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1989\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1989 - val_loss: 0.2761 - lr: 3.5849e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2009\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.2009 - val_loss: 0.2566 - lr: 3.4056e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1776\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1776 - val_loss: 0.2592 - lr: 3.2353e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1737\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 6s 362ms/step - loss: 0.1737 - val_loss: 0.2529 - lr: 3.0736e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1857\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1857 - val_loss: 0.2558 - lr: 2.9199e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1862\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1862 - val_loss: 0.2509 - lr: 2.7739e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1730\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1730 - val_loss: 0.2577 - lr: 2.6352e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1717\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1717 - val_loss: 0.2445 - lr: 2.5034e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1756\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1756 - val_loss: 0.2666 - lr: 2.3783e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1726 - val_loss: 0.2351 - lr: 2.2594e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1690 - val_loss: 0.2200 - lr: 2.2594e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1652\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1652 - val_loss: 0.2324 - lr: 2.2594e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1689\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1689 - val_loss: 0.2304 - lr: 2.1464e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1641\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1641 - val_loss: 0.2378 - lr: 2.0391e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1675\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1675 - val_loss: 0.2372 - lr: 1.9371e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1456\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1456 - val_loss: 0.2294 - lr: 1.8403e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.1830 - val_loss: 0.2113 - lr: 1.7482e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1639\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1639 - val_loss: 0.2199 - lr: 1.7482e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1705\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 6s 362ms/step - loss: 0.1705 - val_loss: 0.2266 - lr: 1.6608e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1626\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1626 - val_loss: 0.2405 - lr: 1.5778e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1743\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1743 - val_loss: 0.2294 - lr: 1.4989e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1665\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1665 - val_loss: 0.2233 - lr: 1.4240e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1475\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1475 - val_loss: 0.2244 - lr: 1.3528e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1491\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1491 - val_loss: 0.2263 - lr: 1.2851e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1580\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.1580 - val_loss: 0.2308 - lr: 1.2209e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1584\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1584 - val_loss: 0.2367 - lr: 1.1598e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1628\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1628 - val_loss: 0.2313 - lr: 1.1018e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1692\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1692 - val_loss: 0.2379 - lr: 1.0467e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1412\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 8s 467ms/step - loss: 0.1412 - val_loss: 0.2353 - lr: 9.9440e-05\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1475\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1475 - val_loss: 0.2363 - lr: 9.4468e-05\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1493\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 6s 362ms/step - loss: 0.1493 - val_loss: 0.2269 - lr: 8.9745e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1688\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1688 - val_loss: 0.2243 - lr: 8.5258e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1539\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1539 - val_loss: 0.2205 - lr: 8.0995e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1358\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1358 - val_loss: 0.2209 - lr: 7.6945e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1449\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.1449 - val_loss: 0.2202 - lr: 7.3098e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1305\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 6s 359ms/step - loss: 0.1305 - val_loss: 0.2247 - lr: 6.9443e-05\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1719\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.1719 - val_loss: 0.2254 - lr: 6.5971e-05\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1463\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1463 - val_loss: 0.2302 - lr: 6.2672e-05\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1440\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 5.656161210936261e-05.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1440 - val_loss: 0.2305 - lr: 5.9539e-05\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1436\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 5.373353305913042e-05.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.1436 - val_loss: 0.2294 - lr: 5.6562e-05\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1438\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 5.104685606056591e-05.\n",
      "18/18 [==============================] - 6s 360ms/step - loss: 0.1438 - val_loss: 0.2281 - lr: 5.3734e-05\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1409\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 4.849451343034161e-05.\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1409 - val_loss: 0.2310 - lr: 5.1047e-05\n",
      "Epoch 75: early stopping\n",
      "2/2 [==============================] - 6s 130ms/step\n",
      "0.1830, 0.2113, 0.4742\n",
      "______fold 9______, ________repeat 7__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 825ms/step - loss: 0.4805 - val_loss: 0.4404 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.4545 - val_loss: 0.4263 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4493\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.4493 - val_loss: 0.4309 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4460\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 387ms/step - loss: 0.4460 - val_loss: 0.4453 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4351 - val_loss: 0.4164 - lr: 9.0250e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.4225 - val_loss: 0.4017 - lr: 9.0250e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3773\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.3773 - val_loss: 0.4357 - lr: 9.0250e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3527\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.3527 - val_loss: 0.4559 - lr: 8.5737e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3680\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.3680 - val_loss: 0.4556 - lr: 8.1451e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3581\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.3581 - val_loss: 0.4155 - lr: 7.7378e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3577\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.3577 - val_loss: 0.4323 - lr: 7.3509e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3325\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.3325 - val_loss: 0.4258 - lr: 6.9834e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3397\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.3397 - val_loss: 0.4386 - lr: 6.6342e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3120\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.3120 - val_loss: 0.4145 - lr: 6.3025e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2976\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.2976 - val_loss: 0.4299 - lr: 5.9874e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.2961 - val_loss: 0.3841 - lr: 5.6880e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3086\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.3086 - val_loss: 0.4007 - lr: 5.6880e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2849\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.2849 - val_loss: 0.4030 - lr: 5.4036e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3013\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.3013 - val_loss: 0.4014 - lr: 5.1334e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2725\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 364ms/step - loss: 0.2725 - val_loss: 0.4155 - lr: 4.8767e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2755 - val_loss: 0.3577 - lr: 4.6329e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2752\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.2752 - val_loss: 0.3609 - lr: 4.6329e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2551\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2551 - val_loss: 0.3588 - lr: 4.4013e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2652\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2652 - val_loss: 0.3785 - lr: 4.1812e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2646\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2646 - val_loss: 0.3848 - lr: 3.9721e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2578\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2578 - val_loss: 0.3794 - lr: 3.7735e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2470\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.2470 - val_loss: 0.3926 - lr: 3.5849e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2533\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.2533 - val_loss: 0.3711 - lr: 3.4056e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2406\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.2406 - val_loss: 0.3848 - lr: 3.2353e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2581\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.2581 - val_loss: 0.3646 - lr: 3.0736e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2378 - val_loss: 0.3425 - lr: 2.9199e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2461 - val_loss: 0.3270 - lr: 2.9199e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2308 - val_loss: 0.3180 - lr: 2.9199e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.2366 - val_loss: 0.2921 - lr: 2.9199e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2263 - val_loss: 0.2594 - lr: 2.9199e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2080\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.2080 - val_loss: 0.3048 - lr: 2.9199e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2033\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.2033 - val_loss: 0.2780 - lr: 2.7739e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2273\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2273 - val_loss: 0.2807 - lr: 2.6352e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2190\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.2190 - val_loss: 0.2701 - lr: 2.5034e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2053\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.2053 - val_loss: 0.2708 - lr: 2.3783e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1992\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1992 - val_loss: 0.2802 - lr: 2.2594e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2129\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.2129 - val_loss: 0.2905 - lr: 2.1464e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2013\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.2013 - val_loss: 0.2675 - lr: 2.0391e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1977 - val_loss: 0.2497 - lr: 1.9371e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1966 - val_loss: 0.2465 - lr: 1.9371e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2055\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2055 - val_loss: 0.2651 - lr: 1.9371e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1993\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1993 - val_loss: 0.2476 - lr: 1.8403e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1958\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1958 - val_loss: 0.2563 - lr: 1.7482e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1955\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1955 - val_loss: 0.2482 - lr: 1.6608e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1926\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1926 - val_loss: 0.2490 - lr: 1.5778e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1886\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1886 - val_loss: 0.2566 - lr: 1.4989e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2009 - val_loss: 0.2355 - lr: 1.4240e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1822\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1822 - val_loss: 0.2464 - lr: 1.4240e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1765\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1765 - val_loss: 0.2406 - lr: 1.3528e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1854\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1854 - val_loss: 0.2513 - lr: 1.2851e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1830\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1830 - val_loss: 0.2579 - lr: 1.2209e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1947\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1947 - val_loss: 0.2432 - lr: 1.1598e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1779 - val_loss: 0.2352 - lr: 1.1018e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1913\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1913 - val_loss: 0.2359 - lr: 1.1018e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1748 - val_loss: 0.2333 - lr: 1.0467e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1881\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1881 - val_loss: 0.2393 - lr: 1.0467e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1813\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1813 - val_loss: 0.2357 - lr: 9.9440e-05\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.1777 - val_loss: 0.2303 - lr: 9.4468e-05\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1740\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1740 - val_loss: 0.2332 - lr: 9.4468e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1796\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1796 - val_loss: 0.2447 - lr: 8.9745e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1706\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1706 - val_loss: 0.2374 - lr: 8.5258e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1698\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1698 - val_loss: 0.2402 - lr: 8.0995e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1710\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1710 - val_loss: 0.2435 - lr: 7.6945e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1984\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1984 - val_loss: 0.2449 - lr: 7.3098e-05\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1739 - val_loss: 0.2285 - lr: 6.9443e-05\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1644\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1644 - val_loss: 0.2310 - lr: 6.9443e-05\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1796\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1796 - val_loss: 0.2394 - lr: 6.5971e-05\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1705\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1705 - val_loss: 0.2444 - lr: 6.2672e-05\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1725\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 5.656161210936261e-05.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1725 - val_loss: 0.2325 - lr: 5.9539e-05\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1675\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 5.373353305913042e-05.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1675 - val_loss: 0.2334 - lr: 5.6562e-05\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1735\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 5.104685606056591e-05.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1735 - val_loss: 0.2394 - lr: 5.3734e-05\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1650\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 4.849451343034161e-05.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1650 - val_loss: 0.2330 - lr: 5.1047e-05\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1769\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 4.606978654919658e-05.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1769 - val_loss: 0.2378 - lr: 4.8495e-05\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1775\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 4.3766295493696814e-05.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1775 - val_loss: 0.2382 - lr: 4.6070e-05\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1634\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 4.1577981755835934e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1634 - val_loss: 0.2378 - lr: 4.3766e-05\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1625\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.949908405047608e-05.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1625 - val_loss: 0.2400 - lr: 4.1578e-05\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1615\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.752413140318822e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1615 - val_loss: 0.2391 - lr: 3.9499e-05\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1739\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.564792586985277e-05.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1739 - val_loss: 0.2359 - lr: 3.7524e-05\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1758\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 3.3865528712340166e-05.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1758 - val_loss: 0.2358 - lr: 3.5648e-05\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1708\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 3.217225348635111e-05.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1708 - val_loss: 0.2362 - lr: 3.3866e-05\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1753\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 3.0563641848857516e-05.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1753 - val_loss: 0.2387 - lr: 3.2172e-05\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1583\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 2.9035460102022626e-05.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1583 - val_loss: 0.2388 - lr: 3.0564e-05\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1574\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 2.7583687096921494e-05.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1574 - val_loss: 0.2398 - lr: 2.9035e-05\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1607\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 2.620450213726144e-05.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1607 - val_loss: 0.2394 - lr: 2.7584e-05\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1691\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 2.4894276339182395e-05.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1691 - val_loss: 0.2395 - lr: 2.6205e-05\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1689\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 2.3649562263017287e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1689 - val_loss: 0.2387 - lr: 2.4894e-05\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1675\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 2.2467083545052444e-05.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1675 - val_loss: 0.2401 - lr: 2.3650e-05\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1612\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 2.134372971340781e-05.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1612 - val_loss: 0.2400 - lr: 2.2467e-05\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1815\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 2.0276544091757387e-05.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1815 - val_loss: 0.2407 - lr: 2.1344e-05\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1790\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 1.9262716887169517e-05.\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1790 - val_loss: 0.2406 - lr: 2.0277e-05\n",
      "Epoch 95: early stopping\n",
      "2/2 [==============================] - 8s 115ms/step\n",
      "0.1739, 0.2285, 0.4385\n",
      "______fold 9______, ________repeat 8__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 818ms/step - loss: 0.4842 - val_loss: 0.4455 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 424ms/step - loss: 0.4549 - val_loss: 0.4356 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4324\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 415ms/step - loss: 0.4324 - val_loss: 0.4375 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.4230 - val_loss: 0.4194 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4023 - val_loss: 0.3971 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.3864 - val_loss: 0.3687 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.3446 - val_loss: 0.3512 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3214\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.3214 - val_loss: 0.3535 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.3068 - val_loss: 0.3488 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2823 - val_loss: 0.3447 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2980\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2980 - val_loss: 0.3491 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2602 - val_loss: 0.3371 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2552 - val_loss: 0.3286 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2673\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2673 - val_loss: 0.3353 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2627\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2627 - val_loss: 0.3550 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2389\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2389 - val_loss: 0.3322 - lr: 7.7378e-04\n",
      "Epoch 17/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.2354\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2354 - val_loss: 0.3458 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2291\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2291 - val_loss: 0.3573 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2273\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2273 - val_loss: 0.3586 - lr: 6.6342e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2252\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2252 - val_loss: 0.3552 - lr: 6.3025e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2097\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2097 - val_loss: 0.3386 - lr: 5.9874e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2067\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2067 - val_loss: 0.3474 - lr: 5.6880e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2171\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2171 - val_loss: 0.3573 - lr: 5.4036e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2168\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2168 - val_loss: 0.3448 - lr: 5.1334e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1891\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1891 - val_loss: 0.3462 - lr: 4.8767e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2097\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2097 - val_loss: 0.3622 - lr: 4.6329e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1976\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1976 - val_loss: 0.3652 - lr: 4.4013e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2075\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2075 - val_loss: 0.3525 - lr: 4.1812e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1868\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1868 - val_loss: 0.3500 - lr: 3.9721e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2041\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.2041 - val_loss: 0.3327 - lr: 3.7735e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1792\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1792 - val_loss: 0.3331 - lr: 3.5849e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1712\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1712 - val_loss: 0.3321 - lr: 3.4056e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1944\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1944 - val_loss: 0.3375 - lr: 3.2353e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1886 - val_loss: 0.3210 - lr: 3.0736e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1898\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1898 - val_loss: 0.3400 - lr: 3.0736e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1884\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1884 - val_loss: 0.3546 - lr: 2.9199e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1819\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1819 - val_loss: 0.3309 - lr: 2.7739e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1944\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1944 - val_loss: 0.3322 - lr: 2.6352e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1868\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1868 - val_loss: 0.3348 - lr: 2.5034e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1838\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.1838 - val_loss: 0.3413 - lr: 2.3783e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1764\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1764 - val_loss: 0.3286 - lr: 2.2594e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1637\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1637 - val_loss: 0.3394 - lr: 2.1464e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1745\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1745 - val_loss: 0.3413 - lr: 2.0391e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1763\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1763 - val_loss: 0.3356 - lr: 1.9371e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1786\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1786 - val_loss: 0.3268 - lr: 1.8403e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1705\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1705 - val_loss: 0.3344 - lr: 1.7482e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1706 - val_loss: 0.3198 - lr: 1.6608e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1586\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1586 - val_loss: 0.3279 - lr: 1.6608e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1645\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1645 - val_loss: 0.3266 - lr: 1.5778e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.1619 - val_loss: 0.3133 - lr: 1.4989e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1584\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1584 - val_loss: 0.3180 - lr: 1.4989e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1550 - val_loss: 0.3076 - lr: 1.4240e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1577\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.1577 - val_loss: 0.3183 - lr: 1.4240e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1632\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1632 - val_loss: 0.3256 - lr: 1.3528e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1628\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1628 - val_loss: 0.3137 - lr: 1.2851e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1652\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1652 - val_loss: 0.3150 - lr: 1.2209e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1627\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1627 - val_loss: 0.3294 - lr: 1.1598e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1527\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.1527 - val_loss: 0.3244 - lr: 1.1018e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1563\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1563 - val_loss: 0.3276 - lr: 1.0467e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1478\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1478 - val_loss: 0.3197 - lr: 9.9440e-05\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1686\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1686 - val_loss: 0.3220 - lr: 9.4468e-05\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1573\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1573 - val_loss: 0.3273 - lr: 8.9745e-05\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1548\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1548 - val_loss: 0.3222 - lr: 8.5258e-05\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1564\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1564 - val_loss: 0.3203 - lr: 8.0995e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1626\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1626 - val_loss: 0.3207 - lr: 7.6945e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1525\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1525 - val_loss: 0.3211 - lr: 7.3098e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1492\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1492 - val_loss: 0.3260 - lr: 6.9443e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1570\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1570 - val_loss: 0.3317 - lr: 6.5971e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1471\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1471 - val_loss: 0.3347 - lr: 6.2672e-05\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1455\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 5.656161210936261e-05.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1455 - val_loss: 0.3227 - lr: 5.9539e-05\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1489\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 5.373353305913042e-05.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1489 - val_loss: 0.3179 - lr: 5.6562e-05\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1571\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 5.104685606056591e-05.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1571 - val_loss: 0.3154 - lr: 5.3734e-05\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1479\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 4.849451343034161e-05.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1479 - val_loss: 0.3135 - lr: 5.1047e-05\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1547\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 4.606978654919658e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1547 - val_loss: 0.3127 - lr: 4.8495e-05\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1460\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 4.3766295493696814e-05.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1460 - val_loss: 0.3174 - lr: 4.6070e-05\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1561\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 4.1577981755835934e-05.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1561 - val_loss: 0.3192 - lr: 4.3766e-05\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1606\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 3.949908405047608e-05.\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1606 - val_loss: 0.3175 - lr: 4.1578e-05\n",
      "Epoch 77: early stopping\n",
      "2/2 [==============================] - 7s 145ms/step\n",
      "0.1550, 0.3076, 0.6798\n",
      "______fold 9______, ________repeat 9__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 883ms/step - loss: 0.4822 - val_loss: 0.4303 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4544\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 415ms/step - loss: 0.4544 - val_loss: 0.4323 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.4403 - val_loss: 0.4208 - lr: 9.5000e-04\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4225\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.4225 - val_loss: 0.4233 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.4021 - val_loss: 0.4138 - lr: 9.0250e-04\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.3799\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.3799 - val_loss: 0.4678 - lr: 9.0250e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3483\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.3483 - val_loss: 0.4176 - lr: 8.5737e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.3389 - val_loss: 0.3790 - lr: 8.1451e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.3135 - val_loss: 0.3781 - lr: 8.1451e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 8s 434ms/step - loss: 0.3001 - val_loss: 0.3555 - lr: 8.1451e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2796\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2796 - val_loss: 0.4087 - lr: 8.1451e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2825\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2825 - val_loss: 0.3674 - lr: 7.7378e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2662\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.2662 - val_loss: 0.4027 - lr: 7.3509e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2571\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.2571 - val_loss: 0.4192 - lr: 6.9834e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2619\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2619 - val_loss: 0.3766 - lr: 6.6342e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2575\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2575 - val_loss: 0.3682 - lr: 6.3025e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2583 - val_loss: 0.3402 - lr: 5.9874e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2452\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2452 - val_loss: 0.3481 - lr: 5.9874e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2316 - val_loss: 0.3399 - lr: 5.6880e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2359\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2359 - val_loss: 0.3669 - lr: 5.6880e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2369\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2369 - val_loss: 0.4079 - lr: 5.4036e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2322\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2322 - val_loss: 0.3837 - lr: 5.1334e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2430\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2430 - val_loss: 0.3456 - lr: 4.8767e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2240\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2240 - val_loss: 0.3718 - lr: 4.6329e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2199 - val_loss: 0.3391 - lr: 4.4013e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2184 - val_loss: 0.3379 - lr: 4.4013e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2072\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2072 - val_loss: 0.3505 - lr: 4.4013e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.2191 - val_loss: 0.3139 - lr: 4.1812e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2099\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2099 - val_loss: 0.3643 - lr: 4.1812e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.2206 - val_loss: 0.2639 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2055 - val_loss: 0.2376 - lr: 3.9721e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2017\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2017 - val_loss: 0.2469 - lr: 3.9721e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2090\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2090 - val_loss: 0.2521 - lr: 3.7735e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2123\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2123 - val_loss: 0.3068 - lr: 3.5849e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2021\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2021 - val_loss: 0.2511 - lr: 3.4056e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2005\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2005 - val_loss: 0.2659 - lr: 3.2353e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2090\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2090 - val_loss: 0.2701 - lr: 3.0736e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2062\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2062 - val_loss: 0.2645 - lr: 2.9199e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1967\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1967 - val_loss: 0.2607 - lr: 2.7739e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1928\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1928 - val_loss: 0.2572 - lr: 2.6352e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1901\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1901 - val_loss: 0.2869 - lr: 2.5034e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1990\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1990 - val_loss: 0.2615 - lr: 2.3783e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1949\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1949 - val_loss: 0.2613 - lr: 2.2594e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1769\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1769 - val_loss: 0.2521 - lr: 2.1464e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1782\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1782 - val_loss: 0.2667 - lr: 2.0391e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1957\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1957 - val_loss: 0.2754 - lr: 1.9371e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1772\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1772 - val_loss: 0.2747 - lr: 1.8403e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1700\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1700 - val_loss: 0.2827 - lr: 1.7482e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1879\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1879 - val_loss: 0.2808 - lr: 1.6608e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1869\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1869 - val_loss: 0.2810 - lr: 1.5778e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1788\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1788 - val_loss: 0.2804 - lr: 1.4989e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1847\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1847 - val_loss: 0.2934 - lr: 1.4240e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1786\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1786 - val_loss: 0.2969 - lr: 1.3528e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1744\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1744 - val_loss: 0.2914 - lr: 1.2851e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1667\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1667 - val_loss: 0.2880 - lr: 1.2209e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2084\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.2084 - val_loss: 0.2915 - lr: 1.1598e-04\n",
      "Epoch 56: early stopping\n",
      "2/2 [==============================] - 7s 121ms/step\n",
      "0.2055, 0.2376, 0.5797\n",
      "______fold 9______, ________repeat 10__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 56s 833ms/step - loss: 0.4903 - val_loss: 0.4397 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.4455 - val_loss: 0.4355 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4235\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.4235 - val_loss: 0.4403 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4204\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.4204 - val_loss: 0.4389 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.4047 - val_loss: 0.4036 - lr: 9.0250e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.3742 - val_loss: 0.3953 - lr: 9.0250e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.3678 - val_loss: 0.3667 - lr: 9.0250e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.3388 - val_loss: 0.3543 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.3178 - val_loss: 0.3398 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.2957 - val_loss: 0.3104 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3101\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.3101 - val_loss: 0.3163 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2802 - val_loss: 0.2596 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2685\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2685 - val_loss: 0.3196 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2470\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2470 - val_loss: 0.3175 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2841\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2841 - val_loss: 0.2715 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.2445 - val_loss: 0.2483 - lr: 7.3509e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2359\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2359 - val_loss: 0.2662 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2238\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2238 - val_loss: 0.2653 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2250\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.2250 - val_loss: 0.2535 - lr: 6.6342e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.2210 - val_loss: 0.2474 - lr: 6.3025e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2202\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2202 - val_loss: 0.2863 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2171\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2171 - val_loss: 0.2784 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2083\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2083 - val_loss: 0.2803 - lr: 5.6880e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2134\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.2134 - val_loss: 0.2543 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2146 - val_loss: 0.2374 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2083\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2083 - val_loss: 0.2424 - lr: 5.1334e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2074\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.2074 - val_loss: 0.2397 - lr: 4.8767e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1953\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1953 - val_loss: 0.2434 - lr: 4.6329e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1875\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1875 - val_loss: 0.2510 - lr: 4.4013e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2252\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2252 - val_loss: 0.2457 - lr: 4.1812e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2115\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2115 - val_loss: 0.2411 - lr: 3.9721e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1872\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1872 - val_loss: 0.2421 - lr: 3.7735e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1932 - val_loss: 0.2252 - lr: 3.5849e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1922 - val_loss: 0.2113 - lr: 3.5849e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1702\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1702 - val_loss: 0.2210 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1854\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1854 - val_loss: 0.2234 - lr: 3.4056e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1742 - val_loss: 0.2029 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1782\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1782 - val_loss: 0.2252 - lr: 3.2353e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1722 - val_loss: 0.1945 - lr: 3.0736e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1949\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1949 - val_loss: 0.2237 - lr: 3.0736e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1707\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1707 - val_loss: 0.2058 - lr: 2.9199e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1707\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1707 - val_loss: 0.2069 - lr: 2.7739e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1661\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1661 - val_loss: 0.2066 - lr: 2.6352e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1667\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1667 - val_loss: 0.1947 - lr: 2.5034e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1582\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1582 - val_loss: 0.1993 - lr: 2.3783e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1624\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1624 - val_loss: 0.2046 - lr: 2.2594e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1611\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1611 - val_loss: 0.2070 - lr: 2.1464e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1460\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1460 - val_loss: 0.2071 - lr: 2.0391e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1531\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1531 - val_loss: 0.2014 - lr: 1.9371e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1494 - val_loss: 0.1881 - lr: 1.8403e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1476\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1476 - val_loss: 0.1934 - lr: 1.8403e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1546 - val_loss: 0.1743 - lr: 1.7482e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1505\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1505 - val_loss: 0.2138 - lr: 1.7482e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1634\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1634 - val_loss: 0.1877 - lr: 1.6608e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1497\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1497 - val_loss: 0.1905 - lr: 1.5778e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1505\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1505 - val_loss: 0.1837 - lr: 1.4989e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1497\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1497 - val_loss: 0.2081 - lr: 1.4240e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1434\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1434 - val_loss: 0.2028 - lr: 1.3528e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1562\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1562 - val_loss: 0.1901 - lr: 1.2851e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1432\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1432 - val_loss: 0.1778 - lr: 1.2209e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1586\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1586 - val_loss: 0.1890 - lr: 1.1598e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1360\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1360 - val_loss: 0.1841 - lr: 1.1018e-04\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1383\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1383 - val_loss: 0.1851 - lr: 1.0467e-04\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1375\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1375 - val_loss: 0.1857 - lr: 9.9440e-05\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1406\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1406 - val_loss: 0.1898 - lr: 9.4468e-05\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1494\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1494 - val_loss: 0.1834 - lr: 8.9745e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1298\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1298 - val_loss: 0.1965 - lr: 8.5258e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1331\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1331 - val_loss: 0.1993 - lr: 8.0995e-05\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1318\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1318 - val_loss: 0.2041 - lr: 7.6945e-05\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1379\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1379 - val_loss: 0.1914 - lr: 7.3098e-05\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1306\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1306 - val_loss: 0.1900 - lr: 6.9443e-05\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1353\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1353 - val_loss: 0.1848 - lr: 6.5971e-05\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1379\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1379 - val_loss: 0.1806 - lr: 6.2672e-05\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1510\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 5.656161210936261e-05.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1510 - val_loss: 0.1922 - lr: 5.9539e-05\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1396\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 5.373353305913042e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1396 - val_loss: 0.1869 - lr: 5.6562e-05\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1315\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 5.104685606056591e-05.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1315 - val_loss: 0.1827 - lr: 5.3734e-05\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1481\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 4.849451343034161e-05.\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1481 - val_loss: 0.1867 - lr: 5.1047e-05\n",
      "Epoch 77: early stopping\n",
      "2/2 [==============================] - 7s 125ms/step\n",
      "0.1546, 0.1743, 0.3296\n",
      "______fold 10______, ________repeat 1__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 52s 794ms/step - loss: 0.4927 - val_loss: 0.4444 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 429ms/step - loss: 0.4649 - val_loss: 0.4422 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.4577 - val_loss: 0.4326 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4442\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.4442 - val_loss: 0.4351 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.4192 - val_loss: 0.3998 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.3986 - val_loss: 0.3560 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3681\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.3681 - val_loss: 0.3580 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.3354 - val_loss: 0.3244 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3195\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.3195 - val_loss: 0.3279 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.3066 - val_loss: 0.3062 - lr: 8.5737e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2895 - val_loss: 0.2798 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2875 - val_loss: 0.2582 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2615\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2615 - val_loss: 0.2613 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2488\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2488 - val_loss: 0.2685 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2442\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2442 - val_loss: 0.2657 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2605\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2605 - val_loss: 0.2659 - lr: 7.3509e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.2392 - val_loss: 0.2487 - lr: 6.9834e-04\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2217 - val_loss: 0.2474 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2157\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2157 - val_loss: 0.2509 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2340 - val_loss: 0.2222 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2118\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2118 - val_loss: 0.2315 - lr: 6.6342e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2203\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2203 - val_loss: 0.2359 - lr: 6.3025e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2215 - val_loss: 0.2130 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2119 - val_loss: 0.2089 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2062\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.2062 - val_loss: 0.2180 - lr: 5.9874e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1928\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1928 - val_loss: 0.2262 - lr: 5.6880e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1908\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1908 - val_loss: 0.2119 - lr: 5.4036e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1946 - val_loss: 0.2027 - lr: 5.1334e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1763 - val_loss: 0.1976 - lr: 5.1334e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1996\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 413ms/step - loss: 0.1996 - val_loss: 0.2096 - lr: 5.1334e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1709\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1709 - val_loss: 0.1986 - lr: 4.8767e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.1801 - val_loss: 0.1653 - lr: 4.6329e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1822\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1822 - val_loss: 0.1950 - lr: 4.6329e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1798\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1798 - val_loss: 0.1862 - lr: 4.4013e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1727\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1727 - val_loss: 0.1862 - lr: 4.1812e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1668\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1668 - val_loss: 0.1923 - lr: 3.9721e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1670\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1670 - val_loss: 0.1932 - lr: 3.7735e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1683\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1683 - val_loss: 0.1943 - lr: 3.5849e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1535\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1535 - val_loss: 0.1945 - lr: 3.4056e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1825\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1825 - val_loss: 0.2030 - lr: 3.2353e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1573\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1573 - val_loss: 0.1880 - lr: 3.0736e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1573\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1573 - val_loss: 0.1957 - lr: 2.9199e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1529\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1529 - val_loss: 0.1921 - lr: 2.7739e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1519\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1519 - val_loss: 0.1872 - lr: 2.6352e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1522\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1522 - val_loss: 0.1890 - lr: 2.5034e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1545\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1545 - val_loss: 0.1948 - lr: 2.3783e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1540\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1540 - val_loss: 0.2141 - lr: 2.2594e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1460\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1460 - val_loss: 0.2006 - lr: 2.1464e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1411\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1411 - val_loss: 0.1966 - lr: 2.0391e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1631\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1631 - val_loss: 0.1937 - lr: 1.9371e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1446\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1446 - val_loss: 0.2020 - lr: 1.8403e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1379\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1379 - val_loss: 0.2113 - lr: 1.7482e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1508\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1508 - val_loss: 0.2076 - lr: 1.6608e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1499\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1499 - val_loss: 0.2042 - lr: 1.5778e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1377\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1377 - val_loss: 0.1972 - lr: 1.4989e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1458\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1458 - val_loss: 0.1956 - lr: 1.4240e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1354\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.1354 - val_loss: 0.1973 - lr: 1.3528e-04\n",
      "Epoch 57: early stopping\n",
      "2/2 [==============================] - 8s 127ms/step\n",
      "0.1801, 0.1653, 0.2389\n",
      "______fold 10______, ________repeat 2__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 805ms/step - loss: 0.4869 - val_loss: 0.4464 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 412ms/step - loss: 0.4615 - val_loss: 0.4361 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.4430 - val_loss: 0.4312 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.4293 - val_loss: 0.4192 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.4140 - val_loss: 0.3823 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3854\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.3854 - val_loss: 0.3851 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.3601 - val_loss: 0.3303 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 414ms/step - loss: 0.3208 - val_loss: 0.3208 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.3033 - val_loss: 0.3106 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.3035 - val_loss: 0.3037 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2613\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2613 - val_loss: 0.3045 - lr: 9.5000e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2965 - val_loss: 0.2739 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2632 - val_loss: 0.2654 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2560\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2560 - val_loss: 0.2817 - lr: 9.0250e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2393\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2393 - val_loss: 0.2770 - lr: 8.5737e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2382 - val_loss: 0.2606 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2268\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2268 - val_loss: 0.2812 - lr: 8.1451e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2360\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.2360 - val_loss: 0.3037 - lr: 7.7378e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2509 - val_loss: 0.2430 - lr: 7.3509e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2399\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2399 - val_loss: 0.2731 - lr: 7.3509e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2385\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2385 - val_loss: 0.2718 - lr: 6.9834e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2171\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2171 - val_loss: 0.2786 - lr: 6.6342e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2018\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2018 - val_loss: 0.2619 - lr: 6.3025e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2132\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.2132 - val_loss: 0.2686 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2027\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2027 - val_loss: 0.2797 - lr: 5.6880e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2031\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2031 - val_loss: 0.2476 - lr: 5.4036e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2043\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2043 - val_loss: 0.2648 - lr: 5.1334e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2006\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2006 - val_loss: 0.2562 - lr: 4.8767e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1816\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1816 - val_loss: 0.2746 - lr: 4.6329e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1854\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1854 - val_loss: 0.2893 - lr: 4.4013e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1818\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1818 - val_loss: 0.2702 - lr: 4.1812e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1754\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1754 - val_loss: 0.2561 - lr: 3.9721e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1729\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1729 - val_loss: 0.2667 - lr: 3.7735e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1793\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1793 - val_loss: 0.2552 - lr: 3.5849e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1757\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1757 - val_loss: 0.2644 - lr: 3.4056e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1791\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1791 - val_loss: 0.2529 - lr: 3.2353e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1617\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1617 - val_loss: 0.2733 - lr: 3.0736e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1717\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1717 - val_loss: 0.2503 - lr: 2.9199e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1715\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1715 - val_loss: 0.2598 - lr: 2.7739e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1642\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1642 - val_loss: 0.2500 - lr: 2.6352e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1591\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1591 - val_loss: 0.2436 - lr: 2.5034e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1607\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1607 - val_loss: 0.2893 - lr: 2.3783e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1757\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1757 - val_loss: 0.2697 - lr: 2.2594e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1554\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1554 - val_loss: 0.2637 - lr: 2.1464e-04\n",
      "Epoch 44: early stopping\n",
      "2/2 [==============================] - 6s 133ms/step\n",
      "0.2509, 0.2430, 0.4588\n",
      "______fold 10______, ________repeat 3__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 784ms/step - loss: 0.4967 - val_loss: 0.4457 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 431ms/step - loss: 0.4682 - val_loss: 0.4442 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.4596 - val_loss: 0.4318 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4488\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.4488 - val_loss: 0.4321 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.4390 - val_loss: 0.4160 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.4221 - val_loss: 0.3823 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.3732 - val_loss: 0.3126 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.3332 - val_loss: 0.2939 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3119\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.3119 - val_loss: 0.2970 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.3051 - val_loss: 0.2530 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2979\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.2979 - val_loss: 0.2546 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2726\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2726 - val_loss: 0.2876 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2624 - val_loss: 0.2465 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2640 - val_loss: 0.2444 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2910\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2910 - val_loss: 0.2940 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2594 - val_loss: 0.2222 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2444\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.2444 - val_loss: 0.2259 - lr: 7.7378e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2449 - val_loss: 0.1955 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2320\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.2320 - val_loss: 0.2439 - lr: 7.3509e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2233\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2233 - val_loss: 0.2262 - lr: 6.9834e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2099\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.2099 - val_loss: 0.2239 - lr: 6.6342e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1985\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1985 - val_loss: 0.2091 - lr: 6.3025e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2108\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.2108 - val_loss: 0.2222 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2237\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.2237 - val_loss: 0.2226 - lr: 5.6880e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2124\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.2124 - val_loss: 0.2252 - lr: 5.4036e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2078\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.2078 - val_loss: 0.2249 - lr: 5.1334e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2077\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2077 - val_loss: 0.1976 - lr: 4.8767e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1994\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1994 - val_loss: 0.2154 - lr: 4.6329e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1819\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1819 - val_loss: 0.2257 - lr: 4.4013e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1854\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1854 - val_loss: 0.2325 - lr: 4.1812e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1727\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1727 - val_loss: 0.2379 - lr: 3.9721e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1726\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1726 - val_loss: 0.2083 - lr: 3.7735e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1724\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1724 - val_loss: 0.2078 - lr: 3.5849e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1828\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1828 - val_loss: 0.2181 - lr: 3.4056e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1720 - val_loss: 0.1947 - lr: 3.2353e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1632\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1632 - val_loss: 0.2323 - lr: 3.2353e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1875\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1875 - val_loss: 0.2279 - lr: 3.0736e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1654\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1654 - val_loss: 0.2127 - lr: 2.9199e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1585\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1585 - val_loss: 0.2262 - lr: 2.7739e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1558\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1558 - val_loss: 0.2673 - lr: 2.6352e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1849\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1849 - val_loss: 0.2322 - lr: 2.5034e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1625\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1625 - val_loss: 0.2177 - lr: 2.3783e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1532\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1532 - val_loss: 0.2238 - lr: 2.2594e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1542\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1542 - val_loss: 0.2209 - lr: 2.1464e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1676\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1676 - val_loss: 0.2200 - lr: 2.0391e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1661\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1661 - val_loss: 0.2266 - lr: 1.9371e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1649\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1649 - val_loss: 0.2233 - lr: 1.8403e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1562\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1562 - val_loss: 0.2245 - lr: 1.7482e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1519\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1519 - val_loss: 0.2261 - lr: 1.6608e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1524\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1524 - val_loss: 0.2342 - lr: 1.5778e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1363\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1363 - val_loss: 0.2260 - lr: 1.4989e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1462\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1462 - val_loss: 0.2088 - lr: 1.4240e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1445\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1445 - val_loss: 0.2142 - lr: 1.3528e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1433\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1433 - val_loss: 0.2325 - lr: 1.2851e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1430\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1430 - val_loss: 0.2174 - lr: 1.2209e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1497\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1497 - val_loss: 0.2214 - lr: 1.1598e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1500\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1500 - val_loss: 0.2331 - lr: 1.1018e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1483\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1483 - val_loss: 0.2345 - lr: 1.0467e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1433\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1433 - val_loss: 0.2310 - lr: 9.9440e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1465\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.1465 - val_loss: 0.2268 - lr: 9.4468e-05\n",
      "Epoch 60: early stopping\n",
      "2/2 [==============================] - 6s 127ms/step\n",
      "0.1720, 0.1947, 0.4188\n",
      "______fold 10______, ________repeat 4__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 790ms/step - loss: 0.4721 - val_loss: 0.4418 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.4533 - val_loss: 0.4352 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.4453 - val_loss: 0.4307 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4399\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.4399 - val_loss: 0.4719 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.4184 - val_loss: 0.4120 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.4030 - val_loss: 0.3939 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3886\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.3886 - val_loss: 0.4015 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.3595 - val_loss: 0.3446 - lr: 9.0250e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.3493 - val_loss: 0.3432 - lr: 9.0250e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.3410 - val_loss: 0.3015 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.3098 - val_loss: 0.2867 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2969 - val_loss: 0.2545 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2990\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.2990 - val_loss: 0.2602 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2824\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2824 - val_loss: 0.2573 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2975\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.2975 - val_loss: 0.2546 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2706\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2706 - val_loss: 0.2680 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2460\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2460 - val_loss: 0.2587 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2603\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2603 - val_loss: 0.2994 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2447 - val_loss: 0.2500 - lr: 6.6342e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2286 - val_loss: 0.2092 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2266\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.2266 - val_loss: 0.2159 - lr: 6.6342e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2218\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.2218 - val_loss: 0.2365 - lr: 6.3025e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2216 - val_loss: 0.1991 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2032\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.2032 - val_loss: 0.2331 - lr: 5.9874e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2068\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2068 - val_loss: 0.2191 - lr: 5.6880e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1953\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1953 - val_loss: 0.2060 - lr: 5.4036e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.1923 - val_loss: 0.1685 - lr: 5.1334e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2036\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2036 - val_loss: 0.1876 - lr: 5.1334e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1981\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1981 - val_loss: 0.1960 - lr: 4.8767e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1859\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1859 - val_loss: 0.2006 - lr: 4.6329e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1668\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1668 - val_loss: 0.1848 - lr: 4.4013e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1929\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1929 - val_loss: 0.1787 - lr: 4.1812e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1916\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1916 - val_loss: 0.1966 - lr: 3.9721e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1977\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1977 - val_loss: 0.1931 - lr: 3.7735e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1806\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1806 - val_loss: 0.1921 - lr: 3.5849e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1834\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1834 - val_loss: 0.1915 - lr: 3.4056e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1698\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1698 - val_loss: 0.1880 - lr: 3.2353e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1656\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1656 - val_loss: 0.1837 - lr: 3.0736e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1492\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1492 - val_loss: 0.1824 - lr: 2.9199e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1714\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1714 - val_loss: 0.1998 - lr: 2.7739e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1691\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1691 - val_loss: 0.2014 - lr: 2.6352e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1692\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1692 - val_loss: 0.1917 - lr: 2.5034e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1624\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1624 - val_loss: 0.1906 - lr: 2.3783e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1550\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1550 - val_loss: 0.1770 - lr: 2.2594e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1434\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1434 - val_loss: 0.1720 - lr: 2.1464e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1751\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1751 - val_loss: 0.1831 - lr: 2.0391e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1648\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1648 - val_loss: 0.1846 - lr: 1.9371e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1614\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1614 - val_loss: 0.1851 - lr: 1.8403e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1582\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1582 - val_loss: 0.1864 - lr: 1.7482e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1535\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1535 - val_loss: 0.1839 - lr: 1.6608e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1485\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1485 - val_loss: 0.1825 - lr: 1.5778e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1486\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1486 - val_loss: 0.1735 - lr: 1.4989e-04\n",
      "Epoch 52: early stopping\n",
      "2/2 [==============================] - 6s 145ms/step\n",
      "0.1923, 0.1685, 0.3284\n",
      "______fold 10______, ________repeat 5__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 808ms/step - loss: 0.4757 - val_loss: 0.4488 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 8s 439ms/step - loss: 0.4716 - val_loss: 0.4427 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.4584 - val_loss: 0.4376 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.4370 - val_loss: 0.3896 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.4002 - val_loss: 0.3859 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 430ms/step - loss: 0.3819 - val_loss: 0.3577 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3579\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.3579 - val_loss: 0.3584 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.3348 - val_loss: 0.2909 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.3225 - val_loss: 0.2581 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3117\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.3117 - val_loss: 0.2604 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3096\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.3096 - val_loss: 0.2700 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 387ms/step - loss: 0.2698 - val_loss: 0.2452 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2714 - val_loss: 0.2395 - lr: 8.5737e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2360\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.2360 - val_loss: 0.2509 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.2542 - val_loss: 0.1927 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2301\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.2301 - val_loss: 0.2095 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2201\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.2201 - val_loss: 0.2442 - lr: 7.7378e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2334\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.2334 - val_loss: 0.2268 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2232\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2232 - val_loss: 0.2229 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2018\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.2018 - val_loss: 0.2345 - lr: 6.6342e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1936\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1936 - val_loss: 0.2427 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1986\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1986 - val_loss: 0.2205 - lr: 5.9874e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1963\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1963 - val_loss: 0.1957 - lr: 5.6880e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1974\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1974 - val_loss: 0.2231 - lr: 5.4036e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1933\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1933 - val_loss: 0.2273 - lr: 5.1334e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1913\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1913 - val_loss: 0.2143 - lr: 4.8767e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1915\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1915 - val_loss: 0.2053 - lr: 4.6329e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1660\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1660 - val_loss: 0.2218 - lr: 4.4013e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1824\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1824 - val_loss: 0.2209 - lr: 4.1812e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1660\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1660 - val_loss: 0.2108 - lr: 3.9721e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1754\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1754 - val_loss: 0.2220 - lr: 3.7735e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1604\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 365ms/step - loss: 0.1604 - val_loss: 0.2251 - lr: 3.5849e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1698\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1698 - val_loss: 0.2174 - lr: 3.4056e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1759\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1759 - val_loss: 0.2243 - lr: 3.2353e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1713\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1713 - val_loss: 0.2169 - lr: 3.0736e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1631\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1631 - val_loss: 0.2152 - lr: 2.9199e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1525\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1525 - val_loss: 0.2190 - lr: 2.7739e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1542\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1542 - val_loss: 0.2132 - lr: 2.6352e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1530\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1530 - val_loss: 0.2148 - lr: 2.5034e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1414\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.1414 - val_loss: 0.2225 - lr: 2.3783e-04\n",
      "Epoch 40: early stopping\n",
      "2/2 [==============================] - 6s 121ms/step\n",
      "0.2542, 0.1927, 0.2847\n",
      "______fold 10______, ________repeat 6__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 54s 793ms/step - loss: 0.4799 - val_loss: 0.4389 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.4441 - val_loss: 0.4338 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.4462 - val_loss: 0.4104 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4340\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.4340 - val_loss: 0.4231 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4106\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.4106 - val_loss: 0.4111 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4356\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.4356 - val_loss: 0.4150 - lr: 9.0250e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.3853 - val_loss: 0.4072 - lr: 8.5737e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.3791 - val_loss: 0.3893 - lr: 8.5737e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3654\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.3654 - val_loss: 0.4010 - lr: 8.5737e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.3431 - val_loss: 0.3788 - lr: 8.1451e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.3282 - val_loss: 0.3499 - lr: 8.1451e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.3153 - val_loss: 0.3426 - lr: 8.1451e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.3160 - val_loss: 0.3077 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2815\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 6s 362ms/step - loss: 0.2815 - val_loss: 0.3291 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2989\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 6s 361ms/step - loss: 0.2989 - val_loss: 0.3268 - lr: 7.7378e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.2792 - val_loss: 0.2932 - lr: 7.3509e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.2848 - val_loss: 0.2598 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2800\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.2800 - val_loss: 0.2934 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 8s 422ms/step - loss: 0.2562 - val_loss: 0.2489 - lr: 6.9834e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2685\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2685 - val_loss: 0.3063 - lr: 6.9834e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2556\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.2556 - val_loss: 0.2769 - lr: 6.6342e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2420\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.2420 - val_loss: 0.2825 - lr: 6.3025e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2426\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2426 - val_loss: 0.2656 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2426\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.2426 - val_loss: 0.2795 - lr: 5.6880e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2340\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2340 - val_loss: 0.2624 - lr: 5.4036e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2399\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2399 - val_loss: 0.2627 - lr: 5.1334e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2181\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2181 - val_loss: 0.2578 - lr: 4.8767e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2238 - val_loss: 0.2254 - lr: 4.6329e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2250\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 416ms/step - loss: 0.2250 - val_loss: 0.2261 - lr: 4.6329e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2139\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2139 - val_loss: 0.2357 - lr: 4.4013e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2214\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2214 - val_loss: 0.2434 - lr: 4.1812e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2130\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2130 - val_loss: 0.2466 - lr: 3.9721e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1907\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1907 - val_loss: 0.2429 - lr: 3.7735e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2070\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2070 - val_loss: 0.2364 - lr: 3.5849e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1820\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1820 - val_loss: 0.2477 - lr: 3.4056e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1861\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1861 - val_loss: 0.2325 - lr: 3.2353e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1954\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1954 - val_loss: 0.2520 - lr: 3.0736e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1703\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1703 - val_loss: 0.2426 - lr: 2.9199e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1965\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1965 - val_loss: 0.2698 - lr: 2.7739e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1839\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1839 - val_loss: 0.2536 - lr: 2.6352e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1775\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1775 - val_loss: 0.2459 - lr: 2.5034e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1773\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1773 - val_loss: 0.2432 - lr: 2.3783e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1992\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1992 - val_loss: 0.2529 - lr: 2.2594e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1870\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1870 - val_loss: 0.2536 - lr: 2.1464e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1851\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1851 - val_loss: 0.2410 - lr: 2.0391e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1828\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1828 - val_loss: 0.2514 - lr: 1.9371e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1833\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1833 - val_loss: 0.2552 - lr: 1.8403e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1794\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1794 - val_loss: 0.2528 - lr: 1.7482e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1741\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1741 - val_loss: 0.2427 - lr: 1.6608e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1805\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1805 - val_loss: 0.2504 - lr: 1.5778e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1748\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1748 - val_loss: 0.2432 - lr: 1.4989e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1721\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1721 - val_loss: 0.2418 - lr: 1.4240e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1756\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1756 - val_loss: 0.2545 - lr: 1.3528e-04\n",
      "Epoch 53: early stopping\n",
      "2/2 [==============================] - 6s 127ms/step\n",
      "0.2238, 0.2254, 0.4948\n",
      "______fold 10______, ________repeat 7__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 830ms/step - loss: 0.4653 - val_loss: 0.4371 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 412ms/step - loss: 0.4490 - val_loss: 0.4198 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.4202 - val_loss: 0.4111 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3893\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.3893 - val_loss: 0.4409 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.4113 - val_loss: 0.4017 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3783\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 362ms/step - loss: 0.3783 - val_loss: 0.4048 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3582\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 6s 356ms/step - loss: 0.3582 - val_loss: 0.4043 - lr: 9.0250e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.3337 - val_loss: 0.3812 - lr: 8.5737e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.3363 - val_loss: 0.3677 - lr: 8.5737e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.3213 - val_loss: 0.3592 - lr: 8.5737e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.3075 - val_loss: 0.3577 - lr: 8.5737e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3073\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.3073 - val_loss: 0.3726 - lr: 8.5737e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2982 - val_loss: 0.3487 - lr: 8.1451e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 404ms/step - loss: 0.2965 - val_loss: 0.3422 - lr: 8.1451e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3030\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.3030 - val_loss: 0.3572 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2935 - val_loss: 0.3350 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2632\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2632 - val_loss: 0.3362 - lr: 7.7378e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2499 - val_loss: 0.3165 - lr: 7.3509e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2575\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2575 - val_loss: 0.3226 - lr: 7.3509e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2657\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2657 - val_loss: 0.3210 - lr: 6.9834e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2749 - val_loss: 0.3110 - lr: 6.6342e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2482 - val_loss: 0.2928 - lr: 6.6342e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2613\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2613 - val_loss: 0.3039 - lr: 6.6342e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2336\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2336 - val_loss: 0.3014 - lr: 6.3025e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.2303 - val_loss: 0.2787 - lr: 5.9874e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2327\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.2327 - val_loss: 0.3075 - lr: 5.9874e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2398\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2398 - val_loss: 0.3149 - lr: 5.6880e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2199\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2199 - val_loss: 0.3059 - lr: 5.4036e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2184\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2184 - val_loss: 0.2960 - lr: 5.1334e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2020\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2020 - val_loss: 0.2851 - lr: 4.8767e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.2021 - val_loss: 0.2781 - lr: 4.6329e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.2082 - val_loss: 0.2771 - lr: 4.6329e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2023\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.2023 - val_loss: 0.3045 - lr: 4.6329e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2245\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2245 - val_loss: 0.3054 - lr: 4.4013e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1917 - val_loss: 0.2768 - lr: 4.1812e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1993\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.1993 - val_loss: 0.2769 - lr: 4.1812e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.1959 - val_loss: 0.2661 - lr: 3.9721e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2027 - val_loss: 0.2601 - lr: 3.9721e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1873\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.1873 - val_loss: 0.2728 - lr: 3.9721e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1953 - val_loss: 0.2495 - lr: 3.7735e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1863\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1863 - val_loss: 0.2537 - lr: 3.7735e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1858 - val_loss: 0.2463 - lr: 3.5849e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1745\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1745 - val_loss: 0.2575 - lr: 3.5849e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1821\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1821 - val_loss: 0.2489 - lr: 3.4056e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1737 - val_loss: 0.2409 - lr: 3.2353e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 7s 410ms/step - loss: 0.1552 - val_loss: 0.2298 - lr: 3.2353e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.1601 - val_loss: 0.2285 - lr: 3.2353e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1706\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.1706 - val_loss: 0.2556 - lr: 3.2353e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 7s 407ms/step - loss: 0.1683 - val_loss: 0.2274 - lr: 3.0736e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.1678 - val_loss: 0.2078 - lr: 3.0736e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1854\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.1854 - val_loss: 0.2258 - lr: 3.0736e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1545\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.1545 - val_loss: 0.2252 - lr: 2.9199e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1543\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1543 - val_loss: 0.2093 - lr: 2.7739e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1631\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1631 - val_loss: 0.2361 - lr: 2.6352e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1531\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1531 - val_loss: 0.2262 - lr: 2.5034e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1576\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1576 - val_loss: 0.2238 - lr: 2.3783e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1649\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1649 - val_loss: 0.2188 - lr: 2.2594e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1516\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1516 - val_loss: 0.2161 - lr: 2.1464e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1568\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1568 - val_loss: 0.2271 - lr: 2.0391e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1456\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1456 - val_loss: 0.2201 - lr: 1.9371e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1526\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1526 - val_loss: 0.2234 - lr: 1.8403e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 7s 408ms/step - loss: 0.1511 - val_loss: 0.2056 - lr: 1.7482e-04\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1409\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1409 - val_loss: 0.2192 - lr: 1.7482e-04\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1545\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1545 - val_loss: 0.2185 - lr: 1.6608e-04\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1433\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1433 - val_loss: 0.2175 - lr: 1.5778e-04\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1482\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 394ms/step - loss: 0.1482 - val_loss: 0.2168 - lr: 1.4989e-04\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1497\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1497 - val_loss: 0.2285 - lr: 1.4240e-04\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1617\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.1617 - val_loss: 0.2237 - lr: 1.3528e-04\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1383\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1383 - val_loss: 0.2274 - lr: 1.2851e-04\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1413\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.1413 - val_loss: 0.2311 - lr: 1.2209e-04\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1461\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1461 - val_loss: 0.2242 - lr: 1.1598e-04\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1342\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1342 - val_loss: 0.2146 - lr: 1.1018e-04\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1319\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1319 - val_loss: 0.2224 - lr: 1.0467e-04\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1454\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.1454 - val_loss: 0.2351 - lr: 9.9440e-05\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1366\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1366 - val_loss: 0.2280 - lr: 9.4468e-05\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1271\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1271 - val_loss: 0.2235 - lr: 8.9745e-05\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.1394\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1394 - val_loss: 0.2207 - lr: 8.5258e-05\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1321\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1321 - val_loss: 0.2297 - lr: 8.0995e-05\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1243\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1243 - val_loss: 0.2314 - lr: 7.6945e-05\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1321\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1321 - val_loss: 0.2248 - lr: 7.3098e-05\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1345\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1345 - val_loss: 0.2106 - lr: 6.9443e-05\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1226\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1226 - val_loss: 0.2166 - lr: 6.5971e-05\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1257\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1257 - val_loss: 0.2204 - lr: 6.2672e-05\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1281\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 5.656161210936261e-05.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1281 - val_loss: 0.2186 - lr: 5.9539e-05\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1269\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 5.373353305913042e-05.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1269 - val_loss: 0.2174 - lr: 5.6562e-05\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1327\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 5.104685606056591e-05.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1327 - val_loss: 0.2251 - lr: 5.3734e-05\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1290\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 4.849451343034161e-05.\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.1290 - val_loss: 0.2266 - lr: 5.1047e-05\n",
      "Epoch 87: early stopping\n",
      "2/2 [==============================] - 7s 127ms/step\n",
      "0.1511, 0.2056, 0.3577\n",
      "______fold 10______, ________repeat 8__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 847ms/step - loss: 0.4862 - val_loss: 0.4391 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.4632 - val_loss: 0.4386 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.4529 - val_loss: 0.4288 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4430\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.4430 - val_loss: 0.4307 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.4295 - val_loss: 0.4059 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.4031 - val_loss: 0.4041 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 8s 437ms/step - loss: 0.3676 - val_loss: 0.3655 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 8s 436ms/step - loss: 0.3391 - val_loss: 0.3458 - lr: 9.5000e-04\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 8s 430ms/step - loss: 0.3097 - val_loss: 0.3212 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 8s 432ms/step - loss: 0.3068 - val_loss: 0.2947 - lr: 9.5000e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2669 - val_loss: 0.2711 - lr: 9.5000e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2423 - val_loss: 0.2686 - lr: 9.5000e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 7s 399ms/step - loss: 0.2505 - val_loss: 0.2469 - lr: 9.5000e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2359\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.2359 - val_loss: 0.2716 - lr: 9.5000e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2317\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.2317 - val_loss: 0.2591 - lr: 9.0250e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2143\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2143 - val_loss: 0.2988 - lr: 8.5737e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2215\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2215 - val_loss: 0.2627 - lr: 8.1451e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2067\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2067 - val_loss: 0.2479 - lr: 7.7378e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2286 - val_loss: 0.2369 - lr: 7.3509e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.2007 - val_loss: 0.2368 - lr: 7.3509e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.1949 - val_loss: 0.2344 - lr: 7.3509e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1823\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 415ms/step - loss: 0.1823 - val_loss: 0.2409 - lr: 7.3509e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1945\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1945 - val_loss: 0.2525 - lr: 6.9834e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.2185 - val_loss: 0.2232 - lr: 6.6342e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1775\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1775 - val_loss: 0.2344 - lr: 6.6342e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1800\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1800 - val_loss: 0.2235 - lr: 6.3025e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1974 - val_loss: 0.2166 - lr: 5.9874e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1716\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.1716 - val_loss: 0.2345 - lr: 5.9874e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1720\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1720 - val_loss: 0.2583 - lr: 5.6880e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1666\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1666 - val_loss: 0.2647 - lr: 5.4036e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1625\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1625 - val_loss: 0.2439 - lr: 5.1334e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1708\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1708 - val_loss: 0.2445 - lr: 4.8767e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1675\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1675 - val_loss: 0.2427 - lr: 4.6329e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1754\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1754 - val_loss: 0.2211 - lr: 4.4013e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.1562 - val_loss: 0.1876 - lr: 4.1812e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1612\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1612 - val_loss: 0.1924 - lr: 4.1812e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.1447 - val_loss: 0.1822 - lr: 3.9721e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1418\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1418 - val_loss: 0.1944 - lr: 3.9721e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1472\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1472 - val_loss: 0.2009 - lr: 3.7735e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1409\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1409 - val_loss: 0.2259 - lr: 3.5849e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1405\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1405 - val_loss: 0.2386 - lr: 3.4056e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1376\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1376 - val_loss: 0.2177 - lr: 3.2353e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1393\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1393 - val_loss: 0.2694 - lr: 3.0736e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1438\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1438 - val_loss: 0.2410 - lr: 2.9199e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1405\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1405 - val_loss: 0.2180 - lr: 2.7739e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1277\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1277 - val_loss: 0.2217 - lr: 2.6352e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1435\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1435 - val_loss: 0.2392 - lr: 2.5034e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1427\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1427 - val_loss: 0.2367 - lr: 2.3783e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1358\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1358 - val_loss: 0.2690 - lr: 2.2594e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1174\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1174 - val_loss: 0.2689 - lr: 2.1464e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1422\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1422 - val_loss: 0.2316 - lr: 2.0391e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1235\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1235 - val_loss: 0.2170 - lr: 1.9371e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1289\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1289 - val_loss: 0.2101 - lr: 1.8403e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1304\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1304 - val_loss: 0.2123 - lr: 1.7482e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1229\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1229 - val_loss: 0.2248 - lr: 1.6608e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1339\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1339 - val_loss: 0.2370 - lr: 1.5778e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1189\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1189 - val_loss: 0.2267 - lr: 1.4989e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1222\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1222 - val_loss: 0.2117 - lr: 1.4240e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1208\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1208 - val_loss: 0.2170 - lr: 1.3528e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1277\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1277 - val_loss: 0.2139 - lr: 1.2851e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1174\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1174 - val_loss: 0.2117 - lr: 1.2209e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1219\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 37.\n",
      "18/18 [==============================] - 7s 392ms/step - loss: 0.1219 - val_loss: 0.2121 - lr: 1.1598e-04\n",
      "Epoch 62: early stopping\n",
      "2/2 [==============================] - 6s 121ms/step\n",
      "0.1447, 0.1822, 0.3746\n",
      "______fold 10______, ________repeat 9__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 53s 867ms/step - loss: 0.4986 - val_loss: 0.4486 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 7s 413ms/step - loss: 0.4664 - val_loss: 0.4415 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.4544 - val_loss: 0.4354 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 397ms/step - loss: 0.4376 - val_loss: 0.4221 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.4115 - val_loss: 0.4161 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.4172 - val_loss: 0.3852 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.3824 - val_loss: 0.3563 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3736\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.3736 - val_loss: 0.3805 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3597\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.3597 - val_loss: 0.3586 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.3473 - val_loss: 0.3291 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.3344 - val_loss: 0.3264 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 396ms/step - loss: 0.3152 - val_loss: 0.2949 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3020\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.3020 - val_loss: 0.3009 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2923 - val_loss: 0.2896 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2956\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.2956 - val_loss: 0.3075 - lr: 8.5737e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2871\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.2871 - val_loss: 0.2907 - lr: 8.1451e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2509 - val_loss: 0.2889 - lr: 7.7378e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2657 - val_loss: 0.2816 - lr: 7.7378e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 7s 393ms/step - loss: 0.2489 - val_loss: 0.2551 - lr: 7.7378e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2242\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.2242 - val_loss: 0.2681 - lr: 7.7378e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 7s 390ms/step - loss: 0.2178 - val_loss: 0.2259 - lr: 7.3509e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2397\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.2397 - val_loss: 0.2724 - lr: 7.3509e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2279 - val_loss: 0.2181 - lr: 6.9834e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 7s 391ms/step - loss: 0.2180 - val_loss: 0.1929 - lr: 6.9834e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2126\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.2126 - val_loss: 0.2343 - lr: 6.9834e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2112 - val_loss: 0.1672 - lr: 6.6342e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2019\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.2019 - val_loss: 0.2178 - lr: 6.6342e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1997\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1997 - val_loss: 0.1994 - lr: 6.3025e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1947\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1947 - val_loss: 0.2151 - lr: 5.9874e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1963\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1963 - val_loss: 0.2203 - lr: 5.6880e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1939\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1939 - val_loss: 0.2202 - lr: 5.4036e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1827\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1827 - val_loss: 0.2023 - lr: 5.1334e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1762\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1762 - val_loss: 0.2089 - lr: 4.8767e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1882\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1882 - val_loss: 0.2189 - lr: 4.6329e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1782\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1782 - val_loss: 0.1953 - lr: 4.4013e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1700\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1700 - val_loss: 0.1941 - lr: 4.1812e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1646\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1646 - val_loss: 0.1933 - lr: 3.9721e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1667\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1667 - val_loss: 0.1788 - lr: 3.7735e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.1637 - val_loss: 0.1631 - lr: 3.5849e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1704\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 371ms/step - loss: 0.1704 - val_loss: 0.1756 - lr: 3.5849e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1577\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1577 - val_loss: 0.1813 - lr: 3.4056e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1696\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1696 - val_loss: 0.1761 - lr: 3.2353e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 7s 389ms/step - loss: 0.1603 - val_loss: 0.1438 - lr: 3.0736e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1604\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1604 - val_loss: 0.1702 - lr: 3.0736e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1488\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1488 - val_loss: 0.1945 - lr: 2.9199e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1458\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1458 - val_loss: 0.1905 - lr: 2.7739e-04\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1489\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1489 - val_loss: 0.1827 - lr: 2.6352e-04\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1443\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1443 - val_loss: 0.1724 - lr: 2.5034e-04\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1445\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 369ms/step - loss: 0.1445 - val_loss: 0.1818 - lr: 2.3783e-04\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1583\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 370ms/step - loss: 0.1583 - val_loss: 0.1756 - lr: 2.2594e-04\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1354\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 368ms/step - loss: 0.1354 - val_loss: 0.1818 - lr: 2.1464e-04\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1383\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.1383 - val_loss: 0.1862 - lr: 2.0391e-04\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1430\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1430 - val_loss: 0.1737 - lr: 1.9371e-04\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1569\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1569 - val_loss: 0.1868 - lr: 1.8403e-04\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1359\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1359 - val_loss: 0.1972 - lr: 1.7482e-04\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1364\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1364 - val_loss: 0.1965 - lr: 1.6608e-04\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1371\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "18/18 [==============================] - 7s 375ms/step - loss: 0.1371 - val_loss: 0.1875 - lr: 1.5778e-04\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1404\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1404 - val_loss: 0.1853 - lr: 1.4989e-04\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1289\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1289 - val_loss: 0.1801 - lr: 1.4240e-04\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1368\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1368 - val_loss: 0.1764 - lr: 1.3528e-04\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1306\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1306 - val_loss: 0.1786 - lr: 1.2851e-04\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1402\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 0.1402 - val_loss: 0.1804 - lr: 1.2209e-04\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1370\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1370 - val_loss: 0.1824 - lr: 1.1598e-04\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1353\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1353 - val_loss: 0.1773 - lr: 1.1018e-04\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1387\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1387 - val_loss: 0.1765 - lr: 1.0467e-04\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1293\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1293 - val_loss: 0.1741 - lr: 9.9440e-05\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1268\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "18/18 [==============================] - 7s 373ms/step - loss: 0.1268 - val_loss: 0.1679 - lr: 9.4468e-05\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1432\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "18/18 [==============================] - 7s 398ms/step - loss: 0.1432 - val_loss: 0.1691 - lr: 8.9745e-05\n",
      "Epoch 68: early stopping\n",
      "2/2 [==============================] - 7s 133ms/step\n",
      "0.1603, 0.1438, 0.2403\n",
      "______fold 10______, ________repeat 10__________\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 55s 832ms/step - loss: 0.4674 - val_loss: 0.4215 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4475\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "18/18 [==============================] - 7s 417ms/step - loss: 0.4475 - val_loss: 0.4357 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 7s 401ms/step - loss: 0.4319 - val_loss: 0.4192 - lr: 9.5000e-04\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.4235 - val_loss: 0.4115 - lr: 9.5000e-04\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 8s 432ms/step - loss: 0.3969 - val_loss: 0.3885 - lr: 9.5000e-04\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.3957 - val_loss: 0.3612 - lr: 9.5000e-04\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 7s 409ms/step - loss: 0.3692 - val_loss: 0.3507 - lr: 9.5000e-04\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.3458 - val_loss: 0.3198 - lr: 9.5000e-04\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.3297\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.3297 - val_loss: 0.3221 - lr: 9.5000e-04\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.3082 - val_loss: 0.3111 - lr: 9.0250e-04\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 7s 402ms/step - loss: 0.2805 - val_loss: 0.2951 - lr: 9.0250e-04\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 7s 405ms/step - loss: 0.2453 - val_loss: 0.2562 - lr: 9.0250e-04\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2528\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "18/18 [==============================] - 8s 419ms/step - loss: 0.2528 - val_loss: 0.2563 - lr: 9.0250e-04\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2418\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2418 - val_loss: 0.2821 - lr: 8.5737e-04\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2475\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.2475 - val_loss: 0.2704 - lr: 8.1451e-04\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2178\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "18/18 [==============================] - 7s 388ms/step - loss: 0.2178 - val_loss: 0.2728 - lr: 7.7378e-04\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2183\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "18/18 [==============================] - 7s 383ms/step - loss: 0.2183 - val_loss: 0.2752 - lr: 7.3509e-04\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2139\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "18/18 [==============================] - 7s 385ms/step - loss: 0.2139 - val_loss: 0.2990 - lr: 6.9834e-04\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2264\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "18/18 [==============================] - 7s 386ms/step - loss: 0.2264 - val_loss: 0.2686 - lr: 6.6342e-04\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 7s 400ms/step - loss: 0.2148 - val_loss: 0.2430 - lr: 6.3025e-04\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 7s 395ms/step - loss: 0.2195 - val_loss: 0.2244 - lr: 6.3025e-04\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2027\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.2027 - val_loss: 0.2306 - lr: 6.3025e-04\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2032\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.2032 - val_loss: 0.2320 - lr: 5.9874e-04\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1996\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1996 - val_loss: 0.2450 - lr: 5.6880e-04\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1997\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1997 - val_loss: 0.2466 - lr: 5.4036e-04\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2187\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.2187 - val_loss: 0.2266 - lr: 5.1334e-04\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1901\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1901 - val_loss: 0.2293 - lr: 4.8767e-04\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1774\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1774 - val_loss: 0.2253 - lr: 4.6329e-04\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1751\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1751 - val_loss: 0.2482 - lr: 4.4013e-04\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1874\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "18/18 [==============================] - 7s 380ms/step - loss: 0.1874 - val_loss: 0.2380 - lr: 4.1812e-04\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1729\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1729 - val_loss: 0.2362 - lr: 3.9721e-04\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1704\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1704 - val_loss: 0.2319 - lr: 3.7735e-04\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1770\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1770 - val_loss: 0.2312 - lr: 3.5849e-04\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1695\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1695 - val_loss: 0.2384 - lr: 3.4056e-04\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1674\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1674 - val_loss: 0.2258 - lr: 3.2353e-04\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1426\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "18/18 [==============================] - 7s 381ms/step - loss: 0.1426 - val_loss: 0.2491 - lr: 3.0736e-04\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1565\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "18/18 [==============================] - 7s 376ms/step - loss: 0.1565 - val_loss: 0.2424 - lr: 2.9199e-04\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1634\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "18/18 [==============================] - 7s 377ms/step - loss: 0.1634 - val_loss: 0.2441 - lr: 2.7739e-04\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1683\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "18/18 [==============================] - 7s 374ms/step - loss: 0.1683 - val_loss: 0.2377 - lr: 2.6352e-04\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1489\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1489 - val_loss: 0.2427 - lr: 2.5034e-04\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1469\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n",
      "18/18 [==============================] - 7s 382ms/step - loss: 0.1469 - val_loss: 0.2392 - lr: 2.3783e-04\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1576\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "18/18 [==============================] - 7s 384ms/step - loss: 0.1576 - val_loss: 0.2445 - lr: 2.2594e-04\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1623\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1623 - val_loss: 0.2377 - lr: 2.1464e-04\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1542\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "18/18 [==============================] - 7s 379ms/step - loss: 0.1542 - val_loss: 0.2525 - lr: 2.0391e-04\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1542\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "18/18 [==============================] - 7s 378ms/step - loss: 0.1542 - val_loss: 0.2361 - lr: 1.9371e-04\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1505\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "18/18 [==============================] - 7s 403ms/step - loss: 0.1505 - val_loss: 0.2400 - lr: 1.8403e-04\n",
      "Epoch 46: early stopping\n",
      "2/2 [==============================] - 6s 126ms/step\n",
      "0.2195, 0.2244, 0.4738\n",
      "0.3824131122562675\n",
      "CPU times: total: 10h 28min 18s\n",
      "Wall time: 13h 18min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "blls = []\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "units_1 = 32\n",
    "drop_1 = 0.75\n",
    "dense_units = 8\n",
    "\n",
    "units_2 = 16\n",
    "drop_2 = 0.5\n",
    "\n",
    "units_3 = 8\n",
    "drop_3 = 0.25\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=722)\n",
    "for n, (train_idx, val_idx) in enumerate(cv.split(X, (tgt + 1) * (tgt2 - 3))):\n",
    "    for k in range(10):\n",
    "        print(f'______fold {n+1}______, ________repeat {k+1}__________')\n",
    "\n",
    "        inputs_1 = tf.keras.Input(shape=(56,))\n",
    "        \n",
    "        features_1 = VariableSelectionFlow(56, units_1, drop_1, dense_units=dense_units)(inputs_1)\n",
    "        features_2 = VariableSelectionFlow(units_1, units_2, drop_2)(features_1)         \n",
    "        features_3 = VariableSelectionFlow(units_2, units_3, drop_3)(features_2)         \n",
    "\n",
    "        outputs = L.Dense(1, activation=\"sigmoid\")(features_3)\n",
    "\n",
    "        model = Model(inputs=inputs_1, outputs=outputs)      \n",
    "\n",
    "        opt = O.Adam(1e-3, epsilon=1e-7)\n",
    "        loss = binary_crossentropy\n",
    "\n",
    "        lr = ReduceLROnPlateau(monitor=\"val_loss\", mode='min', factor=0.95, patience=1, verbose=1)\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', patience=25, verbose=1, restore_best_weights=True)\n",
    "\n",
    "        model.compile(optimizer=opt, \n",
    "                        loss=loss\n",
    "                     )\n",
    "\n",
    "        history = model.fit(x=X[train_idx],\n",
    "                          y=tgt[train_idx],\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=200,\n",
    "                          validation_data=(X[val_idx], tgt[val_idx]),\n",
    "                              callbacks=[lr,es]\n",
    "                )\n",
    "                \n",
    "        probs = model.predict(X[val_idx])[:,0]\n",
    "        bll = balanced_log_loss_np(train_df.Class.values[val_idx], probs)\n",
    "        blls.append(bll)\n",
    "        val_loss = np.asarray(history.history['val_loss'])\n",
    "        train_loss = np.asarray(history.history['loss'])\n",
    "        min_val_loss = val_loss.min()\n",
    "        min_train_loss = train_loss[val_loss.argmin()]\n",
    "        print(f'{min_train_loss:.4f}, {min_val_loss:.4f}, {bll:.4f}')  \n",
    "        \n",
    "        model.save_weights(f'ICR_tf_adv_models/mod_f{n}_r{k}_tr{min_train_loss:.4f}_val{min_val_loss:.4f}.h5')\n",
    "        \n",
    "print(np.mean(blls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c23528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml_env_v1]",
   "language": "python",
   "name": "conda-env-ml_env_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
